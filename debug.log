2024-12-09 23:14:53,393 [DEBUG] Starting new HTTPS connection (1): pypi.org:443
2024-12-09 23:14:53,455 [DEBUG] https://pypi.org:443 "GET /pypi/praw/json HTTP/11" 200 36290
2024-12-09 23:14:53,465 [INFO] Successfully initialized Reddit API.
2024-12-09 23:14:53,466 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733804093.4663098
2024-12-09 23:14:53,466 [DEBUG] Data: None
2024-12-09 23:14:53,466 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-09 23:14:53,468 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-09 23:14:53,570 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 656
2024-12-09 23:14:53,573 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-09 23:14:54,305 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 52045
2024-12-09 23:14:54,323 [DEBUG] Response: 200 (52045 bytes) (rst-306:rem-999.0:used-1 ratelimit) at 1733804094.3233569
2024-12-09 23:14:54,335 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hae4tc/ at 1733804094.335097
2024-12-09 23:14:54,335 [DEBUG] Data: None
2024-12-09 23:14:54,335 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:14:54,468 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hae4tc/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3187
2024-12-09 23:14:54,469 [DEBUG] Response: 200 (3187 bytes) (rst-305:rem-998.0:used-2 ratelimit) at 1733804094.4695559
2024-12-09 23:14:54,471 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9vjwq/ at 1733804094.471811
2024-12-09 23:14:54,471 [DEBUG] Data: None
2024-12-09 23:14:54,472 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:14:54,602 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9vjwq/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3408
2024-12-09 23:14:54,605 [DEBUG] Response: 200 (3408 bytes) (rst-305:rem-997.0:used-3 ratelimit) at 1733804094.605022
2024-12-09 23:14:54,607 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9sr7i/ at 1733804094.607161
2024-12-09 23:14:54,607 [DEBUG] Data: None
2024-12-09 23:14:54,607 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:14:54,757 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9sr7i/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3899
2024-12-09 23:14:54,758 [DEBUG] Response: 200 (3899 bytes) (rst-305:rem-996.0:used-4 ratelimit) at 1733804094.75892
2024-12-09 23:14:54,760 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9omov/ at 1733804094.76074
2024-12-09 23:14:54,760 [DEBUG] Data: None
2024-12-09 23:14:54,760 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:14:55,120 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9omov/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4230
2024-12-09 23:14:55,121 [DEBUG] Response: 200 (4230 bytes) (rst-305:rem-995.0:used-5 ratelimit) at 1733804095.121963
2024-12-09 23:14:55,123 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9fg8c/ at 1733804095.1236842
2024-12-09 23:14:55,123 [DEBUG] Data: None
2024-12-09 23:14:55,123 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:14:55,275 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9fg8c/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6631
2024-12-09 23:14:55,277 [DEBUG] Response: 200 (6631 bytes) (rst-304:rem-994.0:used-6 ratelimit) at 1733804095.277109
2024-12-09 23:14:55,279 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h93w33/ at 1733804095.279425
2024-12-09 23:14:55,279 [DEBUG] Data: None
2024-12-09 23:14:55,279 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:14:55,471 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h93w33/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 5247
2024-12-09 23:14:55,473 [DEBUG] Response: 200 (5247 bytes) (rst-304:rem-993.0:used-7 ratelimit) at 1733804095.4729862
2024-12-09 23:14:55,475 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h8p7ym/ at 1733804095.475589
2024-12-09 23:14:55,475 [DEBUG] Data: None
2024-12-09 23:14:55,475 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:14:55,651 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h8p7ym/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7120
2024-12-09 23:14:55,653 [DEBUG] Response: 200 (7120 bytes) (rst-304:rem-992.0:used-8 ratelimit) at 1733804095.653257
2024-12-09 23:14:55,656 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h8lxr0/ at 1733804095.656119
2024-12-09 23:14:55,656 [DEBUG] Data: None
2024-12-09 23:14:55,656 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:14:55,800 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h8lxr0/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3397
2024-12-09 23:14:55,801 [DEBUG] Response: 200 (3397 bytes) (rst-304:rem-991.0:used-9 ratelimit) at 1733804095.801724
2024-12-09 23:14:55,802 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h8ktl3/ at 1733804095.8029828
2024-12-09 23:14:55,803 [DEBUG] Data: None
2024-12-09 23:14:55,803 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:14:56,144 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h8ktl3/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7672
2024-12-09 23:14:56,146 [DEBUG] Response: 200 (7672 bytes) (rst-304:rem-990.0:used-10 ratelimit) at 1733804096.146434
2024-12-09 23:14:56,150 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733804096.15087
2024-12-09 23:14:56,151 [DEBUG] Data: None
2024-12-09 23:14:56,151 [DEBUG] Params: {'after': 't3_1h3s6y6', 'limit': 200, 'raw_json': 1}
2024-12-09 23:14:56,963 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h3s6y6&raw_json=1 HTTP/11" 200 51688
2024-12-09 23:14:56,965 [DEBUG] Response: 200 (51688 bytes) (rst-303:rem-989.0:used-11 ratelimit) at 1733804096.9659688
2024-12-09 23:14:56,978 [INFO] Fetched 9 posts after filtering.
2024-12-09 23:14:56,992 [ERROR] Error filtering posts with GPT-3.5.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 114, in filter_good_posts_with_gpt35
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/lib/_old_api.py", line 39, in __call__
    raise APIRemovedInV1(symbol=self._symbol)
openai.lib._old_api.APIRemovedInV1: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-09 23:14:56,995 [ERROR] Error in run_script
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 114, in filter_good_posts_with_gpt35
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/lib/_old_api.py", line 39, in __call__
    raise APIRemovedInV1(symbol=self._symbol)
openai.lib._old_api.APIRemovedInV1: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 189, in run_script
    good_posts = filter_good_posts_with_gpt35(posts)
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 131, in filter_good_posts_with_gpt35
    raise RuntimeError(f"Error filtering posts with GPT-3.5: {e}")
RuntimeError: Error filtering posts with GPT-3.5: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-09 23:18:44,569 [INFO] Successfully initialized Reddit API.
2024-12-09 23:18:44,570 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733804324.570518
2024-12-09 23:18:44,570 [DEBUG] Data: None
2024-12-09 23:18:44,570 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-09 23:18:44,574 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-09 23:18:44,906 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 655
2024-12-09 23:18:44,912 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-09 23:18:45,933 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 52059
2024-12-09 23:18:45,998 [DEBUG] Response: 200 (52059 bytes) (rst-74:rem-988.0:used-12 ratelimit) at 1733804325.998317
2024-12-09 23:18:46,005 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hae4tc/ at 1733804326.005583
2024-12-09 23:18:46,005 [DEBUG] Data: None
2024-12-09 23:18:46,005 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:18:46,248 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hae4tc/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3188
2024-12-09 23:18:46,250 [DEBUG] Response: 200 (3188 bytes) (rst-73:rem-987.0:used-13 ratelimit) at 1733804326.2504792
2024-12-09 23:18:46,252 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9vjwq/ at 1733804326.25244
2024-12-09 23:18:46,252 [DEBUG] Data: None
2024-12-09 23:18:46,252 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:18:46,482 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9vjwq/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3407
2024-12-09 23:18:46,483 [DEBUG] Response: 200 (3407 bytes) (rst-73:rem-986.0:used-14 ratelimit) at 1733804326.4837031
2024-12-09 23:18:46,485 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9omov/ at 1733804326.485423
2024-12-09 23:18:46,485 [DEBUG] Data: None
2024-12-09 23:18:46,485 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:18:46,719 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9omov/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4231
2024-12-09 23:18:46,721 [DEBUG] Response: 200 (4231 bytes) (rst-73:rem-985.0:used-15 ratelimit) at 1733804326.721081
2024-12-09 23:18:46,722 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9fg8c/ at 1733804326.722373
2024-12-09 23:18:46,722 [DEBUG] Data: None
2024-12-09 23:18:46,722 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:18:46,970 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9fg8c/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6629
2024-12-09 23:18:46,971 [DEBUG] Response: 200 (6629 bytes) (rst-73:rem-984.0:used-16 ratelimit) at 1733804326.971384
2024-12-09 23:18:46,973 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h93w33/ at 1733804326.973284
2024-12-09 23:18:46,973 [DEBUG] Data: None
2024-12-09 23:18:46,973 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:18:47,364 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h93w33/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 5243
2024-12-09 23:18:47,365 [DEBUG] Response: 200 (5243 bytes) (rst-72:rem-983.0:used-17 ratelimit) at 1733804327.365511
2024-12-09 23:18:47,367 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h8p7ym/ at 1733804327.367786
2024-12-09 23:18:47,367 [DEBUG] Data: None
2024-12-09 23:18:47,367 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:18:47,624 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h8p7ym/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7120
2024-12-09 23:18:47,626 [DEBUG] Response: 200 (7120 bytes) (rst-72:rem-982.0:used-18 ratelimit) at 1733804327.626119
2024-12-09 23:18:47,628 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h8lxr0/ at 1733804327.628983
2024-12-09 23:18:47,629 [DEBUG] Data: None
2024-12-09 23:18:47,629 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:18:47,855 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h8lxr0/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3399
2024-12-09 23:18:47,856 [DEBUG] Response: 200 (3399 bytes) (rst-72:rem-981.0:used-19 ratelimit) at 1733804327.856444
2024-12-09 23:18:47,858 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h8ktl3/ at 1733804327.8585
2024-12-09 23:18:47,858 [DEBUG] Data: None
2024-12-09 23:18:47,858 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:18:48,285 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h8ktl3/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7665
2024-12-09 23:18:48,285 [DEBUG] Response: 200 (7665 bytes) (rst-71:rem-980.0:used-20 ratelimit) at 1733804328.285377
2024-12-09 23:18:48,286 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733804328.286581
2024-12-09 23:18:48,286 [DEBUG] Data: None
2024-12-09 23:18:48,286 [DEBUG] Params: {'after': 't3_1h3s6y6', 'limit': 200, 'raw_json': 1}
2024-12-09 23:18:49,176 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h3s6y6&raw_json=1 HTTP/11" 200 51697
2024-12-09 23:18:49,242 [DEBUG] Response: 200 (51697 bytes) (rst-71:rem-979.0:used-21 ratelimit) at 1733804329.2426171
2024-12-09 23:18:49,254 [INFO] Fetched 8 posts after filtering.
2024-12-09 23:18:49,265 [ERROR] Error filtering posts with GPT-3.5.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 114, in filter_good_posts_with_gpt35
    response = openai.Chat.create(
               ^^^^^^^^^^^
AttributeError: module 'openai' has no attribute 'Chat'. Did you mean: 'chat'?
2024-12-09 23:18:49,266 [ERROR] Error in run_script
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 114, in filter_good_posts_with_gpt35
    response = openai.Chat.create(
               ^^^^^^^^^^^
AttributeError: module 'openai' has no attribute 'Chat'. Did you mean: 'chat'?

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 189, in run_script
    good_posts = filter_good_posts_with_gpt35(posts)
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 131, in filter_good_posts_with_gpt35
    raise RuntimeError(f"Error filtering posts with GPT-3.5: {e}")
RuntimeError: Error filtering posts with GPT-3.5: module 'openai' has no attribute 'Chat'
2024-12-09 23:40:52,504 [INFO] Successfully initialized Reddit API.
2024-12-09 23:40:52,505 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733805652.50528
2024-12-09 23:40:52,505 [DEBUG] Data: None
2024-12-09 23:40:52,505 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-09 23:40:52,508 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-09 23:40:52,619 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 651
2024-12-09 23:40:52,625 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-09 23:40:53,474 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 52101
2024-12-09 23:40:53,490 [DEBUG] Response: 200 (52101 bytes) (rst-547:rem-999.0:used-1 ratelimit) at 1733805653.490626
2024-12-09 23:40:53,503 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hae4tc/ at 1733805653.503911
2024-12-09 23:40:53,504 [DEBUG] Data: None
2024-12-09 23:40:53,504 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:40:53,651 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hae4tc/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3188
2024-12-09 23:40:53,652 [DEBUG] Response: 200 (3188 bytes) (rst-546:rem-998.0:used-2 ratelimit) at 1733805653.652489
2024-12-09 23:40:53,653 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9vjwq/ at 1733805653.653036
2024-12-09 23:40:53,653 [DEBUG] Data: None
2024-12-09 23:40:53,653 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:40:53,784 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9vjwq/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3408
2024-12-09 23:40:53,785 [DEBUG] Response: 200 (3408 bytes) (rst-546:rem-997.0:used-3 ratelimit) at 1733805653.7859242
2024-12-09 23:40:53,788 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9omov/ at 1733805653.787992
2024-12-09 23:40:53,788 [DEBUG] Data: None
2024-12-09 23:40:53,788 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:40:53,923 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9omov/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4228
2024-12-09 23:40:53,925 [DEBUG] Response: 200 (4228 bytes) (rst-546:rem-996.0:used-4 ratelimit) at 1733805653.9251451
2024-12-09 23:40:53,926 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9fg8c/ at 1733805653.926789
2024-12-09 23:40:53,926 [DEBUG] Data: None
2024-12-09 23:40:53,927 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:40:54,090 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9fg8c/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6631
2024-12-09 23:40:54,091 [DEBUG] Response: 200 (6631 bytes) (rst-545:rem-995.0:used-5 ratelimit) at 1733805654.091498
2024-12-09 23:40:54,093 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h93w33/ at 1733805654.093651
2024-12-09 23:40:54,093 [DEBUG] Data: None
2024-12-09 23:40:54,093 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:40:54,289 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h93w33/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 5242
2024-12-09 23:40:54,290 [DEBUG] Response: 200 (5242 bytes) (rst-545:rem-994.0:used-6 ratelimit) at 1733805654.290751
2024-12-09 23:40:54,293 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h8p7ym/ at 1733805654.293822
2024-12-09 23:40:54,294 [DEBUG] Data: None
2024-12-09 23:40:54,294 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:40:54,475 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h8p7ym/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7119
2024-12-09 23:40:54,477 [DEBUG] Response: 200 (7119 bytes) (rst-545:rem-993.0:used-7 ratelimit) at 1733805654.477377
2024-12-09 23:40:54,480 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h8lxr0/ at 1733805654.4808161
2024-12-09 23:40:54,481 [DEBUG] Data: None
2024-12-09 23:40:54,481 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:40:54,615 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h8lxr0/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3400
2024-12-09 23:40:54,617 [DEBUG] Response: 200 (3400 bytes) (rst-545:rem-992.0:used-8 ratelimit) at 1733805654.617085
2024-12-09 23:40:54,618 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h8ktl3/ at 1733805654.6189592
2024-12-09 23:40:54,619 [DEBUG] Data: None
2024-12-09 23:40:54,619 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:40:54,904 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h8ktl3/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7667
2024-12-09 23:40:54,905 [DEBUG] Response: 200 (7667 bytes) (rst-545:rem-991.0:used-9 ratelimit) at 1733805654.9057899
2024-12-09 23:40:54,909 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733805654.909388
2024-12-09 23:40:54,909 [DEBUG] Data: None
2024-12-09 23:40:54,909 [DEBUG] Params: {'after': 't3_1h3s6y6', 'limit': 200, 'raw_json': 1}
2024-12-09 23:40:55,819 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h3s6y6&raw_json=1 HTTP/11" 200 51729
2024-12-09 23:40:55,823 [DEBUG] Response: 200 (51729 bytes) (rst-545:rem-990.0:used-10 ratelimit) at 1733805655.823154
2024-12-09 23:40:55,836 [INFO] Fetched 8 posts after filtering.
2024-12-09 23:40:55,850 [ERROR] Error filtering posts with GPT-3.5.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 114, in filter_good_posts_with_gpt35
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/lib/_old_api.py", line 39, in __call__
    raise APIRemovedInV1(symbol=self._symbol)
openai.lib._old_api.APIRemovedInV1: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-09 23:40:55,852 [ERROR] Error in run_script
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 114, in filter_good_posts_with_gpt35
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/lib/_old_api.py", line 39, in __call__
    raise APIRemovedInV1(symbol=self._symbol)
openai.lib._old_api.APIRemovedInV1: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 188, in run_script
    good_posts = filter_good_posts_with_gpt35(posts)
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 130, in filter_good_posts_with_gpt35
    raise RuntimeError(f"Error filtering posts with GPT-3.5: {e}")
RuntimeError: Error filtering posts with GPT-3.5: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-09 23:42:49,840 [INFO] Successfully initialized Reddit API.
2024-12-09 23:42:49,840 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733805769.840686
2024-12-09 23:42:49,840 [DEBUG] Data: None
2024-12-09 23:42:49,841 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-09 23:42:49,844 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-09 23:42:50,147 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 651
2024-12-09 23:42:50,151 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-09 23:42:51,132 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 52079
2024-12-09 23:42:51,200 [DEBUG] Response: 200 (52079 bytes) (rst-429:rem-989.0:used-11 ratelimit) at 1733805771.200772
2024-12-09 23:42:51,213 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hae4tc/ at 1733805771.213311
2024-12-09 23:42:51,213 [DEBUG] Data: None
2024-12-09 23:42:51,213 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:42:51,455 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hae4tc/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3188
2024-12-09 23:42:51,457 [DEBUG] Response: 200 (3188 bytes) (rst-428:rem-988.0:used-12 ratelimit) at 1733805771.45728
2024-12-09 23:42:51,459 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1ha9il4/ at 1733805771.459326
2024-12-09 23:42:51,459 [DEBUG] Data: None
2024-12-09 23:42:51,459 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:42:51,678 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1ha9il4/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2894
2024-12-09 23:42:51,679 [DEBUG] Response: 200 (2894 bytes) (rst-428:rem-987.0:used-13 ratelimit) at 1733805771.6797922
2024-12-09 23:42:51,681 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9vjwq/ at 1733805771.6813061
2024-12-09 23:42:51,681 [DEBUG] Data: None
2024-12-09 23:42:51,681 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:42:51,909 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9vjwq/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3408
2024-12-09 23:42:51,910 [DEBUG] Response: 200 (3408 bytes) (rst-428:rem-986.0:used-14 ratelimit) at 1733805771.910948
2024-12-09 23:42:51,912 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9v7dz/ at 1733805771.912642
2024-12-09 23:42:51,912 [DEBUG] Data: None
2024-12-09 23:42:51,912 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:42:52,126 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9v7dz/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2603
2024-12-09 23:42:52,128 [DEBUG] Response: 200 (2603 bytes) (rst-427:rem-985.0:used-15 ratelimit) at 1733805772.12834
2024-12-09 23:42:52,130 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9omov/ at 1733805772.130259
2024-12-09 23:42:52,130 [DEBUG] Data: None
2024-12-09 23:42:52,130 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:42:52,346 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9omov/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4229
2024-12-09 23:42:52,348 [DEBUG] Response: 200 (4229 bytes) (rst-427:rem-984.0:used-16 ratelimit) at 1733805772.3482711
2024-12-09 23:42:52,349 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9fg8c/ at 1733805772.3496761
2024-12-09 23:42:52,349 [DEBUG] Data: None
2024-12-09 23:42:52,349 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:42:52,598 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9fg8c/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6631
2024-12-09 23:42:52,599 [DEBUG] Response: 200 (6631 bytes) (rst-427:rem-983.0:used-17 ratelimit) at 1733805772.5997388
2024-12-09 23:42:52,602 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h93w33/ at 1733805772.6024299
2024-12-09 23:42:52,602 [DEBUG] Data: None
2024-12-09 23:42:52,602 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:42:52,974 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h93w33/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 5247
2024-12-09 23:42:52,976 [DEBUG] Response: 200 (5247 bytes) (rst-427:rem-982.0:used-18 ratelimit) at 1733805772.976397
2024-12-09 23:42:52,979 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h8p7ym/ at 1733805772.979136
2024-12-09 23:42:52,979 [DEBUG] Data: None
2024-12-09 23:42:52,979 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-09 23:42:53,247 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h8p7ym/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7120
2024-12-09 23:42:53,249 [DEBUG] Response: 200 (7120 bytes) (rst-426:rem-981.0:used-19 ratelimit) at 1733805773.2495182
2024-12-09 23:42:53,252 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733805773.252785
2024-12-09 23:42:53,252 [DEBUG] Data: None
2024-12-09 23:42:53,253 [DEBUG] Params: {'after': 't3_1h3s6y6', 'limit': 200, 'raw_json': 1}
2024-12-09 23:42:54,303 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h3s6y6&raw_json=1 HTTP/11" 200 51711
2024-12-09 23:42:54,306 [DEBUG] Response: 200 (51711 bytes) (rst-426:rem-980.0:used-20 ratelimit) at 1733805774.306784
2024-12-09 23:42:54,319 [INFO] Fetched 8 posts after filtering.
2024-12-09 23:42:54,331 [ERROR] Error filtering posts with GPT-3.5.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 114, in filter_good_posts_with_gpt35
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/lib/_old_api.py", line 39, in __call__
    raise APIRemovedInV1(symbol=self._symbol)
openai.lib._old_api.APIRemovedInV1: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-09 23:42:54,333 [ERROR] Error in run_script
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 114, in filter_good_posts_with_gpt35
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/lib/_old_api.py", line 39, in __call__
    raise APIRemovedInV1(symbol=self._symbol)
openai.lib._old_api.APIRemovedInV1: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 188, in run_script
    good_posts = filter_good_posts_with_gpt35(posts)
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 130, in filter_good_posts_with_gpt35
    raise RuntimeError(f"Error filtering posts with GPT-3.5: {e}")
RuntimeError: Error filtering posts with GPT-3.5: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-10 20:55:42,532 [ERROR] An unexpected error occurred in the main GUI loop.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 162, in <module>
    root = create_gui()
           ^^^^^^^^^^
NameError: name 'create_gui' is not defined
2024-12-10 21:01:05,089 [DEBUG] Starting new HTTPS connection (1): pypi.org:443
2024-12-10 21:01:05,179 [DEBUG] https://pypi.org:443 "GET /pypi/praw/json HTTP/11" 200 36290
2024-12-10 21:01:05,191 [INFO] Successfully connected to the Reddit API.
2024-12-10 21:01:05,192 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733882465.192451
2024-12-10 21:01:05,192 [DEBUG] Data: None
2024-12-10 21:01:05,192 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-10 21:01:05,193 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-10 21:01:05,725 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 656
2024-12-10 21:01:05,727 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-10 21:01:06,950 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 51596
2024-12-10 21:01:07,090 [DEBUG] Response: 200 (51596 bytes) (rst-534:rem-999.0:used-1 ratelimit) at 1733882467.090763
2024-12-10 21:01:07,103 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbej76/ at 1733882467.103761
2024-12-10 21:01:07,103 [DEBUG] Data: None
2024-12-10 21:01:07,104 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:01:07,352 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbej76/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3745
2024-12-10 21:01:07,354 [DEBUG] Response: 200 (3745 bytes) (rst-532:rem-998.0:used-2 ratelimit) at 1733882467.354164
2024-12-10 21:01:07,356 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbam3w/ at 1733882467.356151
2024-12-10 21:01:07,356 [DEBUG] Data: None
2024-12-10 21:01:07,357 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:01:07,608 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbam3w/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3487
2024-12-10 21:01:07,609 [DEBUG] Response: 200 (3487 bytes) (rst-532:rem-997.0:used-3 ratelimit) at 1733882467.6095328
2024-12-10 21:01:07,611 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hb3wd9/ at 1733882467.611068
2024-12-10 21:01:07,611 [DEBUG] Data: None
2024-12-10 21:01:07,611 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:01:07,906 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hb3wd9/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3655
2024-12-10 21:01:07,908 [DEBUG] Response: 200 (3655 bytes) (rst-532:rem-996.0:used-4 ratelimit) at 1733882467.908187
2024-12-10 21:01:07,908 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hazjmj/ at 1733882467.908871
2024-12-10 21:01:07,908 [DEBUG] Data: None
2024-12-10 21:01:07,908 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:01:08,245 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hazjmj/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3102
2024-12-10 21:01:08,247 [DEBUG] Response: 200 (3102 bytes) (rst-531:rem-995.0:used-5 ratelimit) at 1733882468.247828
2024-12-10 21:01:08,248 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1harj8o/ at 1733882468.248533
2024-12-10 21:01:08,248 [DEBUG] Data: None
2024-12-10 21:01:08,248 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:01:08,695 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1harj8o/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 8684
2024-12-10 21:01:08,695 [DEBUG] Response: 200 (8684 bytes) (rst-531:rem-994.0:used-6 ratelimit) at 1733882468.695842
2024-12-10 21:01:08,697 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1haooje/ at 1733882468.697721
2024-12-10 21:01:08,697 [DEBUG] Data: None
2024-12-10 21:01:08,697 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:01:09,205 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1haooje/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2624
2024-12-10 21:01:09,206 [DEBUG] Response: 200 (2624 bytes) (rst-531:rem-993.0:used-7 ratelimit) at 1733882469.206076
2024-12-10 21:01:09,206 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hae4tc/ at 1733882469.206506
2024-12-10 21:01:09,206 [DEBUG] Data: None
2024-12-10 21:01:09,206 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:01:09,481 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hae4tc/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4999
2024-12-10 21:01:09,484 [DEBUG] Response: 200 (4999 bytes) (rst-530:rem-992.0:used-8 ratelimit) at 1733882469.484673
2024-12-10 21:01:09,487 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1ha9il4/ at 1733882469.4871528
2024-12-10 21:01:09,487 [DEBUG] Data: None
2024-12-10 21:01:09,487 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:01:09,923 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1ha9il4/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3799
2024-12-10 21:01:09,924 [DEBUG] Response: 200 (3799 bytes) (rst-530:rem-991.0:used-9 ratelimit) at 1733882469.9247181
2024-12-10 21:01:09,926 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9vjwq/ at 1733882469.926177
2024-12-10 21:01:09,926 [DEBUG] Data: None
2024-12-10 21:01:09,926 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:01:10,334 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9vjwq/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4200
2024-12-10 21:01:10,335 [DEBUG] Response: 200 (4200 bytes) (rst-529:rem-990.0:used-10 ratelimit) at 1733882470.335777
2024-12-10 21:01:10,337 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9omov/ at 1733882470.3378718
2024-12-10 21:01:10,337 [DEBUG] Data: None
2024-12-10 21:01:10,337 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:01:10,744 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9omov/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4231
2024-12-10 21:01:10,746 [DEBUG] Response: 200 (4231 bytes) (rst-529:rem-989.0:used-11 ratelimit) at 1733882470.7460191
2024-12-10 21:01:10,747 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9fg8c/ at 1733882470.7472708
2024-12-10 21:01:10,747 [DEBUG] Data: None
2024-12-10 21:01:10,747 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:01:11,154 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9fg8c/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6812
2024-12-10 21:01:11,154 [DEBUG] Response: 200 (6812 bytes) (rst-529:rem-988.0:used-12 ratelimit) at 1733882471.154832
2024-12-10 21:01:11,155 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733882471.155989
2024-12-10 21:01:11,156 [DEBUG] Data: None
2024-12-10 21:01:11,156 [DEBUG] Params: {'after': 't3_1h55mng', 'limit': 200, 'raw_json': 1}
2024-12-10 21:01:12,383 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h55mng&raw_json=1 HTTP/11" 200 50949
2024-12-10 21:01:12,708 [DEBUG] Response: 200 (50949 bytes) (rst-528:rem-987.0:used-13 ratelimit) at 1733882472.708129
2024-12-10 21:01:12,720 [INFO] Fetched and filtered 11 posts.
2024-12-10 21:01:12,720 [ERROR] Error filtering posts with GPT-3.5.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 114, in filter_posts_with_gpt
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/lib/_old_api.py", line 39, in __call__
    raise APIRemovedInV1(symbol=self._symbol)
openai.lib._old_api.APIRemovedInV1: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-10 21:01:12,723 [ERROR] Error in script execution.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 114, in filter_posts_with_gpt
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/lib/_old_api.py", line 39, in __call__
    raise APIRemovedInV1(symbol=self._symbol)
openai.lib._old_api.APIRemovedInV1: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 226, in run_script
    good_posts = filter_posts_with_gpt(posts)
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 129, in filter_posts_with_gpt
    raise RuntimeError(f"Error filtering posts with GPT-3.5: {e}")
RuntimeError: Error filtering posts with GPT-3.5: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-10 21:06:55,666 [INFO] Successfully connected to the Reddit API.
2024-12-10 21:06:55,667 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733882815.66705
2024-12-10 21:06:55,667 [DEBUG] Data: None
2024-12-10 21:06:55,667 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-10 21:06:55,670 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-10 21:06:55,848 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 656
2024-12-10 21:06:55,852 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-10 21:06:57,349 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 51601
2024-12-10 21:06:57,577 [DEBUG] Response: 200 (51601 bytes) (rst-184:rem-986.0:used-14 ratelimit) at 1733882817.5776188
2024-12-10 21:06:57,585 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbej76/ at 1733882817.5853581
2024-12-10 21:06:57,585 [DEBUG] Data: None
2024-12-10 21:06:57,585 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:06:57,981 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbej76/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3737
2024-12-10 21:06:57,982 [DEBUG] Response: 200 (3737 bytes) (rst-182:rem-985.0:used-15 ratelimit) at 1733882817.982956
2024-12-10 21:06:57,985 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbam3w/ at 1733882817.985564
2024-12-10 21:06:57,985 [DEBUG] Data: None
2024-12-10 21:06:57,985 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:06:58,389 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbam3w/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3487
2024-12-10 21:06:58,390 [DEBUG] Response: 200 (3487 bytes) (rst-181:rem-984.0:used-16 ratelimit) at 1733882818.390765
2024-12-10 21:06:58,392 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hb3wd9/ at 1733882818.391996
2024-12-10 21:06:58,392 [DEBUG] Data: None
2024-12-10 21:06:58,392 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:06:58,725 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hb3wd9/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3654
2024-12-10 21:06:58,726 [DEBUG] Response: 200 (3654 bytes) (rst-181:rem-983.0:used-17 ratelimit) at 1733882818.726681
2024-12-10 21:06:58,728 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hazjmj/ at 1733882818.728223
2024-12-10 21:06:58,728 [DEBUG] Data: None
2024-12-10 21:06:58,728 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:06:59,106 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hazjmj/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3104
2024-12-10 21:06:59,106 [DEBUG] Response: 200 (3104 bytes) (rst-181:rem-982.0:used-18 ratelimit) at 1733882819.106786
2024-12-10 21:06:59,107 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1harj8o/ at 1733882819.107737
2024-12-10 21:06:59,107 [DEBUG] Data: None
2024-12-10 21:06:59,107 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:06:59,516 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1harj8o/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 8677
2024-12-10 21:06:59,517 [DEBUG] Response: 200 (8677 bytes) (rst-180:rem-981.0:used-19 ratelimit) at 1733882819.517969
2024-12-10 21:06:59,519 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hae4tc/ at 1733882819.519975
2024-12-10 21:06:59,520 [DEBUG] Data: None
2024-12-10 21:06:59,520 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:06:59,927 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hae4tc/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4999
2024-12-10 21:06:59,929 [DEBUG] Response: 200 (4999 bytes) (rst-180:rem-980.0:used-20 ratelimit) at 1733882819.9291031
2024-12-10 21:06:59,931 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1ha9il4/ at 1733882819.931595
2024-12-10 21:06:59,931 [DEBUG] Data: None
2024-12-10 21:06:59,931 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:07:00,439 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1ha9il4/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3798
2024-12-10 21:07:00,441 [DEBUG] Response: 200 (3798 bytes) (rst-180:rem-979.0:used-21 ratelimit) at 1733882820.4411361
2024-12-10 21:07:00,442 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9vjwq/ at 1733882820.442244
2024-12-10 21:07:00,442 [DEBUG] Data: None
2024-12-10 21:07:00,442 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:07:00,848 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9vjwq/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4200
2024-12-10 21:07:00,849 [DEBUG] Response: 200 (4200 bytes) (rst-179:rem-978.0:used-22 ratelimit) at 1733882820.8493729
2024-12-10 21:07:00,852 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9omov/ at 1733882820.8523278
2024-12-10 21:07:00,852 [DEBUG] Data: None
2024-12-10 21:07:00,853 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:07:01,260 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9omov/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4230
2024-12-10 21:07:01,261 [DEBUG] Response: 200 (4230 bytes) (rst-179:rem-977.0:used-23 ratelimit) at 1733882821.261472
2024-12-10 21:07:01,262 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9fg8c/ at 1733882821.262686
2024-12-10 21:07:01,262 [DEBUG] Data: None
2024-12-10 21:07:01,262 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:07:02,488 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9fg8c/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6811
2024-12-10 21:07:02,489 [DEBUG] Response: 200 (6811 bytes) (rst-178:rem-976.0:used-24 ratelimit) at 1733882822.489868
2024-12-10 21:07:02,492 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733882822.492353
2024-12-10 21:07:02,492 [DEBUG] Data: None
2024-12-10 21:07:02,492 [DEBUG] Params: {'after': 't3_1h55mng', 'limit': 200, 'raw_json': 1}
2024-12-10 21:07:03,407 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h55mng&raw_json=1 HTTP/11" 200 50933
2024-12-10 21:07:03,571 [DEBUG] Response: 200 (50933 bytes) (rst-177:rem-975.0:used-25 ratelimit) at 1733882823.5717702
2024-12-10 21:07:03,585 [INFO] Fetched and filtered 10 posts.
2024-12-10 21:07:03,594 [ERROR] Error filtering posts with GPT-3.5.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 114, in filter_posts_with_gpt
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/lib/_old_api.py", line 39, in __call__
    raise APIRemovedInV1(symbol=self._symbol)
openai.lib._old_api.APIRemovedInV1: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-10 21:07:03,596 [ERROR] Error in script execution.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 114, in filter_posts_with_gpt
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/lib/_old_api.py", line 39, in __call__
    raise APIRemovedInV1(symbol=self._symbol)
openai.lib._old_api.APIRemovedInV1: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 227, in run_script
    good_posts = filter_posts_with_gpt(posts)
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 129, in filter_posts_with_gpt
    raise RuntimeError(f"Error filtering posts with GPT-3.5: {e}")
RuntimeError: Error filtering posts with GPT-3.5: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-10 21:18:53,429 [INFO] Successfully connected to the Reddit API.
2024-12-10 21:18:53,430 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733883533.4300852
2024-12-10 21:18:53,430 [DEBUG] Data: None
2024-12-10 21:18:53,430 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-10 21:18:53,432 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-10 21:18:53,750 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 652
2024-12-10 21:18:53,753 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-10 21:18:54,984 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 51620
2024-12-10 21:18:55,058 [DEBUG] Response: 200 (51620 bytes) (rst-65:rem-999.0:used-1 ratelimit) at 1733883535.058859
2024-12-10 21:18:55,068 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbej76/ at 1733883535.068109
2024-12-10 21:18:55,068 [DEBUG] Data: None
2024-12-10 21:18:55,068 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:18:55,336 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbej76/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3737
2024-12-10 21:18:55,337 [DEBUG] Response: 200 (3737 bytes) (rst-64:rem-998.0:used-2 ratelimit) at 1733883535.33725
2024-12-10 21:18:55,339 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbam3w/ at 1733883535.339644
2024-12-10 21:18:55,339 [DEBUG] Data: None
2024-12-10 21:18:55,339 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:18:55,589 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbam3w/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3487
2024-12-10 21:18:55,592 [DEBUG] Response: 200 (3487 bytes) (rst-64:rem-997.0:used-3 ratelimit) at 1733883535.5920808
2024-12-10 21:18:55,594 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hb3wd9/ at 1733883535.594342
2024-12-10 21:18:55,594 [DEBUG] Data: None
2024-12-10 21:18:55,594 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:18:55,856 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hb3wd9/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3656
2024-12-10 21:18:55,857 [DEBUG] Response: 200 (3656 bytes) (rst-64:rem-996.0:used-4 ratelimit) at 1733883535.857954
2024-12-10 21:18:55,860 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hazjmj/ at 1733883535.8603241
2024-12-10 21:18:55,860 [DEBUG] Data: None
2024-12-10 21:18:55,860 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:18:56,098 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hazjmj/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3103
2024-12-10 21:18:56,098 [DEBUG] Response: 200 (3103 bytes) (rst-64:rem-995.0:used-5 ratelimit) at 1733883536.098956
2024-12-10 21:18:56,099 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1harj8o/ at 1733883536.0999339
2024-12-10 21:18:56,100 [DEBUG] Data: None
2024-12-10 21:18:56,100 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:18:56,515 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1harj8o/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 8680
2024-12-10 21:18:56,516 [DEBUG] Response: 200 (8680 bytes) (rst-63:rem-994.0:used-6 ratelimit) at 1733883536.516513
2024-12-10 21:18:56,519 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1haooje/ at 1733883536.519514
2024-12-10 21:18:56,519 [DEBUG] Data: None
2024-12-10 21:18:56,519 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:18:56,769 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1haooje/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2621
2024-12-10 21:18:56,770 [DEBUG] Response: 200 (2621 bytes) (rst-63:rem-993.0:used-7 ratelimit) at 1733883536.770638
2024-12-10 21:18:56,771 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hae4tc/ at 1733883536.7717981
2024-12-10 21:18:56,771 [DEBUG] Data: None
2024-12-10 21:18:56,771 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:18:57,037 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hae4tc/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4996
2024-12-10 21:18:57,038 [DEBUG] Response: 200 (4996 bytes) (rst-63:rem-992.0:used-8 ratelimit) at 1733883537.038465
2024-12-10 21:18:57,041 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1ha9il4/ at 1733883537.041724
2024-12-10 21:18:57,041 [DEBUG] Data: None
2024-12-10 21:18:57,041 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:18:57,281 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1ha9il4/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3799
2024-12-10 21:18:57,438 [DEBUG] Response: 200 (3799 bytes) (rst-62:rem-991.0:used-9 ratelimit) at 1733883537.438797
2024-12-10 21:18:57,440 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9vjwq/ at 1733883537.440911
2024-12-10 21:18:57,441 [DEBUG] Data: None
2024-12-10 21:18:57,441 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:18:57,714 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9vjwq/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4200
2024-12-10 21:18:57,716 [DEBUG] Response: 200 (4200 bytes) (rst-62:rem-990.0:used-10 ratelimit) at 1733883537.716476
2024-12-10 21:18:57,719 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9omov/ at 1733883537.71927
2024-12-10 21:18:57,719 [DEBUG] Data: None
2024-12-10 21:18:57,719 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:18:57,956 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9omov/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4229
2024-12-10 21:18:57,958 [DEBUG] Response: 200 (4229 bytes) (rst-62:rem-989.0:used-11 ratelimit) at 1733883537.9584289
2024-12-10 21:18:57,960 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9fg8c/ at 1733883537.9601011
2024-12-10 21:18:57,960 [DEBUG] Data: None
2024-12-10 21:18:57,960 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:18:58,208 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9fg8c/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6812
2024-12-10 21:18:58,210 [DEBUG] Response: 200 (6812 bytes) (rst-61:rem-988.0:used-12 ratelimit) at 1733883538.210007
2024-12-10 21:18:58,212 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733883538.2128682
2024-12-10 21:18:58,213 [DEBUG] Data: None
2024-12-10 21:18:58,213 [DEBUG] Params: {'after': 't3_1h55mng', 'limit': 200, 'raw_json': 1}
2024-12-10 21:18:59,445 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h55mng&raw_json=1 HTTP/11" 200 50977
2024-12-10 21:18:59,521 [DEBUG] Response: 200 (50977 bytes) (rst-61:rem-987.0:used-13 ratelimit) at 1733883539.5214999
2024-12-10 21:18:59,533 [INFO] Fetched and filtered 11 posts.
2024-12-10 21:18:59,567 [ERROR] Error filtering posts with GPT-3.5.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 114, in filter_posts_with_gpt
    response = openai.chat.create(
               ^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_utils/_proxy.py", line 23, in __getattr__
    return getattr(proxied, attr)
AttributeError: 'Chat' object has no attribute 'create'
2024-12-10 21:18:59,568 [ERROR] Error in script execution.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 114, in filter_posts_with_gpt
    response = openai.chat.create(
               ^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_utils/_proxy.py", line 23, in __getattr__
    return getattr(proxied, attr)
AttributeError: 'Chat' object has no attribute 'create'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 227, in run_script
    good_posts = filter_posts_with_gpt(posts)
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 129, in filter_posts_with_gpt
    raise RuntimeError(f"Error filtering posts with GPT-3.5: {e}")
RuntimeError: Error filtering posts with GPT-3.5: 'Chat' object has no attribute 'create'
2024-12-10 21:24:34,542 [INFO] Successfully connected to the Reddit API.
2024-12-10 21:24:34,543 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733883874.543204
2024-12-10 21:24:34,543 [DEBUG] Data: None
2024-12-10 21:24:34,543 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-10 21:24:34,546 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-10 21:24:35,655 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 654
2024-12-10 21:24:35,659 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-10 21:24:36,895 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 51639
2024-12-10 21:24:36,975 [DEBUG] Response: 200 (51639 bytes) (rst-324:rem-999.0:used-1 ratelimit) at 1733883876.9757628
2024-12-10 21:24:36,987 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbej76/ at 1733883876.987443
2024-12-10 21:24:36,987 [DEBUG] Data: None
2024-12-10 21:24:36,987 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:24:37,402 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbej76/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3745
2024-12-10 21:24:37,404 [DEBUG] Response: 200 (3745 bytes) (rst-322:rem-998.0:used-2 ratelimit) at 1733883877.404062
2024-12-10 21:24:37,406 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbam3w/ at 1733883877.406708
2024-12-10 21:24:37,406 [DEBUG] Data: None
2024-12-10 21:24:37,406 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:24:37,813 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbam3w/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3485
2024-12-10 21:24:37,814 [DEBUG] Response: 200 (3485 bytes) (rst-322:rem-997.0:used-3 ratelimit) at 1733883877.814446
2024-12-10 21:24:37,816 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hb3wd9/ at 1733883877.816637
2024-12-10 21:24:37,816 [DEBUG] Data: None
2024-12-10 21:24:37,816 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:24:38,223 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hb3wd9/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3665
2024-12-10 21:24:38,224 [DEBUG] Response: 200 (3665 bytes) (rst-322:rem-996.0:used-4 ratelimit) at 1733883878.2246988
2024-12-10 21:24:38,227 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hazjmj/ at 1733883878.227467
2024-12-10 21:24:38,227 [DEBUG] Data: None
2024-12-10 21:24:38,227 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:24:38,634 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hazjmj/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3109
2024-12-10 21:24:38,636 [DEBUG] Response: 200 (3109 bytes) (rst-321:rem-995.0:used-5 ratelimit) at 1733883878.6360261
2024-12-10 21:24:38,637 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1harj8o/ at 1733883878.637769
2024-12-10 21:24:38,637 [DEBUG] Data: None
2024-12-10 21:24:38,637 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:24:39,246 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1harj8o/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 8680
2024-12-10 21:24:39,247 [DEBUG] Response: 200 (8680 bytes) (rst-321:rem-994.0:used-6 ratelimit) at 1733883879.2477372
2024-12-10 21:24:39,251 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hae4tc/ at 1733883879.251044
2024-12-10 21:24:39,251 [DEBUG] Data: None
2024-12-10 21:24:39,251 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:24:39,555 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hae4tc/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4999
2024-12-10 21:24:39,555 [DEBUG] Response: 200 (4999 bytes) (rst-320:rem-993.0:used-7 ratelimit) at 1733883879.555817
2024-12-10 21:24:39,558 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1ha9il4/ at 1733883879.558582
2024-12-10 21:24:39,558 [DEBUG] Data: None
2024-12-10 21:24:39,558 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:24:39,862 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1ha9il4/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3798
2024-12-10 21:24:39,863 [DEBUG] Response: 200 (3798 bytes) (rst-320:rem-992.0:used-8 ratelimit) at 1733883879.863261
2024-12-10 21:24:39,864 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9vjwq/ at 1733883879.8647628
2024-12-10 21:24:39,864 [DEBUG] Data: None
2024-12-10 21:24:39,864 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:24:40,291 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9vjwq/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4198
2024-12-10 21:24:40,292 [DEBUG] Response: 200 (4198 bytes) (rst-320:rem-991.0:used-9 ratelimit) at 1733883880.292479
2024-12-10 21:24:40,294 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9omov/ at 1733883880.294344
2024-12-10 21:24:40,294 [DEBUG] Data: None
2024-12-10 21:24:40,294 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:24:40,579 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9omov/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4231
2024-12-10 21:24:40,580 [DEBUG] Response: 200 (4231 bytes) (rst-319:rem-990.0:used-10 ratelimit) at 1733883880.580551
2024-12-10 21:24:40,582 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9fg8c/ at 1733883880.582158
2024-12-10 21:24:40,582 [DEBUG] Data: None
2024-12-10 21:24:40,582 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:24:40,987 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9fg8c/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6812
2024-12-10 21:24:40,988 [DEBUG] Response: 200 (6812 bytes) (rst-319:rem-989.0:used-11 ratelimit) at 1733883880.988516
2024-12-10 21:24:40,991 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733883880.991144
2024-12-10 21:24:40,991 [DEBUG] Data: None
2024-12-10 21:24:40,991 [DEBUG] Params: {'after': 't3_1h55mng', 'limit': 200, 'raw_json': 1}
2024-12-10 21:24:42,319 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h55mng&raw_json=1 HTTP/11" 200 50937
2024-12-10 21:24:42,502 [DEBUG] Response: 200 (50937 bytes) (rst-318:rem-988.0:used-12 ratelimit) at 1733883882.502246
2024-12-10 21:24:42,515 [INFO] Fetched and filtered 10 posts.
2024-12-10 21:24:42,524 [ERROR] Error in script execution.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 231, in run_script
    good_posts = filter_posts_with_gpt(posts)
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 103, in filter_posts_with_gpt
    posts_summary = "".join(summarize_post_for_gpt(p) for p in posts)
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 103, in <genexpr>
    posts_summary = "".join(summarize_post_for_gpt(p) for p in posts)
                            ^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'summarize_post_for_gpt' is not defined
2024-12-10 21:29:48,477 [INFO] Successfully connected to the Reddit API.
2024-12-10 21:29:48,478 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733884188.478265
2024-12-10 21:29:48,478 [DEBUG] Data: None
2024-12-10 21:29:48,478 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-10 21:29:48,481 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-10 21:29:48,920 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 652
2024-12-10 21:29:48,923 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-10 21:29:50,059 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 51584
2024-12-10 21:29:50,225 [DEBUG] Response: 200 (51584 bytes) (rst-10:rem-987.0:used-13 ratelimit) at 1733884190.225695
2024-12-10 21:29:50,237 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbam3w/ at 1733884190.2378602
2024-12-10 21:29:50,238 [DEBUG] Data: None
2024-12-10 21:29:50,238 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:29:50,561 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbam3w/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3487
2024-12-10 21:29:50,561 [DEBUG] Response: 200 (3487 bytes) (rst-9:rem-986.0:used-14 ratelimit) at 1733884190.561592
2024-12-10 21:29:50,562 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hb3wd9/ at 1733884190.562266
2024-12-10 21:29:50,562 [DEBUG] Data: None
2024-12-10 21:29:50,562 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:29:50,869 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hb3wd9/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3666
2024-12-10 21:29:50,870 [DEBUG] Response: 200 (3666 bytes) (rst-9:rem-985.0:used-15 ratelimit) at 1733884190.870095
2024-12-10 21:29:50,871 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hazjmj/ at 1733884190.871546
2024-12-10 21:29:50,871 [DEBUG] Data: None
2024-12-10 21:29:50,871 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:29:51,154 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hazjmj/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3106
2024-12-10 21:29:51,155 [DEBUG] Response: 200 (3106 bytes) (rst-9:rem-984.0:used-16 ratelimit) at 1733884191.1553018
2024-12-10 21:29:51,156 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1harj8o/ at 1733884191.15636
2024-12-10 21:29:51,156 [DEBUG] Data: None
2024-12-10 21:29:51,156 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:29:51,582 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1harj8o/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 8680
2024-12-10 21:29:51,609 [DEBUG] Response: 200 (8680 bytes) (rst-8:rem-983.0:used-17 ratelimit) at 1733884191.6090791
2024-12-10 21:29:51,611 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hae4tc/ at 1733884191.611627
2024-12-10 21:29:51,611 [DEBUG] Data: None
2024-12-10 21:29:51,611 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:29:51,993 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hae4tc/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4996
2024-12-10 21:29:51,995 [DEBUG] Response: 200 (4996 bytes) (rst-8:rem-982.0:used-18 ratelimit) at 1733884191.995029
2024-12-10 21:29:51,997 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1ha9il4/ at 1733884191.997531
2024-12-10 21:29:51,997 [DEBUG] Data: None
2024-12-10 21:29:51,997 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:29:52,504 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1ha9il4/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3798
2024-12-10 21:29:52,505 [DEBUG] Response: 200 (3798 bytes) (rst-7:rem-981.0:used-19 ratelimit) at 1733884192.505054
2024-12-10 21:29:52,506 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9vjwq/ at 1733884192.5064409
2024-12-10 21:29:52,506 [DEBUG] Data: None
2024-12-10 21:29:52,506 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:29:52,811 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9vjwq/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4195
2024-12-10 21:29:53,185 [DEBUG] Response: 200 (4195 bytes) (rst-7:rem-980.0:used-20 ratelimit) at 1733884193.185298
2024-12-10 21:29:53,188 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9v7dz/ at 1733884193.188737
2024-12-10 21:29:53,188 [DEBUG] Data: None
2024-12-10 21:29:53,188 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:29:53,529 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9v7dz/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2882
2024-12-10 21:29:53,530 [DEBUG] Response: 200 (2882 bytes) (rst-6:rem-979.0:used-21 ratelimit) at 1733884193.5301068
2024-12-10 21:29:53,531 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9omov/ at 1733884193.531501
2024-12-10 21:29:53,531 [DEBUG] Data: None
2024-12-10 21:29:53,531 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:29:53,692 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9omov/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4230
2024-12-10 21:29:53,703 [DEBUG] Response: 200 (4230 bytes) (rst-6:rem-978.0:used-22 ratelimit) at 1733884193.703344
2024-12-10 21:29:53,704 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9fg8c/ at 1733884193.704766
2024-12-10 21:29:53,704 [DEBUG] Data: None
2024-12-10 21:29:53,704 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:29:54,041 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9fg8c/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6812
2024-12-10 21:29:54,043 [DEBUG] Response: 200 (6812 bytes) (rst-6:rem-977.0:used-23 ratelimit) at 1733884194.043029
2024-12-10 21:29:54,045 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733884194.0454772
2024-12-10 21:29:54,045 [DEBUG] Data: None
2024-12-10 21:29:54,045 [DEBUG] Params: {'after': 't3_1h55mng', 'limit': 200, 'raw_json': 1}
2024-12-10 21:29:55,060 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h55mng&raw_json=1 HTTP/11" 200 50902
2024-12-10 21:29:55,204 [DEBUG] Response: 200 (50902 bytes) (rst-5:rem-976.0:used-24 ratelimit) at 1733884195.2047071
2024-12-10 21:29:55,215 [INFO] Fetched and filtered 10 posts.
2024-12-10 21:29:55,229 [ERROR] Error filtering posts with GPT-3.5.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 127, in filter_posts_with_gpt
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/lib/_old_api.py", line 39, in __call__
    raise APIRemovedInV1(symbol=self._symbol)
openai.lib._old_api.APIRemovedInV1: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-10 21:29:55,230 [ERROR] Error in script execution.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 127, in filter_posts_with_gpt
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/lib/_old_api.py", line 39, in __call__
    raise APIRemovedInV1(symbol=self._symbol)
openai.lib._old_api.APIRemovedInV1: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 260, in run_script
    good_posts = filter_posts_with_gpt(posts)
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 144, in filter_posts_with_gpt
    raise RuntimeError(f"Error filtering posts with GPT-3.5: {e}")
RuntimeError: Error filtering posts with GPT-3.5: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-10 21:46:48,030 [INFO] Successfully connected to the Reddit API.
2024-12-10 21:46:48,031 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733885208.031669
2024-12-10 21:46:48,031 [DEBUG] Data: None
2024-12-10 21:46:48,031 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-10 21:46:48,034 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-10 21:46:48,929 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 653
2024-12-10 21:46:48,932 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-10 21:46:50,569 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 51586
2024-12-10 21:46:50,874 [DEBUG] Response: 200 (51586 bytes) (rst-190:rem-999.0:used-1 ratelimit) at 1733885210.874937
2024-12-10 21:46:50,886 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbej76/ at 1733885210.886812
2024-12-10 21:46:50,886 [DEBUG] Data: None
2024-12-10 21:46:50,887 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:46:51,385 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbej76/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4385
2024-12-10 21:46:51,386 [DEBUG] Response: 200 (4385 bytes) (rst-189:rem-998.0:used-2 ratelimit) at 1733885211.386742
2024-12-10 21:46:51,389 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbam3w/ at 1733885211.38942
2024-12-10 21:46:51,389 [DEBUG] Data: None
2024-12-10 21:46:51,389 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:46:51,798 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbam3w/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3484
2024-12-10 21:46:51,800 [DEBUG] Response: 200 (3484 bytes) (rst-188:rem-997.0:used-3 ratelimit) at 1733885211.800368
2024-12-10 21:46:51,802 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hb3wd9/ at 1733885211.802351
2024-12-10 21:46:51,802 [DEBUG] Data: None
2024-12-10 21:46:51,802 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:46:52,453 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hb3wd9/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3657
2024-12-10 21:46:52,455 [DEBUG] Response: 200 (3657 bytes) (rst-188:rem-996.0:used-4 ratelimit) at 1733885212.4555871
2024-12-10 21:46:52,458 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hazjmj/ at 1733885212.458496
2024-12-10 21:46:52,458 [DEBUG] Data: None
2024-12-10 21:46:52,458 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:46:52,910 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hazjmj/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3109
2024-12-10 21:46:52,910 [DEBUG] Response: 200 (3109 bytes) (rst-187:rem-995.0:used-5 ratelimit) at 1733885212.910784
2024-12-10 21:46:52,911 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1harj8o/ at 1733885212.911938
2024-12-10 21:46:52,912 [DEBUG] Data: None
2024-12-10 21:46:52,912 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:46:53,330 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1harj8o/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 8681
2024-12-10 21:46:53,332 [DEBUG] Response: 200 (8681 bytes) (rst-187:rem-994.0:used-6 ratelimit) at 1733885213.332333
2024-12-10 21:46:53,335 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hae4tc/ at 1733885213.335684
2024-12-10 21:46:53,335 [DEBUG] Data: None
2024-12-10 21:46:53,335 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:46:53,849 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hae4tc/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4996
2024-12-10 21:46:53,850 [DEBUG] Response: 200 (4996 bytes) (rst-186:rem-993.0:used-7 ratelimit) at 1733885213.850566
2024-12-10 21:46:53,854 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1ha9il4/ at 1733885213.854481
2024-12-10 21:46:53,854 [DEBUG] Data: None
2024-12-10 21:46:53,854 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:46:54,130 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1ha9il4/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3798
2024-12-10 21:46:54,131 [DEBUG] Response: 200 (3798 bytes) (rst-186:rem-992.0:used-8 ratelimit) at 1733885214.131652
2024-12-10 21:46:54,134 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9vjwq/ at 1733885214.134261
2024-12-10 21:46:54,134 [DEBUG] Data: None
2024-12-10 21:46:54,134 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:46:54,563 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9vjwq/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4200
2024-12-10 21:46:54,564 [DEBUG] Response: 200 (4200 bytes) (rst-185:rem-991.0:used-9 ratelimit) at 1733885214.564534
2024-12-10 21:46:54,567 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9omov/ at 1733885214.567152
2024-12-10 21:46:54,567 [DEBUG] Data: None
2024-12-10 21:46:54,567 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:46:54,931 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9omov/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4231
2024-12-10 21:46:54,932 [DEBUG] Response: 200 (4231 bytes) (rst-185:rem-990.0:used-10 ratelimit) at 1733885214.932222
2024-12-10 21:46:54,932 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9fg8c/ at 1733885214.932991
2024-12-10 21:46:54,933 [DEBUG] Data: None
2024-12-10 21:46:54,933 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 21:46:55,379 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9fg8c/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6812
2024-12-10 21:46:55,381 [DEBUG] Response: 200 (6812 bytes) (rst-185:rem-989.0:used-11 ratelimit) at 1733885215.381126
2024-12-10 21:46:55,383 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733885215.383211
2024-12-10 21:46:55,383 [DEBUG] Data: None
2024-12-10 21:46:55,383 [DEBUG] Params: {'after': 't3_1h55mng', 'limit': 200, 'raw_json': 1}
2024-12-10 21:46:56,532 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h55mng&raw_json=1 HTTP/11" 200 50948
2024-12-10 21:46:56,778 [DEBUG] Response: 200 (50948 bytes) (rst-184:rem-988.0:used-12 ratelimit) at 1733885216.778669
2024-12-10 21:46:56,792 [INFO] Fetched and filtered 10 posts.
2024-12-10 21:46:56,810 [ERROR] Error in script execution.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 126, in filter_posts_with_gpt
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Users/chrisgaya/openai-python/venv/lib/python3.13/site-packages/openai/lib/_old_api.py", line 39, in __call__
    raise APIRemovedInV1(symbol=self._symbol)
openai.lib._old_api.APIRemovedInV1: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 271, in run_script
    good_posts = filter_posts_with_gpt(posts)
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 141, in filter_posts_with_gpt
    except openai.error.OpenAIError as e:
           ^^^^^^^^^^^^
AttributeError: module 'openai' has no attribute 'error'
2024-12-10 22:03:54,745 [DEBUG] Starting new HTTPS connection (1): pypi.org:443
2024-12-10 22:03:54,837 [DEBUG] https://pypi.org:443 "GET /pypi/praw/json HTTP/11" 200 36290
2024-12-10 22:03:54,854 [INFO] Successfully connected to the Reddit API.
2024-12-10 22:03:54,854 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733886234.854629
2024-12-10 22:03:54,854 [DEBUG] Data: None
2024-12-10 22:03:54,854 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-10 22:03:54,855 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-10 22:03:55,290 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 651
2024-12-10 22:03:55,292 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-10 22:03:57,068 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 51579
2024-12-10 22:03:57,470 [DEBUG] Response: 200 (51579 bytes) (rst-364:rem-999.0:used-1 ratelimit) at 1733886237.470457
2024-12-10 22:03:57,482 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbam3w/ at 1733886237.4825978
2024-12-10 22:03:57,482 [DEBUG] Data: None
2024-12-10 22:03:57,482 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:03:57,950 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbam3w/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3486
2024-12-10 22:03:57,951 [DEBUG] Response: 200 (3486 bytes) (rst-362:rem-998.0:used-2 ratelimit) at 1733886237.951467
2024-12-10 22:03:57,952 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hb3wd9/ at 1733886237.952478
2024-12-10 22:03:57,952 [DEBUG] Data: None
2024-12-10 22:03:57,952 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:03:58,360 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hb3wd9/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3669
2024-12-10 22:03:58,507 [DEBUG] Response: 200 (3669 bytes) (rst-361:rem-997.0:used-3 ratelimit) at 1733886238.507351
2024-12-10 22:03:58,510 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hazjmj/ at 1733886238.510619
2024-12-10 22:03:58,510 [DEBUG] Data: None
2024-12-10 22:03:58,510 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:03:58,974 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hazjmj/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3667
2024-12-10 22:03:58,976 [DEBUG] Response: 200 (3667 bytes) (rst-361:rem-996.0:used-4 ratelimit) at 1733886238.9761238
2024-12-10 22:03:58,978 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1harj8o/ at 1733886238.978248
2024-12-10 22:03:58,978 [DEBUG] Data: None
2024-12-10 22:03:58,978 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:03:59,589 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1harj8o/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 8682
2024-12-10 22:03:59,591 [DEBUG] Response: 200 (8682 bytes) (rst-360:rem-995.0:used-5 ratelimit) at 1733886239.5910022
2024-12-10 22:03:59,594 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hae4tc/ at 1733886239.594719
2024-12-10 22:03:59,594 [DEBUG] Data: None
2024-12-10 22:03:59,594 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:04:00,101 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hae4tc/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4996
2024-12-10 22:04:00,102 [DEBUG] Response: 200 (4996 bytes) (rst-360:rem-994.0:used-6 ratelimit) at 1733886240.102884
2024-12-10 22:04:00,106 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1ha9il4/ at 1733886240.106078
2024-12-10 22:04:00,106 [DEBUG] Data: None
2024-12-10 22:04:00,106 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:04:00,568 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1ha9il4/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3798
2024-12-10 22:04:00,569 [DEBUG] Response: 200 (3798 bytes) (rst-359:rem-993.0:used-7 ratelimit) at 1733886240.5699499
2024-12-10 22:04:00,572 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9vjwq/ at 1733886240.572004
2024-12-10 22:04:00,572 [DEBUG] Data: None
2024-12-10 22:04:00,572 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:04:01,124 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9vjwq/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4196
2024-12-10 22:04:01,125 [DEBUG] Response: 200 (4196 bytes) (rst-359:rem-992.0:used-8 ratelimit) at 1733886241.125855
2024-12-10 22:04:01,128 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9v7dz/ at 1733886241.128918
2024-12-10 22:04:01,129 [DEBUG] Data: None
2024-12-10 22:04:01,129 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:04:01,637 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9v7dz/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2882
2024-12-10 22:04:01,638 [DEBUG] Response: 200 (2882 bytes) (rst-358:rem-991.0:used-9 ratelimit) at 1733886241.6388779
2024-12-10 22:04:01,640 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9omov/ at 1733886241.640882
2024-12-10 22:04:01,640 [DEBUG] Data: None
2024-12-10 22:04:01,641 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:04:02,148 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9omov/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4229
2024-12-10 22:04:02,150 [DEBUG] Response: 200 (4229 bytes) (rst-358:rem-990.0:used-10 ratelimit) at 1733886242.150066
2024-12-10 22:04:02,151 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9fg8c/ at 1733886242.15172
2024-12-10 22:04:02,151 [DEBUG] Data: None
2024-12-10 22:04:02,151 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:04:02,683 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9fg8c/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6809
2024-12-10 22:04:02,684 [DEBUG] Response: 200 (6809 bytes) (rst-357:rem-989.0:used-11 ratelimit) at 1733886242.6845481
2024-12-10 22:04:02,686 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733886242.686579
2024-12-10 22:04:02,686 [DEBUG] Data: None
2024-12-10 22:04:02,686 [DEBUG] Params: {'after': 't3_1h55mng', 'limit': 200, 'raw_json': 1}
2024-12-10 22:04:03,993 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h55mng&raw_json=1 HTTP/11" 200 50942
2024-12-10 22:04:04,342 [DEBUG] Response: 200 (50942 bytes) (rst-357:rem-988.0:used-12 ratelimit) at 1733886244.3424509
2024-12-10 22:04:04,354 [INFO] Fetched and filtered 10 posts.
2024-12-10 22:04:04,366 [ERROR] Error in script execution.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 129, in filter_posts_with_gpt
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Users/chrisgaya/openai-python/venv/lib/python3.13/site-packages/openai/lib/_old_api.py", line 39, in __call__
    raise APIRemovedInV1(symbol=self._symbol)
openai.lib._old_api.APIRemovedInV1: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 258, in run_script
    good_posts = filter_posts_with_gpt(posts)
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 142, in filter_posts_with_gpt
    except openai.error.OpenAIError as e:
           ^^^^^^^^^^^^
AttributeError: module 'openai' has no attribute 'error'
2024-12-10 22:06:51,602 [INFO] Successfully connected to the Reddit API.
2024-12-10 22:06:51,603 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropshipping/new at 1733886411.603076
2024-12-10 22:06:51,603 [DEBUG] Data: None
2024-12-10 22:06:51,603 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-10 22:06:51,605 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-10 22:06:51,927 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 656
2024-12-10 22:06:51,930 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-10 22:06:54,285 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropshipping/new?limit=200&raw_json=1 HTTP/11" 200 53807
2024-12-10 22:06:54,373 [DEBUG] Response: 200 (53807 bytes) (rst-186:rem-987.0:used-13 ratelimit) at 1733886414.373695
2024-12-10 22:06:54,384 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbc1b1/ at 1733886414.384871
2024-12-10 22:06:54,385 [DEBUG] Data: None
2024-12-10 22:06:54,385 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:06:54,794 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbc1b1/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2159
2024-12-10 22:06:54,796 [DEBUG] Response: 200 (2159 bytes) (rst-185:rem-986.0:used-14 ratelimit) at 1733886414.796034
2024-12-10 22:06:54,796 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbatu4/ at 1733886414.79684
2024-12-10 22:06:54,796 [DEBUG] Data: None
2024-12-10 22:06:54,797 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:06:55,330 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbatu4/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2819
2024-12-10 22:06:55,332 [DEBUG] Response: 200 (2819 bytes) (rst-185:rem-985.0:used-15 ratelimit) at 1733886415.3320231
2024-12-10 22:06:55,334 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1ham0hm/ at 1733886415.334361
2024-12-10 22:06:55,334 [DEBUG] Data: None
2024-12-10 22:06:55,334 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:06:56,025 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1ham0hm/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 19049
2024-12-10 22:06:56,095 [DEBUG] Response: 200 (19049 bytes) (rst-184:rem-984.0:used-16 ratelimit) at 1733886416.0950341
2024-12-10 22:06:56,104 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1ham0hm/_/m1elgn2 at 1733886416.104474
2024-12-10 22:06:56,104 [DEBUG] Data: None
2024-12-10 22:06:56,104 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:06:56,366 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1ham0hm/_/m1elgn2?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2417
2024-12-10 22:06:56,372 [DEBUG] Response: 200 (2417 bytes) (rst-183:rem-983.0:used-17 ratelimit) at 1733886416.372971
2024-12-10 22:06:56,375 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hah6wz/ at 1733886416.3753989
2024-12-10 22:06:56,375 [DEBUG] Data: None
2024-12-10 22:06:56,375 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:06:56,842 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hah6wz/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 13277
2024-12-10 22:06:56,849 [DEBUG] Response: 200 (13277 bytes) (rst-183:rem-982.0:used-18 ratelimit) at 1733886416.849621
2024-12-10 22:06:56,853 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hafohz/ at 1733886416.853337
2024-12-10 22:06:56,853 [DEBUG] Data: None
2024-12-10 22:06:56,853 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:06:57,102 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hafohz/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3069
2024-12-10 22:06:57,113 [DEBUG] Response: 200 (3069 bytes) (rst-183:rem-981.0:used-19 ratelimit) at 1733886417.113182
2024-12-10 22:06:57,115 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1haf305/ at 1733886417.1155462
2024-12-10 22:06:57,115 [DEBUG] Data: None
2024-12-10 22:06:57,115 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:06:57,766 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1haf305/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4157
2024-12-10 22:06:58,173 [DEBUG] Response: 200 (4157 bytes) (rst-182:rem-980.0:used-20 ratelimit) at 1733886418.173682
2024-12-10 22:06:58,175 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1ha3h7s/ at 1733886418.175242
2024-12-10 22:06:58,175 [DEBUG] Data: None
2024-12-10 22:06:58,175 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:06:58,481 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1ha3h7s/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3599
2024-12-10 22:06:58,482 [DEBUG] Response: 200 (3599 bytes) (rst-181:rem-979.0:used-21 ratelimit) at 1733886418.482775
2024-12-10 22:06:58,484 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1ha3dwu/ at 1733886418.484183
2024-12-10 22:06:58,484 [DEBUG] Data: None
2024-12-10 22:06:58,484 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:06:58,995 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1ha3dwu/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 9276
2024-12-10 22:06:58,997 [DEBUG] Response: 200 (9276 bytes) (rst-181:rem-978.0:used-22 ratelimit) at 1733886418.997442
2024-12-10 22:06:59,003 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9yc2x/ at 1733886419.003648
2024-12-10 22:06:59,003 [DEBUG] Data: None
2024-12-10 22:06:59,003 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:06:59,269 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9yc2x/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 5231
2024-12-10 22:06:59,286 [DEBUG] Response: 200 (5231 bytes) (rst-180:rem-977.0:used-23 ratelimit) at 1733886419.2867358
2024-12-10 22:06:59,289 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9w3gv/ at 1733886419.2893949
2024-12-10 22:06:59,289 [DEBUG] Data: None
2024-12-10 22:06:59,289 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:06:59,575 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9w3gv/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4164
2024-12-10 22:06:59,592 [DEBUG] Response: 200 (4164 bytes) (rst-180:rem-976.0:used-24 ratelimit) at 1733886419.592038
2024-12-10 22:06:59,596 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropshipping/new at 1733886419.596055
2024-12-10 22:06:59,596 [DEBUG] Data: None
2024-12-10 22:06:59,596 [DEBUG] Params: {'after': 't3_1h9t55d', 'limit': 200, 'raw_json': 1}
2024-12-10 22:07:00,734 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropshipping/new?limit=200&after=t3_1h9t55d&raw_json=1 HTTP/11" 200 58184
2024-12-10 22:07:00,961 [DEBUG] Response: 200 (58184 bytes) (rst-180:rem-975.0:used-25 ratelimit) at 1733886420.9619431
2024-12-10 22:07:00,977 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9o8kr/ at 1733886420.977959
2024-12-10 22:07:00,978 [DEBUG] Data: None
2024-12-10 22:07:00,978 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:07:01,348 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9o8kr/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4548
2024-12-10 22:07:01,349 [DEBUG] Response: 200 (4548 bytes) (rst-178:rem-974.0:used-26 ratelimit) at 1733886421.349843
2024-12-10 22:07:01,352 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9o2yd/ at 1733886421.3524742
2024-12-10 22:07:01,352 [DEBUG] Data: None
2024-12-10 22:07:01,352 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:07:01,860 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9o2yd/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 12829
2024-12-10 22:07:01,862 [DEBUG] Response: 200 (12829 bytes) (rst-178:rem-973.0:used-27 ratelimit) at 1733886421.862358
2024-12-10 22:07:01,869 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9nqpy/ at 1733886421.8694952
2024-12-10 22:07:01,869 [DEBUG] Data: None
2024-12-10 22:07:01,869 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:07:02,169 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9nqpy/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6920
2024-12-10 22:07:02,193 [DEBUG] Response: 200 (6920 bytes) (rst-178:rem-972.0:used-28 ratelimit) at 1733886422.193816
2024-12-10 22:07:02,198 [INFO] Fetched and filtered 13 posts.
2024-12-10 22:07:02,211 [ERROR] Unexpected error during filtering.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 129, in filter_posts_with_gpt
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Users/chrisgaya/openai-python/venv/lib/python3.13/site-packages/openai/lib/_old_api.py", line 39, in __call__
    raise APIRemovedInV1(symbol=self._symbol)
openai.lib._old_api.APIRemovedInV1: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-10 22:07:02,213 [ERROR] Error in script execution.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 129, in filter_posts_with_gpt
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Users/chrisgaya/openai-python/venv/lib/python3.13/site-packages/openai/lib/_old_api.py", line 39, in __call__
    raise APIRemovedInV1(symbol=self._symbol)
openai.lib._old_api.APIRemovedInV1: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 252, in run_script
    good_posts = filter_posts_with_gpt(posts)
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 144, in filter_posts_with_gpt
    raise RuntimeError(f"Unexpected error: {e}")
RuntimeError: Unexpected error: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-10 22:18:03,235 [INFO] Successfully connected to the Reddit API.
2024-12-10 22:18:03,236 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733887083.236022
2024-12-10 22:18:03,236 [DEBUG] Data: None
2024-12-10 22:18:03,236 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-10 22:18:03,237 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-10 22:18:03,554 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 653
2024-12-10 22:18:03,558 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-10 22:18:05,107 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 51649
2024-12-10 22:18:05,185 [DEBUG] Response: 200 (51649 bytes) (rst-116:rem-999.0:used-1 ratelimit) at 1733887085.185697
2024-12-10 22:18:05,197 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbej76/ at 1733887085.197762
2024-12-10 22:18:05,197 [DEBUG] Data: None
2024-12-10 22:18:05,197 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:18:05,515 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbej76/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4861
2024-12-10 22:18:05,516 [DEBUG] Response: 200 (4861 bytes) (rst-114:rem-998.0:used-2 ratelimit) at 1733887085.51673
2024-12-10 22:18:05,519 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbam3w/ at 1733887085.5199401
2024-12-10 22:18:05,520 [DEBUG] Data: None
2024-12-10 22:18:05,520 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:18:05,822 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbam3w/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3487
2024-12-10 22:18:05,823 [DEBUG] Response: 200 (3487 bytes) (rst-114:rem-997.0:used-3 ratelimit) at 1733887085.822995
2024-12-10 22:18:05,825 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hb3wd9/ at 1733887085.825134
2024-12-10 22:18:05,825 [DEBUG] Data: None
2024-12-10 22:18:05,825 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:18:06,079 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hb3wd9/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3670
2024-12-10 22:18:06,080 [DEBUG] Response: 200 (3670 bytes) (rst-114:rem-996.0:used-4 ratelimit) at 1733887086.080679
2024-12-10 22:18:06,083 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hazjmj/ at 1733887086.083207
2024-12-10 22:18:06,083 [DEBUG] Data: None
2024-12-10 22:18:06,083 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:18:06,327 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hazjmj/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3671
2024-12-10 22:18:06,328 [DEBUG] Response: 200 (3671 bytes) (rst-113:rem-995.0:used-5 ratelimit) at 1733887086.328546
2024-12-10 22:18:06,330 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1harj8o/ at 1733887086.3307579
2024-12-10 22:18:06,330 [DEBUG] Data: None
2024-12-10 22:18:06,330 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:18:06,744 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1harj8o/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 8677
2024-12-10 22:18:06,745 [DEBUG] Response: 200 (8677 bytes) (rst-113:rem-994.0:used-6 ratelimit) at 1733887086.745746
2024-12-10 22:18:06,748 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hae4tc/ at 1733887086.748929
2024-12-10 22:18:06,749 [DEBUG] Data: None
2024-12-10 22:18:06,749 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:18:07,154 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hae4tc/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4997
2024-12-10 22:18:07,155 [DEBUG] Response: 200 (4997 bytes) (rst-113:rem-993.0:used-7 ratelimit) at 1733887087.155621
2024-12-10 22:18:07,163 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1ha9il4/ at 1733887087.1638458
2024-12-10 22:18:07,164 [DEBUG] Data: None
2024-12-10 22:18:07,164 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:18:07,403 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1ha9il4/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3798
2024-12-10 22:18:07,404 [DEBUG] Response: 200 (3798 bytes) (rst-112:rem-992.0:used-8 ratelimit) at 1733887087.4043782
2024-12-10 22:18:07,406 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9vjwq/ at 1733887087.4060428
2024-12-10 22:18:07,406 [DEBUG] Data: None
2024-12-10 22:18:07,406 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:18:07,669 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9vjwq/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4356
2024-12-10 22:18:07,672 [DEBUG] Response: 200 (4356 bytes) (rst-112:rem-991.0:used-9 ratelimit) at 1733887087.6722822
2024-12-10 22:18:07,675 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9omov/ at 1733887087.675311
2024-12-10 22:18:07,675 [DEBUG] Data: None
2024-12-10 22:18:07,675 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:18:07,913 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9omov/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4230
2024-12-10 22:18:07,914 [DEBUG] Response: 200 (4230 bytes) (rst-112:rem-990.0:used-10 ratelimit) at 1733887087.9148228
2024-12-10 22:18:07,916 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9fg8c/ at 1733887087.916608
2024-12-10 22:18:07,916 [DEBUG] Data: None
2024-12-10 22:18:07,916 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:18:08,183 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9fg8c/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6812
2024-12-10 22:18:08,184 [DEBUG] Response: 200 (6812 bytes) (rst-111:rem-989.0:used-11 ratelimit) at 1733887088.184781
2024-12-10 22:18:08,186 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733887088.186708
2024-12-10 22:18:08,186 [DEBUG] Data: None
2024-12-10 22:18:08,186 [DEBUG] Params: {'after': 't3_1h55mng', 'limit': 200, 'raw_json': 1}
2024-12-10 22:18:09,100 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h55mng&raw_json=1 HTTP/11" 200 50954
2024-12-10 22:18:09,103 [DEBUG] Response: 200 (50954 bytes) (rst-111:rem-988.0:used-12 ratelimit) at 1733887089.1036632
2024-12-10 22:18:09,116 [INFO] Fetched and filtered 10 posts.
2024-12-10 22:18:09,127 [ERROR] Error in script execution.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 132, in filter_posts_with_gpt
    response = client.completions.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Users/chrisgaya/openai-python/venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    raise TypeError(msg)
TypeError: Missing required arguments; Expected either ('model' and 'prompt') or ('model', 'prompt' and 'stream') arguments to be given

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 261, in run_script
    good_posts = filter_posts_with_gpt(posts)
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 145, in filter_posts_with_gpt
    except openai.error.OpenAIError as e:
           ^^^^^^^^^^^^
AttributeError: module 'openai' has no attribute 'error'
2024-12-10 22:21:35,539 [INFO] Successfully connected to the Reddit API.
2024-12-10 22:21:35,540 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733887295.54003
2024-12-10 22:21:35,540 [DEBUG] Data: None
2024-12-10 22:21:35,540 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-10 22:21:35,542 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-10 22:21:35,859 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 654
2024-12-10 22:21:35,862 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-10 22:21:37,077 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 51936
2024-12-10 22:21:37,152 [DEBUG] Response: 200 (51936 bytes) (rst-503:rem-999.0:used-1 ratelimit) at 1733887297.152936
2024-12-10 22:21:37,165 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbej76/ at 1733887297.1655731
2024-12-10 22:21:37,165 [DEBUG] Data: None
2024-12-10 22:21:37,165 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:21:37,589 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbej76/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4861
2024-12-10 22:21:37,590 [DEBUG] Response: 200 (4861 bytes) (rst-502:rem-998.0:used-2 ratelimit) at 1733887297.590525
2024-12-10 22:21:37,593 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbam3w/ at 1733887297.593913
2024-12-10 22:21:37,594 [DEBUG] Data: None
2024-12-10 22:21:37,594 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:21:37,842 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbam3w/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3488
2024-12-10 22:21:37,843 [DEBUG] Response: 200 (3488 bytes) (rst-502:rem-997.0:used-3 ratelimit) at 1733887297.843849
2024-12-10 22:21:37,845 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hb3wd9/ at 1733887297.845641
2024-12-10 22:21:37,845 [DEBUG] Data: None
2024-12-10 22:21:37,845 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:21:38,092 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hb3wd9/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3668
2024-12-10 22:21:38,096 [DEBUG] Response: 200 (3668 bytes) (rst-502:rem-996.0:used-4 ratelimit) at 1733887298.0966048
2024-12-10 22:21:38,099 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hazjmj/ at 1733887298.099196
2024-12-10 22:21:38,099 [DEBUG] Data: None
2024-12-10 22:21:38,099 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:21:38,386 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hazjmj/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3673
2024-12-10 22:21:38,387 [DEBUG] Response: 200 (3673 bytes) (rst-501:rem-995.0:used-5 ratelimit) at 1733887298.3878632
2024-12-10 22:21:38,389 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1harj8o/ at 1733887298.389587
2024-12-10 22:21:38,389 [DEBUG] Data: None
2024-12-10 22:21:38,389 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:21:38,816 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1harj8o/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 8685
2024-12-10 22:21:38,817 [DEBUG] Response: 200 (8685 bytes) (rst-501:rem-994.0:used-6 ratelimit) at 1733887298.8179252
2024-12-10 22:21:38,821 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hae4tc/ at 1733887298.821722
2024-12-10 22:21:38,821 [DEBUG] Data: None
2024-12-10 22:21:38,821 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:21:39,124 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hae4tc/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 5001
2024-12-10 22:21:39,288 [DEBUG] Response: 200 (5001 bytes) (rst-501:rem-993.0:used-7 ratelimit) at 1733887299.288179
2024-12-10 22:21:39,296 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1ha9il4/ at 1733887299.296555
2024-12-10 22:21:39,296 [DEBUG] Data: None
2024-12-10 22:21:39,296 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:21:39,544 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1ha9il4/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3799
2024-12-10 22:21:39,545 [DEBUG] Response: 200 (3799 bytes) (rst-500:rem-992.0:used-8 ratelimit) at 1733887299.545484
2024-12-10 22:21:39,547 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9vjwq/ at 1733887299.5475478
2024-12-10 22:21:39,547 [DEBUG] Data: None
2024-12-10 22:21:39,547 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:21:39,831 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9vjwq/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4357
2024-12-10 22:21:39,837 [DEBUG] Response: 200 (4357 bytes) (rst-500:rem-991.0:used-9 ratelimit) at 1733887299.837715
2024-12-10 22:21:39,841 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9v7dz/ at 1733887299.84109
2024-12-10 22:21:39,841 [DEBUG] Data: None
2024-12-10 22:21:39,841 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:21:40,087 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9v7dz/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2882
2024-12-10 22:21:40,090 [DEBUG] Response: 200 (2882 bytes) (rst-500:rem-990.0:used-10 ratelimit) at 1733887300.090471
2024-12-10 22:21:40,092 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9omov/ at 1733887300.092698
2024-12-10 22:21:40,092 [DEBUG] Data: None
2024-12-10 22:21:40,092 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:21:40,326 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9omov/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4229
2024-12-10 22:21:40,490 [DEBUG] Response: 200 (4229 bytes) (rst-499:rem-989.0:used-11 ratelimit) at 1733887300.490953
2024-12-10 22:21:40,492 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9fg8c/ at 1733887300.492615
2024-12-10 22:21:40,492 [DEBUG] Data: None
2024-12-10 22:21:40,492 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:21:40,760 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9fg8c/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6811
2024-12-10 22:21:40,770 [DEBUG] Response: 200 (6811 bytes) (rst-499:rem-988.0:used-12 ratelimit) at 1733887300.770231
2024-12-10 22:21:40,772 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733887300.772956
2024-12-10 22:21:40,773 [DEBUG] Data: None
2024-12-10 22:21:40,773 [DEBUG] Params: {'after': 't3_1h5fz15', 'limit': 200, 'raw_json': 1}
2024-12-10 22:21:41,579 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h5fz15&raw_json=1 HTTP/11" 200 50926
2024-12-10 22:21:41,716 [DEBUG] Response: 200 (50926 bytes) (rst-499:rem-987.0:used-13 ratelimit) at 1733887301.716138
2024-12-10 22:21:41,727 [INFO] Fetched and filtered 11 posts.
2024-12-10 22:21:41,737 [ERROR] Error in script execution.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 132, in filter_posts_with_gpt
    response = client.completions.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Users/chrisgaya/openai-python/venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    raise TypeError(msg)
TypeError: Missing required arguments; Expected either ('model' and 'prompt') or ('model', 'prompt' and 'stream') arguments to be given

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 258, in run_script
    good_posts = filter_posts_with_gpt(posts)
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 145, in filter_posts_with_gpt
    except openai.error.OpenAIError as e:
           ^^^^^^^^^^^^
AttributeError: module 'openai' has no attribute 'error'
2024-12-10 22:22:12,121 [INFO] Successfully connected to the Reddit API.
2024-12-10 22:22:12,121 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733887332.1214662
2024-12-10 22:22:12,121 [DEBUG] Data: None
2024-12-10 22:22:12,121 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-10 22:22:12,123 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-10 22:22:12,274 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 652
2024-12-10 22:22:12,277 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-10 22:22:13,448 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 51851
2024-12-10 22:22:13,460 [DEBUG] Response: 200 (51851 bytes) (rst-467:rem-986.0:used-14 ratelimit) at 1733887333.4606268
2024-12-10 22:22:13,473 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbam3w/ at 1733887333.4729989
2024-12-10 22:22:13,473 [DEBUG] Data: None
2024-12-10 22:22:13,473 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:22:13,630 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbam3w/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3488
2024-12-10 22:22:13,631 [DEBUG] Response: 200 (3488 bytes) (rst-466:rem-985.0:used-15 ratelimit) at 1733887333.631684
2024-12-10 22:22:13,633 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hb3wd9/ at 1733887333.633418
2024-12-10 22:22:13,633 [DEBUG] Data: None
2024-12-10 22:22:13,633 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:22:13,811 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hb3wd9/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3661
2024-12-10 22:22:13,812 [DEBUG] Response: 200 (3661 bytes) (rst-466:rem-984.0:used-16 ratelimit) at 1733887333.812544
2024-12-10 22:22:13,815 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hazjmj/ at 1733887333.815129
2024-12-10 22:22:13,815 [DEBUG] Data: None
2024-12-10 22:22:13,815 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:22:13,974 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hazjmj/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3678
2024-12-10 22:22:13,975 [DEBUG] Response: 200 (3678 bytes) (rst-466:rem-983.0:used-17 ratelimit) at 1733887333.975488
2024-12-10 22:22:13,977 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1harj8o/ at 1733887333.977487
2024-12-10 22:22:13,977 [DEBUG] Data: None
2024-12-10 22:22:13,977 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:22:14,245 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1harj8o/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 8690
2024-12-10 22:22:14,246 [DEBUG] Response: 200 (8690 bytes) (rst-465:rem-982.0:used-18 ratelimit) at 1733887334.246411
2024-12-10 22:22:14,250 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hae4tc/ at 1733887334.250416
2024-12-10 22:22:14,250 [DEBUG] Data: None
2024-12-10 22:22:14,250 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:22:14,457 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hae4tc/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4999
2024-12-10 22:22:14,458 [DEBUG] Response: 200 (4999 bytes) (rst-465:rem-981.0:used-19 ratelimit) at 1733887334.4585862
2024-12-10 22:22:14,461 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1ha9il4/ at 1733887334.461358
2024-12-10 22:22:14,461 [DEBUG] Data: None
2024-12-10 22:22:14,461 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:22:14,631 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1ha9il4/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3799
2024-12-10 22:22:14,632 [DEBUG] Response: 200 (3799 bytes) (rst-465:rem-980.0:used-20 ratelimit) at 1733887334.6329181
2024-12-10 22:22:14,635 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9vjwq/ at 1733887334.635015
2024-12-10 22:22:14,635 [DEBUG] Data: None
2024-12-10 22:22:14,635 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:22:14,816 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9vjwq/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4357
2024-12-10 22:22:14,818 [DEBUG] Response: 200 (4357 bytes) (rst-465:rem-979.0:used-21 ratelimit) at 1733887334.8187678
2024-12-10 22:22:14,826 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9omov/ at 1733887334.8269281
2024-12-10 22:22:14,827 [DEBUG] Data: None
2024-12-10 22:22:14,827 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:22:14,978 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9omov/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4230
2024-12-10 22:22:14,981 [DEBUG] Response: 200 (4230 bytes) (rst-465:rem-978.0:used-22 ratelimit) at 1733887334.9810848
2024-12-10 22:22:14,982 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1h9fg8c/ at 1733887334.98286
2024-12-10 22:22:14,983 [DEBUG] Data: None
2024-12-10 22:22:14,983 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-10 22:22:15,175 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1h9fg8c/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6813
2024-12-10 22:22:15,178 [DEBUG] Response: 200 (6813 bytes) (rst-464:rem-977.0:used-23 ratelimit) at 1733887335.178894
2024-12-10 22:22:15,181 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1733887335.1818502
2024-12-10 22:22:15,181 [DEBUG] Data: None
2024-12-10 22:22:15,182 [DEBUG] Params: {'after': 't3_1h5fz15', 'limit': 200, 'raw_json': 1}
2024-12-10 22:22:15,984 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h5fz15&raw_json=1 HTTP/11" 200 50970
2024-12-10 22:22:16,071 [DEBUG] Response: 200 (50970 bytes) (rst-464:rem-976.0:used-24 ratelimit) at 1733887336.071367
2024-12-10 22:22:16,084 [INFO] Fetched and filtered 9 posts.
2024-12-10 22:22:16,095 [ERROR] Unexpected error during filtering.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 132, in filter_posts_with_gpt
    response = client.completions.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Users/chrisgaya/openai-python/venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    raise TypeError(msg)
TypeError: Missing required arguments; Expected either ('model' and 'prompt') or ('model', 'prompt' and 'stream') arguments to be given
2024-12-10 22:22:16,096 [ERROR] Error in script execution.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 132, in filter_posts_with_gpt
    response = client.completions.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Users/chrisgaya/openai-python/venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    raise TypeError(msg)
TypeError: Missing required arguments; Expected either ('model' and 'prompt') or ('model', 'prompt' and 'stream') arguments to be given

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 255, in run_script
    good_posts = filter_posts_with_gpt(posts)
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 147, in filter_posts_with_gpt
    raise RuntimeError(f"Unexpected error: {e}")
RuntimeError: Unexpected error: Missing required arguments; Expected either ('model' and 'prompt') or ('model', 'prompt' and 'stream') arguments to be given
2024-12-13 23:34:23,941 [DEBUG] Starting new HTTPS connection (1): pypi.org:443
2024-12-13 23:34:24,161 [DEBUG] https://pypi.org:443 "GET /pypi/praw/json HTTP/11" 200 36290
2024-12-13 23:34:24,218 [INFO] Successfully connected to the Reddit API.
2024-12-13 23:34:24,218 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734150864.218487
2024-12-13 23:34:24,218 [DEBUG] Data: None
2024-12-13 23:34:24,218 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-13 23:34:24,219 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-13 23:34:24,771 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 655
2024-12-13 23:34:24,773 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-13 23:34:25,856 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 56175
2024-12-13 23:34:25,926 [DEBUG] Response: 200 (56175 bytes) (rst-334:rem-999.0:used-1 ratelimit) at 1734150865.926621
2024-12-13 23:34:25,939 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdlno3/ at 1734150865.939548
2024-12-13 23:34:25,939 [DEBUG] Data: None
2024-12-13 23:34:25,939 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:34:26,130 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdlno3/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3122
2024-12-13 23:34:26,131 [DEBUG] Response: 200 (3122 bytes) (rst-333:rem-998.0:used-2 ratelimit) at 1734150866.131743
2024-12-13 23:34:26,133 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdg5rp/ at 1734150866.1333601
2024-12-13 23:34:26,133 [DEBUG] Data: None
2024-12-13 23:34:26,133 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:34:26,299 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdg5rp/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3530
2024-12-13 23:34:26,300 [DEBUG] Response: 200 (3530 bytes) (rst-333:rem-997.0:used-3 ratelimit) at 1734150866.30092
2024-12-13 23:34:26,302 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdahzr/ at 1734150866.302627
2024-12-13 23:34:26,302 [DEBUG] Data: None
2024-12-13 23:34:26,302 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:34:26,470 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdahzr/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2518
2024-12-13 23:34:26,472 [DEBUG] Response: 200 (2518 bytes) (rst-333:rem-996.0:used-4 ratelimit) at 1734150866.472091
2024-12-13 23:34:26,473 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hd2nk7/ at 1734150866.473102
2024-12-13 23:34:26,473 [DEBUG] Data: None
2024-12-13 23:34:26,473 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:34:26,750 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hd2nk7/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7692
2024-12-13 23:34:26,753 [DEBUG] Response: 200 (7692 bytes) (rst-333:rem-995.0:used-5 ratelimit) at 1734150866.753407
2024-12-13 23:34:26,757 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcv8pi/ at 1734150866.757327
2024-12-13 23:34:26,757 [DEBUG] Data: None
2024-12-13 23:34:26,757 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:34:26,908 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcv8pi/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3048
2024-12-13 23:34:26,910 [DEBUG] Response: 200 (3048 bytes) (rst-333:rem-994.0:used-6 ratelimit) at 1734150866.910298
2024-12-13 23:34:26,912 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hci0sx/ at 1734150866.9120572
2024-12-13 23:34:26,912 [DEBUG] Data: None
2024-12-13 23:34:26,912 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:34:27,120 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hci0sx/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6180
2024-12-13 23:34:27,122 [DEBUG] Response: 200 (6180 bytes) (rst-333:rem-993.0:used-7 ratelimit) at 1734150867.122575
2024-12-13 23:34:27,125 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcfjg8/ at 1734150867.125956
2024-12-13 23:34:27,126 [DEBUG] Data: None
2024-12-13 23:34:27,126 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:34:27,319 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcfjg8/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4253
2024-12-13 23:34:27,320 [DEBUG] Response: 200 (4253 bytes) (rst-332:rem-992.0:used-8 ratelimit) at 1734150867.320429
2024-12-13 23:34:27,329 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcaa94/ at 1734150867.329526
2024-12-13 23:34:27,329 [DEBUG] Data: None
2024-12-13 23:34:27,329 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:34:27,583 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcaa94/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2771
2024-12-13 23:34:27,583 [DEBUG] Response: 200 (2771 bytes) (rst-332:rem-991.0:used-9 ratelimit) at 1734150867.5838048
2024-12-13 23:34:27,585 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hc7am0/ at 1734150867.585074
2024-12-13 23:34:27,585 [DEBUG] Data: None
2024-12-13 23:34:27,585 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:34:27,848 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hc7am0/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7567
2024-12-13 23:34:27,849 [DEBUG] Response: 200 (7567 bytes) (rst-332:rem-990.0:used-10 ratelimit) at 1734150867.849515
2024-12-13 23:34:27,853 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbuec8/ at 1734150867.853157
2024-12-13 23:34:27,853 [DEBUG] Data: None
2024-12-13 23:34:27,853 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:34:28,075 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbuec8/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6935
2024-12-13 23:34:28,077 [DEBUG] Response: 200 (6935 bytes) (rst-332:rem-989.0:used-11 ratelimit) at 1734150868.077012
2024-12-13 23:34:28,081 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbpira/ at 1734150868.0810509
2024-12-13 23:34:28,081 [DEBUG] Data: None
2024-12-13 23:34:28,081 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:34:28,259 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbpira/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3045
2024-12-13 23:34:28,260 [DEBUG] Response: 200 (3045 bytes) (rst-331:rem-988.0:used-12 ratelimit) at 1734150868.260264
2024-12-13 23:34:28,261 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbmlve/ at 1734150868.2619
2024-12-13 23:34:28,262 [DEBUG] Data: None
2024-12-13 23:34:28,262 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:34:28,434 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbmlve/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4412
2024-12-13 23:34:28,436 [DEBUG] Response: 200 (4412 bytes) (rst-331:rem-987.0:used-13 ratelimit) at 1734150868.436608
2024-12-13 23:34:28,438 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734150868.438736
2024-12-13 23:34:28,438 [DEBUG] Data: None
2024-12-13 23:34:28,439 [DEBUG] Params: {'after': 't3_1h6wpkl', 'limit': 200, 'raw_json': 1}
2024-12-13 23:34:29,731 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h6wpkl&raw_json=1 HTTP/11" 200 49258
2024-12-13 23:34:29,769 [DEBUG] Response: 200 (49258 bytes) (rst-331:rem-986.0:used-14 ratelimit) at 1734150869.76916
2024-12-13 23:34:29,773 [INFO] Fetched and filtered 12 posts.
2024-12-13 23:34:29,783 [ERROR] Unexpected error during filtering.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 132, in filter_posts_with_gpt
    response = client.completions.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    raise TypeError(msg)
TypeError: Missing required arguments; Expected either ('model' and 'prompt') or ('model', 'prompt' and 'stream') arguments to be given
2024-12-13 23:34:29,784 [ERROR] Error in script execution.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 132, in filter_posts_with_gpt
    response = client.completions.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    raise TypeError(msg)
TypeError: Missing required arguments; Expected either ('model' and 'prompt') or ('model', 'prompt' and 'stream') arguments to be given

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 255, in run_script
    good_posts = filter_posts_with_gpt(posts)
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 147, in filter_posts_with_gpt
    raise RuntimeError(f"Unexpected error: {e}")
RuntimeError: Unexpected error: Missing required arguments; Expected either ('model' and 'prompt') or ('model', 'prompt' and 'stream') arguments to be given
2024-12-13 23:39:54,583 [INFO] Successfully connected to the Reddit API.
2024-12-13 23:39:54,583 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734151194.5839229
2024-12-13 23:39:54,584 [DEBUG] Data: None
2024-12-13 23:39:54,584 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-13 23:39:54,586 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-13 23:39:55,102 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 652
2024-12-13 23:39:55,105 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-13 23:39:56,104 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 56215
2024-12-13 23:39:56,175 [DEBUG] Response: 200 (56215 bytes) (rst-4:rem-985.0:used-15 ratelimit) at 1734151196.175597
2024-12-13 23:39:56,185 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdlno3/ at 1734151196.185836
2024-12-13 23:39:56,186 [DEBUG] Data: None
2024-12-13 23:39:56,186 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:39:56,375 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdlno3/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3127
2024-12-13 23:39:56,376 [DEBUG] Response: 200 (3127 bytes) (rst-3:rem-984.0:used-16 ratelimit) at 1734151196.376575
2024-12-13 23:39:56,377 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdahzr/ at 1734151196.377739
2024-12-13 23:39:56,377 [DEBUG] Data: None
2024-12-13 23:39:56,377 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:39:56,542 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdahzr/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2517
2024-12-13 23:39:56,543 [DEBUG] Response: 200 (2517 bytes) (rst-3:rem-983.0:used-17 ratelimit) at 1734151196.543249
2024-12-13 23:39:56,544 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hd2nk7/ at 1734151196.5445602
2024-12-13 23:39:56,544 [DEBUG] Data: None
2024-12-13 23:39:56,544 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:39:56,811 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hd2nk7/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7692
2024-12-13 23:39:56,812 [DEBUG] Response: 200 (7692 bytes) (rst-3:rem-982.0:used-18 ratelimit) at 1734151196.812605
2024-12-13 23:39:56,817 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcv8pi/ at 1734151196.817814
2024-12-13 23:39:56,817 [DEBUG] Data: None
2024-12-13 23:39:56,818 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:39:56,996 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcv8pi/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3047
2024-12-13 23:39:56,997 [DEBUG] Response: 200 (3047 bytes) (rst-3:rem-981.0:used-19 ratelimit) at 1734151196.9976819
2024-12-13 23:39:56,999 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hci0sx/ at 1734151196.9994082
2024-12-13 23:39:56,999 [DEBUG] Data: None
2024-12-13 23:39:56,999 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:39:57,273 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hci0sx/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6186
2024-12-13 23:39:57,280 [DEBUG] Response: 200 (6186 bytes) (rst-2:rem-980.0:used-20 ratelimit) at 1734151197.2807648
2024-12-13 23:39:57,284 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcfjg8/ at 1734151197.284341
2024-12-13 23:39:57,284 [DEBUG] Data: None
2024-12-13 23:39:57,284 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:39:57,480 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcfjg8/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4256
2024-12-13 23:39:57,481 [DEBUG] Response: 200 (4256 bytes) (rst-2:rem-979.0:used-21 ratelimit) at 1734151197.481503
2024-12-13 23:39:57,483 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcaa94/ at 1734151197.4838212
2024-12-13 23:39:57,483 [DEBUG] Data: None
2024-12-13 23:39:57,483 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:39:57,636 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcaa94/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2772
2024-12-13 23:39:57,637 [DEBUG] Response: 200 (2772 bytes) (rst-2:rem-978.0:used-22 ratelimit) at 1734151197.6374779
2024-12-13 23:39:57,638 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hc7am0/ at 1734151197.638977
2024-12-13 23:39:57,639 [DEBUG] Data: None
2024-12-13 23:39:57,639 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:39:57,940 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hc7am0/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7568
2024-12-13 23:39:57,941 [DEBUG] Response: 200 (7568 bytes) (rst-2:rem-977.0:used-23 ratelimit) at 1734151197.941948
2024-12-13 23:39:57,945 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbuec8/ at 1734151197.945667
2024-12-13 23:39:57,945 [DEBUG] Data: None
2024-12-13 23:39:57,945 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:39:58,168 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbuec8/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6935
2024-12-13 23:39:58,171 [DEBUG] Response: 200 (6935 bytes) (rst-1:rem-976.0:used-24 ratelimit) at 1734151198.171934
2024-12-13 23:39:58,176 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbpira/ at 1734151198.1763399
2024-12-13 23:39:58,176 [DEBUG] Data: None
2024-12-13 23:39:58,176 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:39:58,358 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbpira/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3052
2024-12-13 23:39:58,359 [DEBUG] Response: 200 (3052 bytes) (rst-1:rem-975.0:used-25 ratelimit) at 1734151198.3595898
2024-12-13 23:39:58,361 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbmlve/ at 1734151198.361238
2024-12-13 23:39:58,361 [DEBUG] Data: None
2024-12-13 23:39:58,361 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:39:58,565 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbmlve/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4412
2024-12-13 23:39:58,566 [DEBUG] Response: 200 (4412 bytes) (rst-1:rem-974.0:used-26 ratelimit) at 1734151198.566738
2024-12-13 23:39:58,568 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734151198.568704
2024-12-13 23:39:58,568 [DEBUG] Data: None
2024-12-13 23:39:58,568 [DEBUG] Params: {'after': 't3_1h6wpkl', 'limit': 200, 'raw_json': 1}
2024-12-13 23:39:59,488 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h6wpkl&raw_json=1 HTTP/11" 200 49251
2024-12-13 23:39:59,528 [DEBUG] Response: 200 (49251 bytes) (rst-1:rem-973.0:used-27 ratelimit) at 1734151199.5280461
2024-12-13 23:39:59,543 [INFO] Fetched and filtered 11 posts.
2024-12-13 23:39:59,554 [ERROR] Unexpected error during filtering.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 132, in filter_posts_with_gpt
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/lib/_old_api.py", line 39, in __call__
    raise APIRemovedInV1(symbol=self._symbol)
openai.lib._old_api.APIRemovedInV1: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-13 23:39:59,555 [ERROR] Error in script execution.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 132, in filter_posts_with_gpt
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/lib/_old_api.py", line 39, in __call__
    raise APIRemovedInV1(symbol=self._symbol)
openai.lib._old_api.APIRemovedInV1: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 258, in run_script
    good_posts = filter_posts_with_gpt(posts)
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 150, in filter_posts_with_gpt
    raise RuntimeError(f"Unexpected error: {e}")
RuntimeError: Unexpected error: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-13 23:42:15,066 [INFO] Successfully connected to the Reddit API.
2024-12-13 23:42:15,067 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734151335.067373
2024-12-13 23:42:15,067 [DEBUG] Data: None
2024-12-13 23:42:15,067 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-13 23:42:15,069 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-13 23:42:15,589 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 651
2024-12-13 23:42:15,593 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-13 23:42:16,503 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 56173
2024-12-13 23:42:16,574 [DEBUG] Response: 200 (56173 bytes) (rst-464:rem-999.0:used-1 ratelimit) at 1734151336.5749278
2024-12-13 23:42:16,587 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdlno3/ at 1734151336.587234
2024-12-13 23:42:16,587 [DEBUG] Data: None
2024-12-13 23:42:16,587 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:42:16,756 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdlno3/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3124
2024-12-13 23:42:16,757 [DEBUG] Response: 200 (3124 bytes) (rst-463:rem-998.0:used-2 ratelimit) at 1734151336.757313
2024-12-13 23:42:16,758 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdahzr/ at 1734151336.7583842
2024-12-13 23:42:16,758 [DEBUG] Data: None
2024-12-13 23:42:16,758 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:42:16,913 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdahzr/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2517
2024-12-13 23:42:16,914 [DEBUG] Response: 200 (2517 bytes) (rst-463:rem-997.0:used-3 ratelimit) at 1734151336.914326
2024-12-13 23:42:16,915 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hd2nk7/ at 1734151336.915405
2024-12-13 23:42:16,915 [DEBUG] Data: None
2024-12-13 23:42:16,915 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:42:17,159 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hd2nk7/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7683
2024-12-13 23:42:17,161 [DEBUG] Response: 200 (7683 bytes) (rst-463:rem-996.0:used-4 ratelimit) at 1734151337.161104
2024-12-13 23:42:17,165 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcv8pi/ at 1734151337.16544
2024-12-13 23:42:17,165 [DEBUG] Data: None
2024-12-13 23:42:17,165 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:42:17,329 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcv8pi/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3049
2024-12-13 23:42:17,331 [DEBUG] Response: 200 (3049 bytes) (rst-462:rem-995.0:used-5 ratelimit) at 1734151337.331091
2024-12-13 23:42:17,332 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hci0sx/ at 1734151337.332816
2024-12-13 23:42:17,332 [DEBUG] Data: None
2024-12-13 23:42:17,332 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:42:17,559 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hci0sx/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6185
2024-12-13 23:42:17,560 [DEBUG] Response: 200 (6185 bytes) (rst-462:rem-994.0:used-6 ratelimit) at 1734151337.5609448
2024-12-13 23:42:17,563 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcfjg8/ at 1734151337.563554
2024-12-13 23:42:17,563 [DEBUG] Data: None
2024-12-13 23:42:17,563 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:42:17,765 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcfjg8/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4257
2024-12-13 23:42:17,766 [DEBUG] Response: 200 (4257 bytes) (rst-462:rem-993.0:used-7 ratelimit) at 1734151337.7668
2024-12-13 23:42:17,769 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcaa94/ at 1734151337.769005
2024-12-13 23:42:17,769 [DEBUG] Data: None
2024-12-13 23:42:17,769 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:42:17,937 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcaa94/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2769
2024-12-13 23:42:17,938 [DEBUG] Response: 200 (2769 bytes) (rst-462:rem-992.0:used-8 ratelimit) at 1734151337.93875
2024-12-13 23:42:17,940 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hc7am0/ at 1734151337.940307
2024-12-13 23:42:17,940 [DEBUG] Data: None
2024-12-13 23:42:17,940 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:42:18,215 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hc7am0/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7561
2024-12-13 23:42:18,217 [DEBUG] Response: 200 (7561 bytes) (rst-461:rem-991.0:used-9 ratelimit) at 1734151338.217192
2024-12-13 23:42:18,221 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbuec8/ at 1734151338.221916
2024-12-13 23:42:18,222 [DEBUG] Data: None
2024-12-13 23:42:18,222 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:42:18,458 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbuec8/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6936
2024-12-13 23:42:18,461 [DEBUG] Response: 200 (6936 bytes) (rst-461:rem-990.0:used-10 ratelimit) at 1734151338.4616
2024-12-13 23:42:18,465 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbpira/ at 1734151338.46591
2024-12-13 23:42:18,466 [DEBUG] Data: None
2024-12-13 23:42:18,466 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:42:18,657 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbpira/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3054
2024-12-13 23:42:18,658 [DEBUG] Response: 200 (3054 bytes) (rst-461:rem-989.0:used-11 ratelimit) at 1734151338.6589131
2024-12-13 23:42:18,661 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbmlve/ at 1734151338.661173
2024-12-13 23:42:18,661 [DEBUG] Data: None
2024-12-13 23:42:18,661 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-13 23:42:18,869 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbmlve/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4413
2024-12-13 23:42:18,870 [DEBUG] Response: 200 (4413 bytes) (rst-461:rem-988.0:used-12 ratelimit) at 1734151338.870653
2024-12-13 23:42:18,872 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734151338.8723378
2024-12-13 23:42:18,872 [DEBUG] Data: None
2024-12-13 23:42:18,872 [DEBUG] Params: {'after': 't3_1h6wpkl', 'limit': 200, 'raw_json': 1}
2024-12-13 23:42:19,703 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h6wpkl&raw_json=1 HTTP/11" 200 49227
2024-12-13 23:42:19,741 [DEBUG] Response: 200 (49227 bytes) (rst-461:rem-987.0:used-13 ratelimit) at 1734151339.741927
2024-12-13 23:42:19,752 [INFO] Fetched and filtered 11 posts.
2024-12-13 23:42:19,761 [ERROR] Unexpected error during filtering.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 130, in filter_posts_with_gpt
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/lib/_old_api.py", line 39, in __call__
    raise APIRemovedInV1(symbol=self._symbol)
openai.lib._old_api.APIRemovedInV1: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-13 23:42:19,762 [ERROR] Error in script execution.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 130, in filter_posts_with_gpt
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/lib/_old_api.py", line 39, in __call__
    raise APIRemovedInV1(symbol=self._symbol)
openai.lib._old_api.APIRemovedInV1: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 262, in run_script
    good_posts = filter_posts_with_gpt(posts)
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 145, in filter_posts_with_gpt
    raise RuntimeError(f"Unexpected error: {e}")
RuntimeError: Unexpected error: 

You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-14 00:22:11,432 [INFO] Successfully connected to the Reddit API.
2024-12-14 00:22:11,432 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734153731.432939
2024-12-14 00:22:11,433 [DEBUG] Data: None
2024-12-14 00:22:11,433 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-14 00:22:11,435 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-14 00:22:11,949 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 654
2024-12-14 00:22:11,953 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-14 00:22:13,002 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 56218
2024-12-14 00:22:13,089 [DEBUG] Response: 200 (56218 bytes) (rst-467:rem-999.0:used-1 ratelimit) at 1734153733.0893528
2024-12-14 00:22:13,100 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdlno3/ at 1734153733.1004531
2024-12-14 00:22:13,100 [DEBUG] Data: None
2024-12-14 00:22:13,100 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:22:13,281 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdlno3/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3124
2024-12-14 00:22:13,283 [DEBUG] Response: 200 (3124 bytes) (rst-466:rem-998.0:used-2 ratelimit) at 1734153733.283168
2024-12-14 00:22:13,285 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdg5rp/ at 1734153733.285295
2024-12-14 00:22:13,285 [DEBUG] Data: None
2024-12-14 00:22:13,285 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:22:13,461 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdg5rp/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3530
2024-12-14 00:22:13,463 [DEBUG] Response: 200 (3530 bytes) (rst-466:rem-997.0:used-3 ratelimit) at 1734153733.4631019
2024-12-14 00:22:13,465 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdahzr/ at 1734153733.465656
2024-12-14 00:22:13,465 [DEBUG] Data: None
2024-12-14 00:22:13,465 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:22:13,717 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdahzr/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2517
2024-12-14 00:22:13,718 [DEBUG] Response: 200 (2517 bytes) (rst-466:rem-996.0:used-4 ratelimit) at 1734153733.718976
2024-12-14 00:22:13,719 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hd2nk7/ at 1734153733.7199569
2024-12-14 00:22:13,720 [DEBUG] Data: None
2024-12-14 00:22:13,720 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:22:14,010 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hd2nk7/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7687
2024-12-14 00:22:14,011 [DEBUG] Response: 200 (7687 bytes) (rst-466:rem-995.0:used-5 ratelimit) at 1734153734.011466
2024-12-14 00:22:14,015 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcv8pi/ at 1734153734.015543
2024-12-14 00:22:14,015 [DEBUG] Data: None
2024-12-14 00:22:14,015 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:22:14,193 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcv8pi/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3048
2024-12-14 00:22:14,195 [DEBUG] Response: 200 (3048 bytes) (rst-465:rem-994.0:used-6 ratelimit) at 1734153734.195094
2024-12-14 00:22:14,196 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hci0sx/ at 1734153734.196573
2024-12-14 00:22:14,196 [DEBUG] Data: None
2024-12-14 00:22:14,196 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:22:14,414 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hci0sx/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6407
2024-12-14 00:22:14,417 [DEBUG] Response: 200 (6407 bytes) (rst-465:rem-993.0:used-7 ratelimit) at 1734153734.4175181
2024-12-14 00:22:14,421 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcfjg8/ at 1734153734.4215522
2024-12-14 00:22:14,421 [DEBUG] Data: None
2024-12-14 00:22:14,421 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:22:14,617 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcfjg8/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4253
2024-12-14 00:22:14,619 [DEBUG] Response: 200 (4253 bytes) (rst-465:rem-992.0:used-8 ratelimit) at 1734153734.619126
2024-12-14 00:22:14,622 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcaa94/ at 1734153734.62214
2024-12-14 00:22:14,622 [DEBUG] Data: None
2024-12-14 00:22:14,622 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:22:14,775 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcaa94/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2770
2024-12-14 00:22:14,776 [DEBUG] Response: 200 (2770 bytes) (rst-465:rem-991.0:used-9 ratelimit) at 1734153734.7769659
2024-12-14 00:22:14,778 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hc7am0/ at 1734153734.77852
2024-12-14 00:22:14,778 [DEBUG] Data: None
2024-12-14 00:22:14,778 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:22:15,022 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hc7am0/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7567
2024-12-14 00:22:15,026 [DEBUG] Response: 200 (7567 bytes) (rst-465:rem-990.0:used-10 ratelimit) at 1734153735.0260491
2024-12-14 00:22:15,030 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbuec8/ at 1734153735.030488
2024-12-14 00:22:15,030 [DEBUG] Data: None
2024-12-14 00:22:15,030 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:22:15,265 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbuec8/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6932
2024-12-14 00:22:15,270 [DEBUG] Response: 200 (6932 bytes) (rst-464:rem-989.0:used-11 ratelimit) at 1734153735.269978
2024-12-14 00:22:15,274 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbpira/ at 1734153735.274189
2024-12-14 00:22:15,274 [DEBUG] Data: None
2024-12-14 00:22:15,274 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:22:15,469 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbpira/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3051
2024-12-14 00:22:15,471 [DEBUG] Response: 200 (3051 bytes) (rst-464:rem-988.0:used-12 ratelimit) at 1734153735.4710379
2024-12-14 00:22:15,473 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbmlve/ at 1734153735.4735029
2024-12-14 00:22:15,473 [DEBUG] Data: None
2024-12-14 00:22:15,473 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:22:15,673 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbmlve/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4413
2024-12-14 00:22:15,675 [DEBUG] Response: 200 (4413 bytes) (rst-464:rem-987.0:used-13 ratelimit) at 1734153735.675076
2024-12-14 00:22:15,677 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734153735.6770291
2024-12-14 00:22:15,677 [DEBUG] Data: None
2024-12-14 00:22:15,677 [DEBUG] Params: {'after': 't3_1h6wpkl', 'limit': 200, 'raw_json': 1}
2024-12-14 00:22:16,505 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h6wpkl&raw_json=1 HTTP/11" 200 49294
2024-12-14 00:22:16,545 [DEBUG] Response: 200 (49294 bytes) (rst-464:rem-986.0:used-14 ratelimit) at 1734153736.545215
2024-12-14 00:22:16,562 [INFO] Fetched and filtered 12 posts.
2024-12-14 00:22:16,571 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\n    You are a helpful assistant. Identify up to 20 good posts.\n\n    Here are the posts:\n    Post ID: 1hdlno3\nTitle: Dropshipping in 2024: A Comedy Special\nScore: 9\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI dont care if this is written by AI. Its rather funny. Especially Day 30. \nThis is clearly written by AI\n------\nPost ID: 1hdg5rp\nTitle: You guys be careful out there\nScore: 4\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nYeah even with legitimate agents, the price of shipping and storage is extortionate.\n\nHere\'s why I still dropship after 4 years and haven\'t transitioned to agent or 3PL\nhttps://youtu.be/l7uSiQ9sHik?si=aQ9_tytfRXjj7Gzu\nYes 100%, I had one reach out to me. Tried to charge almost double more than Aliexpress...\n------\nPost ID: 1hdahzr\nTitle: Trending Niches on TikTok Shop US in December\nScore: 7\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n------\nPost ID: 1hd2nk7\nTitle: I have a TikTok shop for sale, what is a fair price to ask for it?\nScore: 9\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nFor dropshipping stores with that short of a history you would realisticly be looking at 500-750$ area.\n\nDropshipping stores in themself do not sell for nearly the same as normal companies that are in multipliers of annual incomes.  \nAnd with both being limited to a platform like that plus such a short history, you are not even guaranteed to get 3x average monthly profit (and you can not expect to get the holiday peak included in that average).\nGet some Indian to make ads for you, wont cost you too much, if youre making money organically and youre able to get videos for cheap like that, it doesnt make sense not to continue. You could also look at a supplier platform that allows for automatic fulfilment like SP\n------\nPost ID: 1hcv8pi\nTitle: Doing Ok I Guess\nScore: 29\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n>(ironic most people seek the opposite).\n\nMost kids/teens walking into it imagining it being easy money seek it, majority that are older do not really seek it.\n\nDoing something like dropshipping fulltime is something that sounds great intil you actualy do it tends to be the experience.  \nYou tend to start missing the coworkers, meetings etc that you used to somewhat hate.\nKeep moving forward, you got this\n------\nPost ID: 1hci0sx\nTitle: How long did it take for you to make the first sale?\nScore: 10\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI know this doesn\'t answer your question, but I don\'t think furniture is a good niche for dropshipping, especially for a beginner. Just my 2 cents.\nWhen i initialy started dropshipping half a lifetime ago it was 2-3hours from starting to promote store to first sales, from posting items on listing sites and driving them to the store to purchase.\n\nWhen we launch a store today its also same day from ads.  \nBut with ads is not as much a question if you drive traffic and get sales with a ok store, its how much do you spend per sale.\n------\nPost ID: 1hcfjg8\nTitle: We\'re a manufacturer from Nepal. I\'ve only recently learned about drop shipping. Is there a specific word for sellers? how do I connect with them?\nScore: 13\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWhat do you manufacture? Cost? Shipping cost and time?\nIm interested in selling for you lets connect @zillymilli instagram\n------\nPost ID: 1hcaa94\nTitle: Dropshipping tips-what to sell in January to make 6fig\nScore: 10\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWinter halt mostly happens in the northern most states, not al around, but the major factor is festive season. Not for all industries like gifting, or clothing, etc. But for manufacturing it becomes a pause.\n------\nPost ID: 1hc7am0\nTitle: Instagram acc 60k\nScore: 19\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI wouldn\'t rebrand it, as the followers are there for the food. Run with that niche.\nInstead of selling t shirts or gimmicks , you could sell recipes or cooking pdfs :)\n------\nPost ID: 1hbuec8\nTitle: Is Aliexpress a good place to start?\nScore: 13\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nAliExpress is fine to start with. Make sure you do some form of product research to ensure there is a market for the product. Figure out how you will market the product before you decide to sell it, ie dont just pick a product (charging station) and market it just as a charging station. You need to pick specific angles that will solve problems for people.\n\nYes you can use images and videos from AliExpress but I would advise to only use high quality ones. Best bet is to purchase the product yourself (or ask the seller for a sample) and take your own. Youll need to anyway for your ad creatives.\nI mean there\'s autoDS but I wouldn\'t suggest it and here\'s why\nhttps://youtu.be/PSOkmzjmWRc?si=bk4NS7HxgKw-2wkj\n\nCheck out the comment section too and you can see how many people dislike using Autods. Some have also been scammed by them too.\n\nAnother is Cjdropshipping\nhttps://youtu.be/gWO9kobS4hE?si=Q_ZNc7J2LwD3k7ZH\nI\'m not even too sure how they\'re running tbh.\n\nThe only app I do recommend using is DSers with AliExpress and here\'s why\nhttps://youtu.be/Ote0twG4Wlo?si=Zku7mCUeLi0bU-Nj\n\nI have plenty of videos that go through AliExpress. I\'ve been using this setup for 3+ years now.\n\nIf the videos and photos are good quality then yes you can use them but the videos don\'t tend to do well for advertisements as they\'re not made for video ads.\n------\nPost ID: 1hbpira\nTitle: Too saturated of a product?\nScore: 5\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nBuild an offer and marketing angles that are different to them.\nCan guarantee you most products sold on the market unless there are trademark products & hard to copy are saturated, in the sense that there are multiple sellers on it.\n\nIt doesnt stop anyone from selling tons of it.\n------\nPost ID: 1hbmlve\nTitle: Is dont-ship dropshipping method real? \nScore: 8\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nNot sure why you watch him. Videos are just pure flex and unrealistic. I\'ve generated over $5M from dropshipping in 4 years and still haven\'t retired my parents. And the fact his friend claims that he doesn\'t ship the items out is pure fraud and stupid. I hope chargebacks creep up on him. He\'s the reason for payment holds and Facebook bans that happen so frequently these days.\n\nScum people with no morals.\n\nIf you want to learn dropshipping the proper way here are all my YouTube videos in order\nhttps://youtube.com/playlist?list=PLep-t3wpCPkWSJcyYiFsELQGLn-wzALvX&si=NAc1csVXnsJgwEXB\nI would not even call that a method, its fraud that gets put a end to very quickly.  \nYou would need to have a already established store that you are willing to sacrifice for a payday (and legal issues afterwards) to get much money out of it.\n\nThis is why you see people starting out with long hold periods, so they can just refund it if you dont deliver and ban you.\n\n>and is able to live like the rest of his dropshipping bros.\n\nAlso you accidently wrote "dropshipping bros" when its "course selling bros".  \nNone of the people in videos like that are making their money dropshipping, they make their money selling you content/courses and affiliate marketing from you signing up to services.\n------\n\n\n    Return only a comma-separated list of post IDs without any additional text.\n    '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 500, 'temperature': 0.7}}
2024-12-14 00:22:16,593 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 00:22:16,593 [DEBUG] connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 00:22:16,723 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10f09be00>
2024-12-14 00:22:16,723 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x10ed6bb60> server_hostname='api.openai.com' timeout=5.0
2024-12-14 00:22:16,762 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12a549090>
2024-12-14 00:22:16,762 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-12-14 00:22:16,763 [DEBUG] send_request_headers.complete
2024-12-14 00:22:16,763 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-12-14 00:22:16,763 [DEBUG] send_request_body.complete
2024-12-14 00:22:16,763 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-12-14 00:22:17,807 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 05:22:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-wfobhzlf64ogbzvuffig3c5l'), (b'openai-processing-ms', b'935'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'196808'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'957ms'), (b'x-request-id', b'req_ad77e9a0cd8fa41ea9759b4e23c72ed2'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=YhzZnSKvBRqAH9Sp1cy3zuZp1tt1goOSyKpa72t5HT8-1734153737-1.0.1.1-Yy.8moZyuc3uCQfkLtPJ4qog4dgITkEZoEtdDymSJppGL4_F9AnLopU_nqzrqhtSR.0QBQyvw.pA9VVfIoh4HA; path=/; expires=Sat, 14-Dec-24 05:52:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=syw93RNbo3Nf.MVB1SHGTV9lGAs2M3fvCh6SP.k2VBA-1734153737846-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f1bc15739d0a918-DFW'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 00:22:17,808 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-14 00:22:17,808 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-12-14 00:22:17,808 [DEBUG] receive_response_body.complete
2024-12-14 00:22:17,809 [DEBUG] response_closed.started
2024-12-14 00:22:17,809 [DEBUG] response_closed.complete
2024-12-14 00:22:17,809 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sat, 14 Dec 2024 05:22:17 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-wfobhzlf64ogbzvuffig3c5l'), ('openai-processing-ms', '935'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '196808'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '957ms'), ('x-request-id', 'req_ad77e9a0cd8fa41ea9759b4e23c72ed2'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=YhzZnSKvBRqAH9Sp1cy3zuZp1tt1goOSyKpa72t5HT8-1734153737-1.0.1.1-Yy.8moZyuc3uCQfkLtPJ4qog4dgITkEZoEtdDymSJppGL4_F9AnLopU_nqzrqhtSR.0QBQyvw.pA9VVfIoh4HA; path=/; expires=Sat, 14-Dec-24 05:52:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=syw93RNbo3Nf.MVB1SHGTV9lGAs2M3fvCh6SP.k2VBA-1734153737846-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f1bc15739d0a918-DFW'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-12-14 00:22:17,809 [DEBUG] request_id: req_ad77e9a0cd8fa41ea9759b4e23c72ed2
2024-12-14 00:22:17,813 [ERROR] Error during filtering with GPT.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 134, in filter_posts_with_gpt
    good_posts_ids = response['choices'][0]['message']['content'].strip()
                     ~~~~~~~~^^^^^^^^^^^
TypeError: 'ChatCompletion' object is not subscriptable
2024-12-14 00:22:17,814 [ERROR] Error in script execution.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 134, in filter_posts_with_gpt
    good_posts_ids = response['choices'][0]['message']['content'].strip()
                     ~~~~~~~~^^^^^^^^^^^
TypeError: 'ChatCompletion' object is not subscriptable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 249, in run_script
    good_posts = filter_posts_with_gpt(posts)
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 140, in filter_posts_with_gpt
    raise RuntimeError(f"Error during filtering: {e}")
RuntimeError: Error during filtering: 'ChatCompletion' object is not subscriptable
2024-12-14 00:25:32,479 [INFO] Successfully connected to the Reddit API.
2024-12-14 00:25:32,480 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734153932.480012
2024-12-14 00:25:32,480 [DEBUG] Data: None
2024-12-14 00:25:32,480 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-14 00:25:32,482 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-14 00:25:33,004 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 655
2024-12-14 00:25:33,007 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-14 00:25:33,987 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 56128
2024-12-14 00:25:34,058 [DEBUG] Response: 200 (56128 bytes) (rst-266:rem-985.0:used-15 ratelimit) at 1734153934.0585248
2024-12-14 00:25:34,070 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdlno3/ at 1734153934.0707579
2024-12-14 00:25:34,070 [DEBUG] Data: None
2024-12-14 00:25:34,071 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:25:34,239 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdlno3/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3127
2024-12-14 00:25:34,240 [DEBUG] Response: 200 (3127 bytes) (rst-265:rem-984.0:used-16 ratelimit) at 1734153934.240845
2024-12-14 00:25:34,242 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdg5rp/ at 1734153934.242568
2024-12-14 00:25:34,242 [DEBUG] Data: None
2024-12-14 00:25:34,243 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:25:34,404 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdg5rp/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3524
2024-12-14 00:25:34,406 [DEBUG] Response: 200 (3524 bytes) (rst-265:rem-983.0:used-17 ratelimit) at 1734153934.406621
2024-12-14 00:25:34,408 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdahzr/ at 1734153934.4084532
2024-12-14 00:25:34,408 [DEBUG] Data: None
2024-12-14 00:25:34,408 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:25:34,552 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdahzr/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2517
2024-12-14 00:25:34,554 [DEBUG] Response: 200 (2517 bytes) (rst-265:rem-982.0:used-18 ratelimit) at 1734153934.554007
2024-12-14 00:25:34,554 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hd2nk7/ at 1734153934.554958
2024-12-14 00:25:34,555 [DEBUG] Data: None
2024-12-14 00:25:34,555 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:25:34,845 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hd2nk7/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7787
2024-12-14 00:25:34,848 [DEBUG] Response: 200 (7787 bytes) (rst-265:rem-981.0:used-19 ratelimit) at 1734153934.848137
2024-12-14 00:25:34,851 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcv8pi/ at 1734153934.851798
2024-12-14 00:25:34,851 [DEBUG] Data: None
2024-12-14 00:25:34,852 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:25:35,017 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcv8pi/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3048
2024-12-14 00:25:35,017 [DEBUG] Response: 200 (3048 bytes) (rst-265:rem-980.0:used-20 ratelimit) at 1734153935.0179331
2024-12-14 00:25:35,018 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hci0sx/ at 1734153935.018833
2024-12-14 00:25:35,018 [DEBUG] Data: None
2024-12-14 00:25:35,019 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:25:35,239 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hci0sx/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6404
2024-12-14 00:25:35,240 [DEBUG] Response: 200 (6404 bytes) (rst-264:rem-979.0:used-21 ratelimit) at 1734153935.240376
2024-12-14 00:25:35,243 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcfjg8/ at 1734153935.2434099
2024-12-14 00:25:35,243 [DEBUG] Data: None
2024-12-14 00:25:35,243 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:25:35,432 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcfjg8/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4258
2024-12-14 00:25:35,434 [DEBUG] Response: 200 (4258 bytes) (rst-264:rem-978.0:used-22 ratelimit) at 1734153935.434947
2024-12-14 00:25:35,437 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcaa94/ at 1734153935.437599
2024-12-14 00:25:35,437 [DEBUG] Data: None
2024-12-14 00:25:35,437 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:25:35,594 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcaa94/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2770
2024-12-14 00:25:35,595 [DEBUG] Response: 200 (2770 bytes) (rst-264:rem-977.0:used-23 ratelimit) at 1734153935.595448
2024-12-14 00:25:35,596 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hc7am0/ at 1734153935.5965161
2024-12-14 00:25:35,596 [DEBUG] Data: None
2024-12-14 00:25:35,596 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:25:35,882 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hc7am0/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7572
2024-12-14 00:25:35,884 [DEBUG] Response: 200 (7572 bytes) (rst-264:rem-976.0:used-24 ratelimit) at 1734153935.8845701
2024-12-14 00:25:35,888 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbuec8/ at 1734153935.888072
2024-12-14 00:25:35,888 [DEBUG] Data: None
2024-12-14 00:25:35,888 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:25:36,113 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbuec8/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6934
2024-12-14 00:25:36,114 [DEBUG] Response: 200 (6934 bytes) (rst-264:rem-975.0:used-25 ratelimit) at 1734153936.1148002
2024-12-14 00:25:36,117 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbpira/ at 1734153936.117245
2024-12-14 00:25:36,117 [DEBUG] Data: None
2024-12-14 00:25:36,117 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:25:36,303 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbpira/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3051
2024-12-14 00:25:36,304 [DEBUG] Response: 200 (3051 bytes) (rst-263:rem-974.0:used-26 ratelimit) at 1734153936.304248
2024-12-14 00:25:36,305 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbmlve/ at 1734153936.305866
2024-12-14 00:25:36,305 [DEBUG] Data: None
2024-12-14 00:25:36,306 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:25:36,500 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbmlve/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4414
2024-12-14 00:25:36,502 [DEBUG] Response: 200 (4414 bytes) (rst-263:rem-973.0:used-27 ratelimit) at 1734153936.502035
2024-12-14 00:25:36,503 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734153936.503953
2024-12-14 00:25:36,504 [DEBUG] Data: None
2024-12-14 00:25:36,504 [DEBUG] Params: {'after': 't3_1h6wpkl', 'limit': 200, 'raw_json': 1}
2024-12-14 00:25:37,298 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h6wpkl&raw_json=1 HTTP/11" 200 49313
2024-12-14 00:25:37,338 [DEBUG] Response: 200 (49313 bytes) (rst-263:rem-972.0:used-28 ratelimit) at 1734153937.338507
2024-12-14 00:25:37,350 [INFO] Fetched and filtered 12 posts.
2024-12-14 00:25:37,363 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\n    You are a helpful assistant. Identify up to 20 good posts.\n\n    Here are the posts:\n    Post ID: 1hdlno3\nTitle: Dropshipping in 2024: A Comedy Special\nScore: 10\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI dont care if this is written by AI. Its rather funny. Especially Day 30. \nThis is clearly written by AI\n------\nPost ID: 1hdg5rp\nTitle: You guys be careful out there\nScore: 4\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nYeah even with legitimate agents, the price of shipping and storage is extortionate.\n\nHere\'s why I still dropship after 4 years and haven\'t transitioned to agent or 3PL\nhttps://youtu.be/l7uSiQ9sHik?si=aQ9_tytfRXjj7Gzu\nYes 100%, I had one reach out to me. Tried to charge almost double more than Aliexpress...\n------\nPost ID: 1hdahzr\nTitle: Trending Niches on TikTok Shop US in December\nScore: 7\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n------\nPost ID: 1hd2nk7\nTitle: I have a TikTok shop for sale, what is a fair price to ask for it?\nScore: 9\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nFor dropshipping stores with that short of a history you would realisticly be looking at 500-750$ area.\n\nDropshipping stores in themself do not sell for nearly the same as normal companies that are in multipliers of annual incomes.  \nAnd with both being limited to a platform like that plus such a short history, you are not even guaranteed to get 3x average monthly profit (and you can not expect to get the holiday peak included in that average).\nGet some Indian to make ads for you, wont cost you too much, if youre making money organically and youre able to get videos for cheap like that, it doesnt make sense not to continue. You could also look at a supplier platform that allows for automatic fulfilment like SP\n------\nPost ID: 1hcv8pi\nTitle: Doing Ok I Guess\nScore: 29\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n>(ironic most people seek the opposite).\n\nMost kids/teens walking into it imagining it being easy money seek it, majority that are older do not really seek it.\n\nDoing something like dropshipping fulltime is something that sounds great intil you actualy do it tends to be the experience.  \nYou tend to start missing the coworkers, meetings etc that you used to somewhat hate.\nKeep moving forward, you got this\n------\nPost ID: 1hci0sx\nTitle: How long did it take for you to make the first sale?\nScore: 10\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI know this doesn\'t answer your question, but I don\'t think furniture is a good niche for dropshipping, especially for a beginner. Just my 2 cents.\nWhen i initialy started dropshipping half a lifetime ago it was 2-3hours from starting to promote store to first sales, from posting items on listing sites and driving them to the store to purchase.\n\nWhen we launch a store today its also same day from ads.  \nBut with ads is not as much a question if you drive traffic and get sales with a ok store, its how much do you spend per sale.\n------\nPost ID: 1hcfjg8\nTitle: We\'re a manufacturer from Nepal. I\'ve only recently learned about drop shipping. Is there a specific word for sellers? how do I connect with them?\nScore: 12\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWhat do you manufacture? Cost? Shipping cost and time?\nIm interested in selling for you lets connect @zillymilli instagram\n------\nPost ID: 1hcaa94\nTitle: Dropshipping tips-what to sell in January to make 6fig\nScore: 12\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWinter halt mostly happens in the northern most states, not al around, but the major factor is festive season. Not for all industries like gifting, or clothing, etc. But for manufacturing it becomes a pause.\n------\nPost ID: 1hc7am0\nTitle: Instagram acc 60k\nScore: 20\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI wouldn\'t rebrand it, as the followers are there for the food. Run with that niche.\nInstead of selling t shirts or gimmicks , you could sell recipes or cooking pdfs :)\n------\nPost ID: 1hbuec8\nTitle: Is Aliexpress a good place to start?\nScore: 15\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nAliExpress is fine to start with. Make sure you do some form of product research to ensure there is a market for the product. Figure out how you will market the product before you decide to sell it, ie dont just pick a product (charging station) and market it just as a charging station. You need to pick specific angles that will solve problems for people.\n\nYes you can use images and videos from AliExpress but I would advise to only use high quality ones. Best bet is to purchase the product yourself (or ask the seller for a sample) and take your own. Youll need to anyway for your ad creatives.\nI mean there\'s autoDS but I wouldn\'t suggest it and here\'s why\nhttps://youtu.be/PSOkmzjmWRc?si=bk4NS7HxgKw-2wkj\n\nCheck out the comment section too and you can see how many people dislike using Autods. Some have also been scammed by them too.\n\nAnother is Cjdropshipping\nhttps://youtu.be/gWO9kobS4hE?si=Q_ZNc7J2LwD3k7ZH\nI\'m not even too sure how they\'re running tbh.\n\nThe only app I do recommend using is DSers with AliExpress and here\'s why\nhttps://youtu.be/Ote0twG4Wlo?si=Zku7mCUeLi0bU-Nj\n\nI have plenty of videos that go through AliExpress. I\'ve been using this setup for 3+ years now.\n\nIf the videos and photos are good quality then yes you can use them but the videos don\'t tend to do well for advertisements as they\'re not made for video ads.\n------\nPost ID: 1hbpira\nTitle: Too saturated of a product?\nScore: 6\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nBuild an offer and marketing angles that are different to them.\nCan guarantee you most products sold on the market unless there are trademark products & hard to copy are saturated, in the sense that there are multiple sellers on it.\n\nIt doesnt stop anyone from selling tons of it.\n------\nPost ID: 1hbmlve\nTitle: Is dont-ship dropshipping method real? \nScore: 7\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nNot sure why you watch him. Videos are just pure flex and unrealistic. I\'ve generated over $5M from dropshipping in 4 years and still haven\'t retired my parents. And the fact his friend claims that he doesn\'t ship the items out is pure fraud and stupid. I hope chargebacks creep up on him. He\'s the reason for payment holds and Facebook bans that happen so frequently these days.\n\nScum people with no morals.\n\nIf you want to learn dropshipping the proper way here are all my YouTube videos in order\nhttps://youtube.com/playlist?list=PLep-t3wpCPkWSJcyYiFsELQGLn-wzALvX&si=NAc1csVXnsJgwEXB\nI would not even call that a method, its fraud that gets put a end to very quickly.  \nYou would need to have a already established store that you are willing to sacrifice for a payday (and legal issues afterwards) to get much money out of it.\n\nThis is why you see people starting out with long hold periods, so they can just refund it if you dont deliver and ban you.\n\n>and is able to live like the rest of his dropshipping bros.\n\nAlso you accidently wrote "dropshipping bros" when its "course selling bros".  \nNone of the people in videos like that are making their money dropshipping, they make their money selling you content/courses and affiliate marketing from you signing up to services.\n------\n\n\n    Return only a comma-separated list of post IDs without any additional text.\n    '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 500, 'temperature': 0.7}}
2024-12-14 00:25:37,389 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 00:25:37,389 [DEBUG] connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 00:25:37,422 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10c563e00>
2024-12-14 00:25:37,422 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x10c4c3ad0> server_hostname='api.openai.com' timeout=5.0
2024-12-14 00:25:37,459 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11cb791d0>
2024-12-14 00:25:37,459 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-12-14 00:25:37,459 [DEBUG] send_request_headers.complete
2024-12-14 00:25:37,459 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-12-14 00:25:37,459 [DEBUG] send_request_body.complete
2024-12-14 00:25:37,459 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-12-14 00:25:38,425 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 05:25:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-wfobhzlf64ogbzvuffig3c5l'), (b'openai-processing-ms', b'853'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'196808'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'957ms'), (b'x-request-id', b'req_699621b8412eae54759c3908f426e5b2'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=7FPKvVbSJOgjLUxKPTtYjMfZihgky_W_ZM0772_OYH4-1734153938-1.0.1.1-znJHymcGmjkiKr6riekFuoUsO9LvTxVgie69jQ2o.gXNUBbbQfDRpDXYI1TyHct7Hw9_Um0ue_Nj5_s0IQuN2Q; path=/; expires=Sat, 14-Dec-24 05:55:38 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=C8bsD6X4nzAg4uu.mXKAk0tywKVIPQUvQ81.w2JkmRY-1734153938465-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f1bc63d9826469b-DFW'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 00:25:38,426 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-14 00:25:38,426 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-12-14 00:25:38,427 [DEBUG] receive_response_body.complete
2024-12-14 00:25:38,427 [DEBUG] response_closed.started
2024-12-14 00:25:38,427 [DEBUG] response_closed.complete
2024-12-14 00:25:38,427 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sat, 14 Dec 2024 05:25:38 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-wfobhzlf64ogbzvuffig3c5l'), ('openai-processing-ms', '853'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '196808'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '957ms'), ('x-request-id', 'req_699621b8412eae54759c3908f426e5b2'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=7FPKvVbSJOgjLUxKPTtYjMfZihgky_W_ZM0772_OYH4-1734153938-1.0.1.1-znJHymcGmjkiKr6riekFuoUsO9LvTxVgie69jQ2o.gXNUBbbQfDRpDXYI1TyHct7Hw9_Um0ue_Nj5_s0IQuN2Q; path=/; expires=Sat, 14-Dec-24 05:55:38 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=C8bsD6X4nzAg4uu.mXKAk0tywKVIPQUvQ81.w2JkmRY-1734153938465-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f1bc63d9826469b-DFW'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-12-14 00:25:38,427 [DEBUG] request_id: req_699621b8412eae54759c3908f426e5b2
2024-12-14 00:25:38,431 [INFO] GPT-3.5 identified 12 good posts.
2024-12-14 00:25:38,444 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': "\n        Analyze these posts from r/dropship:\n\n        Post ID: 1hdlno3\nTitle: Dropshipping in 2024: A Comedy Special\nScore: 10\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI dont care if this is written by AI. Its rather funny. Especially Day 30. \nThis is clearly written by AI\n------\n\n\nPost ID: 1hdg5rp\nTitle: You guys be careful out there\nScore: 4\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nYeah even with legitimate agents, the price of shipping and storage is extortionate.\n\nHere's why I still dropship after 4 years and haven't transitioned to agent or 3PL\nhttps://youtu.be/l7uSiQ9sHik?si=aQ9_tytfRXjj7Gzu\nYes 100%, I had one reach out to me. Tried to charge almost double more than Aliexpress...\n------\n\n\nPost ID: 1hdahzr\nTitle: Trending Niches on TikTok Shop US in December\nScore: 7\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n------\n\n\nPost ID: 1hd2nk7\nTitle: I have a TikTok shop for sale, what is a fair price to ask for it?\nScore: 9\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nFor dropshipping stores with that short of a history you would realisticly be looking at 500-750$ area.\n\nDropshipping stores in themself do not sell for nearly the same as normal companies that are in multipliers of annual incomes.  \nAnd with both being limited to a platform like that plus such a short history, you are not even guaranteed to get 3x average monthly profit (and you can not expect to get the holiday peak included in that average).\nGet some Indian to make ads for you, wont cost you too much, if youre making money organically and youre able to get videos for cheap like that, it doesnt make sense not to continue. You could also look at a supplier platform that allows for automatic fulfilment like SP\n------\n\n\nPost ID: 1hcv8pi\nTitle: Doing Ok I Guess\nScore: 29\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n>(ironic most people seek the opposite).\n\nMost kids/teens walking into it imagining it being easy money seek it, majority that are older do not really seek it.\n\nDoing something like dropshipping fulltime is something that sounds great intil you actualy do it tends to be the experience.  \nYou tend to start missing the coworkers, meetings etc that you used to somewhat hate.\nKeep moving forward, you got this\n------\n\n\nPost ID: 1hci0sx\nTitle: How long did it take for you to make the first sale?\nScore: 10\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI know this doesn't answer your question, but I don't think furniture is a good niche for dropshipping, especially for a beginner. Just my 2 cents.\nWhen i initialy started dropshipping half a lifetime ago it was 2-3hours from starting to promote store to first sales, from posting items on listing sites and driving them to the store to purchase.\n\nWhen we launch a store today its also same day from ads.  \nBut with ads is not as much a question if you drive traffic and get sales with a ok store, its how much do you spend per sale.\n------\n\n\nPost ID: 1hcfjg8\nTitle: We're a manufacturer from Nepal. I've only recently learned about drop shipping. Is there a specific word for sellers? how do I connect with them?\nScore: 12\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWhat do you manufacture? Cost? Shipping cost and time?\nIm interested in selling for you lets connect @zillymilli instagram\n------\n\n\nPost ID: 1hcaa94\nTitle: Dropshipping tips-what to sell in January to make 6fig\nScore: 12\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWinter halt mostly happens in the northern most states, not al around, but the major factor is festive season. Not for all industries like gifting, or clothing, etc. But for manufacturing it becomes a pause.\n------\n\n\nPost ID: 1hc7am0\nTitle: Instagram acc 60k\nScore: 20\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI wouldn't rebrand it, as the followers are there for the food. Run with that niche.\nInstead of selling t shirts or gimmicks , you could sell recipes or cooking pdfs :)\n------\n\n\nPost ID: 1hbuec8\nTitle: Is Aliexpress a good place to start?\nScore: 15\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nAliExpress is fine to start with. Make sure you do some form of product research to ensure there is a market for the product. Figure out how you will market the product before you decide to sell it, ie dont just pick a product (charging station) and market it just as a charging station. You need to pick specific angles that will solve problems for people.\n\nYes you can use images and videos from AliExpress but I would advise to only use high quality ones. Best bet is to purchase the product yourself (or ask the seller for a sample) and take your own. Youll need to anyway for your ad creatives.\nI mean there's autoDS but I wouldn't suggest it and here's why\nhttps://youtu.be/PSOkmzjmWRc?si=bk4NS7HxgKw-2wkj\n\nCheck out the comment section too and you can see how many people dislike using Autods. Some have also been scammed by them too.\n\nAnother is Cjdropshipping\nhttps://youtu.be/gWO9kobS4hE?si=Q_ZNc7J2LwD3k7ZH\nI'm not even too sure how they're running tbh.\n\nThe only app I do recommend using is DSers with AliExpress and here's why\nhttps://youtu.be/Ote0twG4Wlo?si=Zku7mCUeLi0bU-Nj\n\nI have plenty of videos that go through AliExpress. I've been using this setup for 3+ years now.\n\nIf the videos and photos are good quality then yes you can use them but the videos don't tend to do well for advertisements as they're not made for video ads.\n------\n\n\n        Provide insights, trends, or recommendations based on these posts.\n        "}], 'model': 'gpt-4', 'max_tokens': 3000, 'temperature': 0.7}}
2024-12-14 00:25:38,444 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 00:25:38,445 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-12-14 00:25:38,445 [DEBUG] send_request_headers.complete
2024-12-14 00:25:38,445 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-12-14 00:25:38,445 [DEBUG] send_request_body.complete
2024-12-14 00:25:38,445 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-12-14 00:25:38,542 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 403, b'Forbidden', [(b'Date', b'Sat, 14 Dec 2024 05:25:38 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_6234df34bf3386bace5bddba504ccb8b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f1bc643cf6e469b-DFW'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 00:25:38,542 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 403 Forbidden"
2024-12-14 00:25:38,542 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-12-14 00:25:38,543 [DEBUG] receive_response_body.complete
2024-12-14 00:25:38,543 [DEBUG] response_closed.started
2024-12-14 00:25:38,543 [DEBUG] response_closed.complete
2024-12-14 00:25:38,543 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "403 Forbidden" Headers({'date': 'Sat, 14 Dec 2024 05:25:38 GMT', 'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_6234df34bf3386bace5bddba504ccb8b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f1bc643cf6e469b-DFW', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 00:25:38,543 [DEBUG] request_id: req_6234df34bf3386bace5bddba504ccb8b
2024-12-14 00:25:38,543 [DEBUG] Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/chrisgaya/Library/Python/3.13/lib/python/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
2024-12-14 00:25:38,546 [DEBUG] Not retrying
2024-12-14 00:25:38,547 [DEBUG] Re-raising status error
2024-12-14 00:25:38,547 [ERROR] Error during analysis with GPT-4.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 156, in analyze_posts_with_gpt4
    response = client.chat.completions.create(
        model="gpt-4",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/resources/chat/completions.py", line 829, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<39 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_base_client.py", line 1280, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_base_client.py", line 957, in request
    return self._request(
           ~~~~~~~~~~~~~^
        cast_to=cast_to,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        retries_taken=retries_taken,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_base_client.py", line 1061, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.PermissionDeniedError: Error code: 403 - {'error': {'message': 'Project `proj_cEihw5JpNgQ1p6L2NbLCoiTW` does not have access to model `gpt-4`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
2024-12-14 00:25:38,551 [ERROR] Error in script execution.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 156, in analyze_posts_with_gpt4
    response = client.chat.completions.create(
        model="gpt-4",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/resources/chat/completions.py", line 829, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<39 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_base_client.py", line 1280, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_base_client.py", line 957, in request
    return self._request(
           ~~~~~~~~~~~~~^
        cast_to=cast_to,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        retries_taken=retries_taken,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_base_client.py", line 1061, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.PermissionDeniedError: Error code: 403 - {'error': {'message': 'Project `proj_cEihw5JpNgQ1p6L2NbLCoiTW` does not have access to model `gpt-4`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 264, in run_script
    analysis = analyze_posts_with_gpt4(good_posts, subreddit_name)
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 171, in analyze_posts_with_gpt4
    raise RuntimeError(f"Error during analysis: {e}")
RuntimeError: Error during analysis: Error code: 403 - {'error': {'message': 'Project `proj_cEihw5JpNgQ1p6L2NbLCoiTW` does not have access to model `gpt-4`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
2024-12-14 00:26:10,074 [DEBUG] close.started
2024-12-14 00:26:10,074 [DEBUG] close.complete
2024-12-14 00:26:14,573 [INFO] Successfully connected to the Reddit API.
2024-12-14 00:26:14,574 [DEBUG] Fetching: GET https://oauth.reddit.com/r/test/new at 1734153974.574019
2024-12-14 00:26:14,574 [DEBUG] Data: None
2024-12-14 00:26:14,574 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-14 00:26:14,575 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-14 00:26:15,091 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 656
2024-12-14 00:26:15,095 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-14 00:26:15,989 [DEBUG] https://oauth.reddit.com:443 "GET /r/test/new?limit=200&raw_json=1 HTTP/11" 200 41304
2024-12-14 00:26:16,043 [DEBUG] Response: 200 (41304 bytes) (rst-224:rem-971.0:used-29 ratelimit) at 1734153976.043881
2024-12-14 00:26:16,056 [DEBUG] Fetching: GET https://oauth.reddit.com/r/test/new at 1734153976.056274
2024-12-14 00:26:16,056 [DEBUG] Data: None
2024-12-14 00:26:16,056 [DEBUG] Params: {'after': 't3_1hb30qc', 'limit': 200, 'raw_json': 1}
2024-12-14 00:26:16,943 [DEBUG] https://oauth.reddit.com:443 "GET /r/test/new?limit=200&after=t3_1hb30qc&raw_json=1 HTTP/11" 200 44428
2024-12-14 00:26:16,981 [DEBUG] Response: 200 (44428 bytes) (rst-223:rem-970.0:used-30 ratelimit) at 1734153976.981411
2024-12-14 00:26:16,994 [INFO] Fetched and filtered 0 posts.
2024-12-14 00:26:22,827 [INFO] Successfully connected to the Reddit API.
2024-12-14 00:26:22,827 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734153982.8275871
2024-12-14 00:26:22,827 [DEBUG] Data: None
2024-12-14 00:26:22,827 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-14 00:26:22,828 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-14 00:26:23,351 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 654
2024-12-14 00:26:23,353 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-14 00:26:24,269 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 56184
2024-12-14 00:26:24,339 [DEBUG] Response: 200 (56184 bytes) (rst-216:rem-969.0:used-31 ratelimit) at 1734153984.338997
2024-12-14 00:26:24,357 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdo31p/ at 1734153984.3570418
2024-12-14 00:26:24,357 [DEBUG] Data: None
2024-12-14 00:26:24,357 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:26:24,528 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdo31p/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3729
2024-12-14 00:26:24,529 [DEBUG] Response: 200 (3729 bytes) (rst-215:rem-968.0:used-32 ratelimit) at 1734153984.5296152
2024-12-14 00:26:24,531 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdlno3/ at 1734153984.531977
2024-12-14 00:26:24,532 [DEBUG] Data: None
2024-12-14 00:26:24,532 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:26:24,703 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdlno3/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3122
2024-12-14 00:26:24,704 [DEBUG] Response: 200 (3122 bytes) (rst-215:rem-967.0:used-33 ratelimit) at 1734153984.704894
2024-12-14 00:26:24,706 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdahzr/ at 1734153984.70629
2024-12-14 00:26:24,706 [DEBUG] Data: None
2024-12-14 00:26:24,706 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:26:24,855 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdahzr/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2519
2024-12-14 00:26:24,856 [DEBUG] Response: 200 (2519 bytes) (rst-215:rem-966.0:used-34 ratelimit) at 1734153984.85628
2024-12-14 00:26:24,857 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hd2nk7/ at 1734153984.85775
2024-12-14 00:26:24,857 [DEBUG] Data: None
2024-12-14 00:26:24,858 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:26:25,119 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hd2nk7/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7785
2024-12-14 00:26:25,121 [DEBUG] Response: 200 (7785 bytes) (rst-215:rem-965.0:used-35 ratelimit) at 1734153985.121071
2024-12-14 00:26:25,125 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcv8pi/ at 1734153985.1254442
2024-12-14 00:26:25,125 [DEBUG] Data: None
2024-12-14 00:26:25,125 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:26:25,304 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcv8pi/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3048
2024-12-14 00:26:25,305 [DEBUG] Response: 200 (3048 bytes) (rst-214:rem-964.0:used-36 ratelimit) at 1734153985.305268
2024-12-14 00:26:25,306 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hci0sx/ at 1734153985.306648
2024-12-14 00:26:25,306 [DEBUG] Data: None
2024-12-14 00:26:25,306 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:26:25,546 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hci0sx/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6411
2024-12-14 00:26:25,548 [DEBUG] Response: 200 (6411 bytes) (rst-214:rem-963.0:used-37 ratelimit) at 1734153985.548637
2024-12-14 00:26:25,552 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcfjg8/ at 1734153985.552845
2024-12-14 00:26:25,552 [DEBUG] Data: None
2024-12-14 00:26:25,553 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:26:25,796 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcfjg8/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4256
2024-12-14 00:26:25,797 [DEBUG] Response: 200 (4256 bytes) (rst-214:rem-962.0:used-38 ratelimit) at 1734153985.797641
2024-12-14 00:26:25,800 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcaa94/ at 1734153985.8006752
2024-12-14 00:26:25,800 [DEBUG] Data: None
2024-12-14 00:26:25,800 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:26:25,951 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcaa94/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2770
2024-12-14 00:26:25,952 [DEBUG] Response: 200 (2770 bytes) (rst-214:rem-961.0:used-39 ratelimit) at 1734153985.9523041
2024-12-14 00:26:25,953 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hc7am0/ at 1734153985.953836
2024-12-14 00:26:25,953 [DEBUG] Data: None
2024-12-14 00:26:25,954 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:26:26,219 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hc7am0/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7570
2024-12-14 00:26:26,220 [DEBUG] Response: 200 (7570 bytes) (rst-213:rem-960.0:used-40 ratelimit) at 1734153986.2206268
2024-12-14 00:26:26,224 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbuec8/ at 1734153986.224629
2024-12-14 00:26:26,224 [DEBUG] Data: None
2024-12-14 00:26:26,224 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:26:26,448 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbuec8/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6933
2024-12-14 00:26:26,451 [DEBUG] Response: 200 (6933 bytes) (rst-213:rem-959.0:used-41 ratelimit) at 1734153986.451226
2024-12-14 00:26:26,455 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbpira/ at 1734153986.455158
2024-12-14 00:26:26,455 [DEBUG] Data: None
2024-12-14 00:26:26,455 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:26:26,641 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbpira/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3057
2024-12-14 00:26:26,642 [DEBUG] Response: 200 (3057 bytes) (rst-213:rem-958.0:used-42 ratelimit) at 1734153986.6429381
2024-12-14 00:26:26,644 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hbmlve/ at 1734153986.644418
2024-12-14 00:26:26,644 [DEBUG] Data: None
2024-12-14 00:26:26,644 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 00:26:26,913 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hbmlve/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4416
2024-12-14 00:26:26,915 [DEBUG] Response: 200 (4416 bytes) (rst-213:rem-957.0:used-43 ratelimit) at 1734153986.915796
2024-12-14 00:26:26,917 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734153986.917702
2024-12-14 00:26:26,917 [DEBUG] Data: None
2024-12-14 00:26:26,917 [DEBUG] Params: {'after': 't3_1h6wpkl', 'limit': 200, 'raw_json': 1}
2024-12-14 00:26:27,773 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h6wpkl&raw_json=1 HTTP/11" 200 49293
2024-12-14 00:26:27,812 [DEBUG] Response: 200 (49293 bytes) (rst-212:rem-956.0:used-44 ratelimit) at 1734153987.812771
2024-12-14 00:26:27,826 [INFO] Fetched and filtered 12 posts.
2024-12-14 00:26:27,839 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\n    You are a helpful assistant. Identify up to 20 good posts.\n\n    Here are the posts:\n    Post ID: 1hdo31p\nTitle: Is email marketing worth the time and money for small e-commerce businesses?\nScore: 4\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI think yes. I plan on working more on this next year and have a decent list to start of people who have signed up to a newsletter.\n\nIt shouldn\'t be costly at all when you start as free plans are provided with limitations. Once you start seeing results you can then invest money.\n\nIf you\'re just cold calling you\'ll land in spam folders and that\'s pointless. Get people to sign up and verify your domain so you land in their actual inbox!\nYep! I was doing 30%+ of my revenue through email. And it was incremental revenue. \n\nYou dont have to overbake it. \n\n1. Text emails are underrated. \n2. For HTML emails, get a solid template designed up and then its easy to swap in new creative each time. Canva is your friend or get someone on Fiverr to help. \n3. Set up a few smart automationsmight take you an hourand then establish a send cadence; maybe one email a week. Again, this shouldnt take more than 30-60 minutes an email. Time well spent. Provides youve got a database of course. \n4. If your database is tinyunder 50you could even just send the odd email directly to key customers. Hey, John here. Im the owner of XYZ Just wanted to mention\n------\nPost ID: 1hdlno3\nTitle: Dropshipping in 2024: A Comedy Special\nScore: 11\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI dont care if this is written by AI. Its rather funny. Especially Day 30. \nThis is clearly written by AI\n------\nPost ID: 1hdahzr\nTitle: Trending Niches on TikTok Shop US in December\nScore: 6\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n------\nPost ID: 1hd2nk7\nTitle: I have a TikTok shop for sale, what is a fair price to ask for it?\nScore: 9\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nFor dropshipping stores with that short of a history you would realisticly be looking at 500-750$ area.\n\nDropshipping stores in themself do not sell for nearly the same as normal companies that are in multipliers of annual incomes.  \nAnd with both being limited to a platform like that plus such a short history, you are not even guaranteed to get 3x average monthly profit (and you can not expect to get the holiday peak included in that average).\nGet some Indian to make ads for you, wont cost you too much, if youre making money organically and youre able to get videos for cheap like that, it doesnt make sense not to continue. You could also look at a supplier platform that allows for automatic fulfilment like SP\n------\nPost ID: 1hcv8pi\nTitle: Doing Ok I Guess\nScore: 30\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n>(ironic most people seek the opposite).\n\nMost kids/teens walking into it imagining it being easy money seek it, majority that are older do not really seek it.\n\nDoing something like dropshipping fulltime is something that sounds great intil you actualy do it tends to be the experience.  \nYou tend to start missing the coworkers, meetings etc that you used to somewhat hate.\nKeep moving forward, you got this\n------\nPost ID: 1hci0sx\nTitle: How long did it take for you to make the first sale?\nScore: 11\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI know this doesn\'t answer your question, but I don\'t think furniture is a good niche for dropshipping, especially for a beginner. Just my 2 cents.\nWhen i initialy started dropshipping half a lifetime ago it was 2-3hours from starting to promote store to first sales, from posting items on listing sites and driving them to the store to purchase.\n\nWhen we launch a store today its also same day from ads.  \nBut with ads is not as much a question if you drive traffic and get sales with a ok store, its how much do you spend per sale.\n------\nPost ID: 1hcfjg8\nTitle: We\'re a manufacturer from Nepal. I\'ve only recently learned about drop shipping. Is there a specific word for sellers? how do I connect with them?\nScore: 12\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWhat do you manufacture? Cost? Shipping cost and time?\nIm interested in selling for you lets connect @zillymilli instagram\n------\nPost ID: 1hcaa94\nTitle: Dropshipping tips-what to sell in January to make 6fig\nScore: 10\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWinter halt mostly happens in the northern most states, not al around, but the major factor is festive season. Not for all industries like gifting, or clothing, etc. But for manufacturing it becomes a pause.\n------\nPost ID: 1hc7am0\nTitle: Instagram acc 60k\nScore: 19\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI wouldn\'t rebrand it, as the followers are there for the food. Run with that niche.\nInstead of selling t shirts or gimmicks , you could sell recipes or cooking pdfs :)\n------\nPost ID: 1hbuec8\nTitle: Is Aliexpress a good place to start?\nScore: 14\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nAliExpress is fine to start with. Make sure you do some form of product research to ensure there is a market for the product. Figure out how you will market the product before you decide to sell it, ie dont just pick a product (charging station) and market it just as a charging station. You need to pick specific angles that will solve problems for people.\n\nYes you can use images and videos from AliExpress but I would advise to only use high quality ones. Best bet is to purchase the product yourself (or ask the seller for a sample) and take your own. Youll need to anyway for your ad creatives.\nI mean there\'s autoDS but I wouldn\'t suggest it and here\'s why\nhttps://youtu.be/PSOkmzjmWRc?si=bk4NS7HxgKw-2wkj\n\nCheck out the comment section too and you can see how many people dislike using Autods. Some have also been scammed by them too.\n\nAnother is Cjdropshipping\nhttps://youtu.be/gWO9kobS4hE?si=Q_ZNc7J2LwD3k7ZH\nI\'m not even too sure how they\'re running tbh.\n\nThe only app I do recommend using is DSers with AliExpress and here\'s why\nhttps://youtu.be/Ote0twG4Wlo?si=Zku7mCUeLi0bU-Nj\n\nI have plenty of videos that go through AliExpress. I\'ve been using this setup for 3+ years now.\n\nIf the videos and photos are good quality then yes you can use them but the videos don\'t tend to do well for advertisements as they\'re not made for video ads.\n------\nPost ID: 1hbpira\nTitle: Too saturated of a product?\nScore: 6\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nBuild an offer and marketing angles that are different to them.\nCan guarantee you most products sold on the market unless there are trademark products & hard to copy are saturated, in the sense that there are multiple sellers on it.\n\nIt doesnt stop anyone from selling tons of it.\n------\nPost ID: 1hbmlve\nTitle: Is dont-ship dropshipping method real? \nScore: 7\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nNot sure why you watch him. Videos are just pure flex and unrealistic. I\'ve generated over $5M from dropshipping in 4 years and still haven\'t retired my parents. And the fact his friend claims that he doesn\'t ship the items out is pure fraud and stupid. I hope chargebacks creep up on him. He\'s the reason for payment holds and Facebook bans that happen so frequently these days.\n\nScum people with no morals.\n\nIf you want to learn dropshipping the proper way here are all my YouTube videos in order\nhttps://youtube.com/playlist?list=PLep-t3wpCPkWSJcyYiFsELQGLn-wzALvX&si=NAc1csVXnsJgwEXB\nI would not even call that a method, its fraud that gets put a end to very quickly.  \nYou would need to have a already established store that you are willing to sacrifice for a payday (and legal issues afterwards) to get much money out of it.\n\nThis is why you see people starting out with long hold periods, so they can just refund it if you dont deliver and ban you.\n\n>and is able to live like the rest of his dropshipping bros.\n\nAlso you accidently wrote "dropshipping bros" when its "course selling bros".  \nNone of the people in videos like that are making their money dropshipping, they make their money selling you content/courses and affiliate marketing from you signing up to services.\n------\n\n\n    Return only a comma-separated list of post IDs without any additional text.\n    '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 500, 'temperature': 0.7}}
2024-12-14 00:26:27,857 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 00:26:27,858 [DEBUG] connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 00:26:27,944 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107351be0>
2024-12-14 00:26:27,945 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x1072b3ad0> server_hostname='api.openai.com' timeout=5.0
2024-12-14 00:26:27,985 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x130c75a90>
2024-12-14 00:26:27,986 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-12-14 00:26:27,986 [DEBUG] send_request_headers.complete
2024-12-14 00:26:27,986 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-12-14 00:26:27,986 [DEBUG] send_request_body.complete
2024-12-14 00:26:27,986 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-12-14 00:26:28,888 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 05:26:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-wfobhzlf64ogbzvuffig3c5l'), (b'openai-processing-ms', b'781'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'196578'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'1.026s'), (b'x-request-id', b'req_8fd5df77d1da8328730595f6c1f92862'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ZkzMeDg3NozsQLnF6WnKhvTfivnlmvmOgCMu.fU7.ag-1734153988-1.0.1.1-XqrA35IM_r6yxknSxbIAIZ.bu1905t6.YePF8PyPQY9CyJs_u8R1DckG1A0bbirBqG1cjuIO9H9HH6_pdm9jqg; path=/; expires=Sat, 14-Dec-24 05:56:28 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=yNNriEqN22oI49yagMmjagJ6Pnbf_CCB7PCPSnj7l4s-1734153988929-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f1bc7796d902fd8-DFW'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 00:26:28,889 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-14 00:26:28,889 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-12-14 00:26:28,893 [DEBUG] receive_response_body.complete
2024-12-14 00:26:28,893 [DEBUG] response_closed.started
2024-12-14 00:26:28,893 [DEBUG] response_closed.complete
2024-12-14 00:26:28,893 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sat, 14 Dec 2024 05:26:28 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-wfobhzlf64ogbzvuffig3c5l'), ('openai-processing-ms', '781'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '196578'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '1.026s'), ('x-request-id', 'req_8fd5df77d1da8328730595f6c1f92862'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=ZkzMeDg3NozsQLnF6WnKhvTfivnlmvmOgCMu.fU7.ag-1734153988-1.0.1.1-XqrA35IM_r6yxknSxbIAIZ.bu1905t6.YePF8PyPQY9CyJs_u8R1DckG1A0bbirBqG1cjuIO9H9HH6_pdm9jqg; path=/; expires=Sat, 14-Dec-24 05:56:28 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=yNNriEqN22oI49yagMmjagJ6Pnbf_CCB7PCPSnj7l4s-1734153988929-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f1bc7796d902fd8-DFW'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-12-14 00:26:28,893 [DEBUG] request_id: req_8fd5df77d1da8328730595f6c1f92862
2024-12-14 00:26:28,899 [INFO] GPT-3.5 identified 12 good posts.
2024-12-14 00:26:28,913 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': "\n        Analyze these posts from r/dropship:\n\n        Post ID: 1hdo31p\nTitle: Is email marketing worth the time and money for small e-commerce businesses?\nScore: 4\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI think yes. I plan on working more on this next year and have a decent list to start of people who have signed up to a newsletter.\n\nIt shouldn't be costly at all when you start as free plans are provided with limitations. Once you start seeing results you can then invest money.\n\nIf you're just cold calling you'll land in spam folders and that's pointless. Get people to sign up and verify your domain so you land in their actual inbox!\nYep! I was doing 30%+ of my revenue through email. And it was incremental revenue. \n\nYou dont have to overbake it. \n\n1. Text emails are underrated. \n2. For HTML emails, get a solid template designed up and then its easy to swap in new creative each time. Canva is your friend or get someone on Fiverr to help. \n3. Set up a few smart automationsmight take you an hourand then establish a send cadence; maybe one email a week. Again, this shouldnt take more than 30-60 minutes an email. Time well spent. Provides youve got a database of course. \n4. If your database is tinyunder 50you could even just send the odd email directly to key customers. Hey, John here. Im the owner of XYZ Just wanted to mention\n------\n\n\nPost ID: 1hdlno3\nTitle: Dropshipping in 2024: A Comedy Special\nScore: 11\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI dont care if this is written by AI. Its rather funny. Especially Day 30. \nThis is clearly written by AI\n------\n\n\nPost ID: 1hdahzr\nTitle: Trending Niches on TikTok Shop US in December\nScore: 6\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n------\n\n\nPost ID: 1hd2nk7\nTitle: I have a TikTok shop for sale, what is a fair price to ask for it?\nScore: 9\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nFor dropshipping stores with that short of a history you would realisticly be looking at 500-750$ area.\n\nDropshipping stores in themself do not sell for nearly the same as normal companies that are in multipliers of annual incomes.  \nAnd with both being limited to a platform like that plus such a short history, you are not even guaranteed to get 3x average monthly profit (and you can not expect to get the holiday peak included in that average).\nGet some Indian to make ads for you, wont cost you too much, if youre making money organically and youre able to get videos for cheap like that, it doesnt make sense not to continue. You could also look at a supplier platform that allows for automatic fulfilment like SP\n------\n\n\nPost ID: 1hcv8pi\nTitle: Doing Ok I Guess\nScore: 30\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n>(ironic most people seek the opposite).\n\nMost kids/teens walking into it imagining it being easy money seek it, majority that are older do not really seek it.\n\nDoing something like dropshipping fulltime is something that sounds great intil you actualy do it tends to be the experience.  \nYou tend to start missing the coworkers, meetings etc that you used to somewhat hate.\nKeep moving forward, you got this\n------\n\n\nPost ID: 1hci0sx\nTitle: How long did it take for you to make the first sale?\nScore: 11\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI know this doesn't answer your question, but I don't think furniture is a good niche for dropshipping, especially for a beginner. Just my 2 cents.\nWhen i initialy started dropshipping half a lifetime ago it was 2-3hours from starting to promote store to first sales, from posting items on listing sites and driving them to the store to purchase.\n\nWhen we launch a store today its also same day from ads.  \nBut with ads is not as much a question if you drive traffic and get sales with a ok store, its how much do you spend per sale.\n------\n\n\nPost ID: 1hcfjg8\nTitle: We're a manufacturer from Nepal. I've only recently learned about drop shipping. Is there a specific word for sellers? how do I connect with them?\nScore: 12\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWhat do you manufacture? Cost? Shipping cost and time?\nIm interested in selling for you lets connect @zillymilli instagram\n------\n\n\nPost ID: 1hcaa94\nTitle: Dropshipping tips-what to sell in January to make 6fig\nScore: 10\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWinter halt mostly happens in the northern most states, not al around, but the major factor is festive season. Not for all industries like gifting, or clothing, etc. But for manufacturing it becomes a pause.\n------\n\n\nPost ID: 1hc7am0\nTitle: Instagram acc 60k\nScore: 19\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI wouldn't rebrand it, as the followers are there for the food. Run with that niche.\nInstead of selling t shirts or gimmicks , you could sell recipes or cooking pdfs :)\n------\n\n\nPost ID: 1hbuec8\nTitle: Is Aliexpress a good place to start?\nScore: 14\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nAliExpress is fine to start with. Make sure you do some form of product research to ensure there is a market for the product. Figure out how you will market the product before you decide to sell it, ie dont just pick a product (charging station) and market it just as a charging station. You need to pick specific angles that will solve problems for people.\n\nYes you can use images and videos from AliExpress but I would advise to only use high quality ones. Best bet is to purchase the product yourself (or ask the seller for a sample) and take your own. Youll need to anyway for your ad creatives.\nI mean there's autoDS but I wouldn't suggest it and here's why\nhttps://youtu.be/PSOkmzjmWRc?si=bk4NS7HxgKw-2wkj\n\nCheck out the comment section too and you can see how many people dislike using Autods. Some have also been scammed by them too.\n\nAnother is Cjdropshipping\nhttps://youtu.be/gWO9kobS4hE?si=Q_ZNc7J2LwD3k7ZH\nI'm not even too sure how they're running tbh.\n\nThe only app I do recommend using is DSers with AliExpress and here's why\nhttps://youtu.be/Ote0twG4Wlo?si=Zku7mCUeLi0bU-Nj\n\nI have plenty of videos that go through AliExpress. I've been using this setup for 3+ years now.\n\nIf the videos and photos are good quality then yes you can use them but the videos don't tend to do well for advertisements as they're not made for video ads.\n------\n\n\n        Provide insights, trends, or recommendations based on these posts.\n        "}], 'model': 'gpt-4-turbo', 'max_tokens': 3000, 'temperature': 0.7}}
2024-12-14 00:26:28,913 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 00:26:28,914 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-12-14 00:26:28,914 [DEBUG] send_request_headers.complete
2024-12-14 00:26:28,914 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-12-14 00:26:28,914 [DEBUG] send_request_body.complete
2024-12-14 00:26:28,914 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-12-14 00:26:42,589 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 05:26:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-wfobhzlf64ogbzvuffig3c5l'), (b'openai-processing-ms', b'13553'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'24678'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'10.644s'), (b'x-request-id', b'req_91a7d114fea589d4654f1b87452e7a16'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f1bc77f3b732fd8-DFW'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 00:26:42,589 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-14 00:26:42,590 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-12-14 00:26:42,590 [DEBUG] receive_response_body.complete
2024-12-14 00:26:42,590 [DEBUG] response_closed.started
2024-12-14 00:26:42,590 [DEBUG] response_closed.complete
2024-12-14 00:26:42,590 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sat, 14 Dec 2024 05:26:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-wfobhzlf64ogbzvuffig3c5l', 'openai-processing-ms': '13553', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '24678', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '10.644s', 'x-request-id': 'req_91a7d114fea589d4654f1b87452e7a16', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f1bc77f3b732fd8-DFW', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 00:26:42,590 [DEBUG] request_id: req_91a7d114fea589d4654f1b87452e7a16
2024-12-14 00:26:42,591 [INFO] GPT-4 analysis completed successfully.
2024-12-14 13:00:42,024 [DEBUG] Starting new HTTPS connection (1): pypi.org:443
2024-12-14 13:00:42,164 [DEBUG] https://pypi.org:443 "GET /pypi/praw/json HTTP/11" 200 36290
2024-12-14 13:00:42,212 [INFO] Successfully connected to the Reddit API.
2024-12-14 13:00:42,212 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734199242.2127051
2024-12-14 13:00:42,212 [DEBUG] Data: None
2024-12-14 13:00:42,212 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-14 13:00:42,213 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-14 13:00:43,663 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 656
2024-12-14 13:00:43,665 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-14 13:00:44,599 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 55677
2024-12-14 13:00:44,668 [DEBUG] Response: 200 (55677 bytes) (rst-556:rem-999.0:used-1 ratelimit) at 1734199244.6685472
2024-12-14 13:00:44,686 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdo31p/ at 1734199244.68646
2024-12-14 13:00:44,686 [DEBUG] Data: None
2024-12-14 13:00:44,686 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:00:44,841 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdo31p/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4387
2024-12-14 13:00:44,842 [DEBUG] Response: 200 (4387 bytes) (rst-555:rem-998.0:used-2 ratelimit) at 1734199244.84253
2024-12-14 13:00:44,845 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdlno3/ at 1734199244.845106
2024-12-14 13:00:44,845 [DEBUG] Data: None
2024-12-14 13:00:44,845 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:00:45,009 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdlno3/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3322
2024-12-14 13:00:45,010 [DEBUG] Response: 200 (3322 bytes) (rst-555:rem-997.0:used-3 ratelimit) at 1734199245.010883
2024-12-14 13:00:45,013 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdg5rp/ at 1734199245.01322
2024-12-14 13:00:45,013 [DEBUG] Data: None
2024-12-14 13:00:45,013 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:00:45,151 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdg5rp/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3722
2024-12-14 13:00:45,154 [DEBUG] Response: 200 (3722 bytes) (rst-554:rem-996.0:used-4 ratelimit) at 1734199245.154853
2024-12-14 13:00:45,157 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdahzr/ at 1734199245.1573288
2024-12-14 13:00:45,157 [DEBUG] Data: None
2024-12-14 13:00:45,157 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:00:45,291 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdahzr/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2517
2024-12-14 13:00:45,292 [DEBUG] Response: 200 (2517 bytes) (rst-554:rem-995.0:used-5 ratelimit) at 1734199245.292502
2024-12-14 13:00:45,293 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hd2nk7/ at 1734199245.2938728
2024-12-14 13:00:45,294 [DEBUG] Data: None
2024-12-14 13:00:45,294 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:00:45,533 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hd2nk7/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7835
2024-12-14 13:00:45,534 [DEBUG] Response: 200 (7835 bytes) (rst-554:rem-994.0:used-6 ratelimit) at 1734199245.534878
2024-12-14 13:00:45,539 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcv8pi/ at 1734199245.539003
2024-12-14 13:00:45,539 [DEBUG] Data: None
2024-12-14 13:00:45,539 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:00:45,690 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcv8pi/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3048
2024-12-14 13:00:45,692 [DEBUG] Response: 200 (3048 bytes) (rst-554:rem-993.0:used-7 ratelimit) at 1734199245.692023
2024-12-14 13:00:45,693 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hci0sx/ at 1734199245.6934001
2024-12-14 13:00:45,693 [DEBUG] Data: None
2024-12-14 13:00:45,693 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:00:45,917 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hci0sx/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6531
2024-12-14 13:00:45,918 [DEBUG] Response: 200 (6531 bytes) (rst-554:rem-992.0:used-8 ratelimit) at 1734199245.9187572
2024-12-14 13:00:45,921 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcfjg8/ at 1734199245.921241
2024-12-14 13:00:45,921 [DEBUG] Data: None
2024-12-14 13:00:45,921 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:00:46,077 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcfjg8/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4255
2024-12-14 13:00:46,078 [DEBUG] Response: 200 (4255 bytes) (rst-554:rem-991.0:used-9 ratelimit) at 1734199246.0787299
2024-12-14 13:00:46,082 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcaa94/ at 1734199246.082101
2024-12-14 13:00:46,082 [DEBUG] Data: None
2024-12-14 13:00:46,082 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:00:46,223 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcaa94/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2772
2024-12-14 13:00:46,224 [DEBUG] Response: 200 (2772 bytes) (rst-553:rem-990.0:used-10 ratelimit) at 1734199246.224403
2024-12-14 13:00:46,225 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hc7am0/ at 1734199246.225601
2024-12-14 13:00:46,225 [DEBUG] Data: None
2024-12-14 13:00:46,225 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:00:46,469 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hc7am0/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7557
2024-12-14 13:00:46,472 [DEBUG] Response: 200 (7557 bytes) (rst-553:rem-989.0:used-11 ratelimit) at 1734199246.472894
2024-12-14 13:00:46,477 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734199246.477303
2024-12-14 13:00:46,477 [DEBUG] Data: None
2024-12-14 13:00:46,477 [DEBUG] Params: {'after': 't3_1h742r6', 'limit': 200, 'raw_json': 1}
2024-12-14 13:00:47,289 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h742r6&raw_json=1 HTTP/11" 200 48008
2024-12-14 13:00:47,309 [DEBUG] Response: 200 (48008 bytes) (rst-553:rem-988.0:used-12 ratelimit) at 1734199247.309174
2024-12-14 13:00:47,320 [INFO] Fetched and filtered 10 posts.
2024-12-14 13:00:47,337 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': "\n    You are a helpful assistant. Identify up to 20 good posts.\n\n    Here are the posts:\n    Post ID: 1hdo31p\nTitle: Is email marketing worth the time and money for small e-commerce businesses?\nScore: 6\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI think yes. I plan on working more on this next year and have a decent list to start of people who have signed up to a newsletter.\n\nIt shouldn't be costly at all when you start as free plans are provided with limitations. Once you start seeing results you can then invest money.\n\nIf you're just cold calling you'll land in spam folders and that's pointless. Get people to sign up and verify your domain so you land in their actual inbox!\nYep! I was doing 30%+ of my revenue through email. And it was incremental revenue. \n\nYou dont have to overbake it. \n\n1. Text emails are underrated. \n2. For HTML emails, get a solid template designed up and then its easy to swap in new creative each time. Canva is your friend or get someone on Fiverr to help. \n3. Set up a few smart automationsmight take you an hourand then establish a send cadence; maybe one email a week. Again, this shouldnt take more than 30-60 minutes an email. Time well spent. Provides youve got a database of course. \n4. If your database is tinyunder 50you could even just send the odd email directly to key customers. Hey, John here. Im the owner of XYZ Just wanted to mention\n------\nPost ID: 1hdlno3\nTitle: Dropshipping in 2024: A Comedy Special\nScore: 23\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI dont care if this is written by AI. Its rather funny. Especially Day 30. \nCertainly much better than those posts from people that have zero knowledge about dropshipping and want someone to tell them how to become a millionaire by the end of the week\n------\nPost ID: 1hdg5rp\nTitle: You guys be careful out there\nScore: 8\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nYes 100%, I had one reach out to me. Tried to charge almost double more than Aliexpress...\nYeah even with legitimate agents, the price of shipping and storage is extortionate.\n\nHere's why I still dropship after 4 years and haven't transitioned to agent or 3PL\nhttps://youtu.be/l7uSiQ9sHik?si=aQ9_tytfRXjj7Gzu\n------\nPost ID: 1hdahzr\nTitle: Trending Niches on TikTok Shop US in December\nScore: 7\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n------\nPost ID: 1hd2nk7\nTitle: I have a TikTok shop for sale, what is a fair price to ask for it?\nScore: 11\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nFor dropshipping stores with that short of a history you would realisticly be looking at 500-750$ area.\n\nDropshipping stores in themself do not sell for nearly the same as normal companies that are in multipliers of annual incomes.  \nAnd with both being limited to a platform like that plus such a short history, you are not even guaranteed to get 3x average monthly profit (and you can not expect to get the holiday peak included in that average).\nAvoid putting any money into tictok until after you know if the ban does or doesn't go through next month.\n------\nPost ID: 1hcv8pi\nTitle: Doing Ok I Guess\nScore: 32\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n>(ironic most people seek the opposite).\n\nMost kids/teens walking into it imagining it being easy money seek it, majority that are older do not really seek it.\n\nDoing something like dropshipping fulltime is something that sounds great intil you actualy do it tends to be the experience.  \nYou tend to start missing the coworkers, meetings etc that you used to somewhat hate.\nKeep moving forward, you got this\n------\nPost ID: 1hci0sx\nTitle: How long did it take for you to make the first sale?\nScore: 12\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI know this doesn't answer your question, but I don't think furniture is a good niche for dropshipping, especially for a beginner. Just my 2 cents.\nWhen i initialy started dropshipping half a lifetime ago it was 2-3hours from starting to promote store to first sales, from posting items on listing sites and driving them to the store to purchase.\n\nWhen we launch a store today its also same day from ads.  \nBut with ads is not as much a question if you drive traffic and get sales with a ok store, its how much do you spend per sale.\n------\nPost ID: 1hcfjg8\nTitle: We're a manufacturer from Nepal. I've only recently learned about drop shipping. Is there a specific word for sellers? how do I connect with them?\nScore: 12\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWhat do you manufacture? Cost? Shipping cost and time?\nIm interested in selling for you lets connect @zillymilli instagram\n------\nPost ID: 1hcaa94\nTitle: Dropshipping tips-what to sell in January to make 6fig\nScore: 11\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWinter halt mostly happens in the northern most states, not al around, but the major factor is festive season. Not for all industries like gifting, or clothing, etc. But for manufacturing it becomes a pause.\n------\nPost ID: 1hc7am0\nTitle: Instagram acc 60k\nScore: 22\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI wouldn't rebrand it, as the followers are there for the food. Run with that niche.\nInstead of selling t shirts or gimmicks , you could sell recipes or cooking pdfs :)\n------\n\n\n    Return only a comma-separated list of post IDs without any additional text.\n    "}], 'model': 'gpt-4o-mini', 'max_tokens': 500, 'temperature': 0.7}}
2024-12-14 13:00:47,355 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 13:00:47,355 [DEBUG] connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 13:00:47,431 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10c1e5d30>
2024-12-14 13:00:47,432 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x10c18d010> server_hostname='api.openai.com' timeout=5.0
2024-12-14 13:00:47,472 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10c097b10>
2024-12-14 13:00:47,472 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-12-14 13:00:47,472 [DEBUG] send_request_headers.complete
2024-12-14 13:00:47,472 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-12-14 13:00:47,473 [DEBUG] send_request_body.complete
2024-12-14 13:00:47,473 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-12-14 13:00:47,629 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 403, b'Forbidden', [(b'Date', b'Sat, 14 Dec 2024 18:00:47 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_133a23b621a14ee06145ec8259fcea0f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=0EqhXUniP0GAIDJnJf6Ll4H8oBJyntPpo1V3aD2mTYs-1734199247-1.0.1.1-hxdpmZktkveXSP0rGZUG_XWLkzN1GPAHzpHJl726dv2M6hTZksQ7rEQy9LRycG5zhXZgfd2qF8rLS8hfWwxzNg; path=/; expires=Sat, 14-Dec-24 18:30:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=5b2HxaRdwRQHDPlCojiMgu1LxuyGKfS5tjl7rYneS48-1734199247647-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f2018710a510f85-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 13:00:47,630 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 403 Forbidden"
2024-12-14 13:00:47,630 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-12-14 13:00:47,630 [DEBUG] receive_response_body.complete
2024-12-14 13:00:47,630 [DEBUG] response_closed.started
2024-12-14 13:00:47,630 [DEBUG] response_closed.complete
2024-12-14 13:00:47,631 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "403 Forbidden" Headers([('date', 'Sat, 14 Dec 2024 18:00:47 GMT'), ('content-type', 'application/json; charset=utf-8'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('vary', 'Origin'), ('x-request-id', 'req_133a23b621a14ee06145ec8259fcea0f'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=0EqhXUniP0GAIDJnJf6Ll4H8oBJyntPpo1V3aD2mTYs-1734199247-1.0.1.1-hxdpmZktkveXSP0rGZUG_XWLkzN1GPAHzpHJl726dv2M6hTZksQ7rEQy9LRycG5zhXZgfd2qF8rLS8hfWwxzNg; path=/; expires=Sat, 14-Dec-24 18:30:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=5b2HxaRdwRQHDPlCojiMgu1LxuyGKfS5tjl7rYneS48-1734199247647-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f2018710a510f85-EWR'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-12-14 13:00:47,631 [DEBUG] request_id: req_133a23b621a14ee06145ec8259fcea0f
2024-12-14 13:00:47,631 [DEBUG] Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/chrisgaya/Library/Python/3.13/lib/python/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
2024-12-14 13:00:47,635 [DEBUG] Not retrying
2024-12-14 13:00:47,635 [DEBUG] Re-raising status error
2024-12-14 13:00:47,638 [ERROR] Error during filtering with GPT.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 129, in filter_posts_with_gpt
    response = client.chat.completions.create(
        model="gpt-4o-mini",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/resources/chat/completions.py", line 829, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<39 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_base_client.py", line 1280, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_base_client.py", line 957, in request
    return self._request(
           ~~~~~~~~~~~~~^
        cast_to=cast_to,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        retries_taken=retries_taken,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_base_client.py", line 1061, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.PermissionDeniedError: Error code: 403 - {'error': {'message': 'Project `proj_cEihw5JpNgQ1p6L2NbLCoiTW` does not have access to model `gpt-4o-mini`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
2024-12-14 13:00:47,642 [ERROR] Error in script execution.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 129, in filter_posts_with_gpt
    response = client.chat.completions.create(
        model="gpt-4o-mini",
    ...<5 lines>...
        temperature=0.7,
    )
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/resources/chat/completions.py", line 829, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<39 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_base_client.py", line 1280, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_base_client.py", line 957, in request
    return self._request(
           ~~~~~~~~~~~~~^
        cast_to=cast_to,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        retries_taken=retries_taken,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_base_client.py", line 1061, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.PermissionDeniedError: Error code: 403 - {'error': {'message': 'Project `proj_cEihw5JpNgQ1p6L2NbLCoiTW` does not have access to model `gpt-4o-mini`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 373, in run_script
    good_posts = filter_posts_with_gpt(posts)
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 145, in filter_posts_with_gpt
    raise RuntimeError(f"Error during filtering: {e}")
RuntimeError: Error during filtering: Error code: 403 - {'error': {'message': 'Project `proj_cEihw5JpNgQ1p6L2NbLCoiTW` does not have access to model `gpt-4o-mini`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
2024-12-14 13:03:24,535 [DEBUG] close.started
2024-12-14 13:03:24,537 [DEBUG] close.complete
2024-12-14 13:04:56,934 [INFO] Successfully connected to the Reddit API.
2024-12-14 13:04:56,935 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734199496.935615
2024-12-14 13:04:56,935 [DEBUG] Data: None
2024-12-14 13:04:56,936 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-14 13:04:56,938 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-14 13:04:57,499 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 657
2024-12-14 13:04:57,504 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-14 13:04:58,497 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 55708
2024-12-14 13:04:58,557 [DEBUG] Response: 200 (55708 bytes) (rst-302:rem-987.0:used-13 ratelimit) at 1734199498.557042
2024-12-14 13:04:58,571 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdo31p/ at 1734199498.5713038
2024-12-14 13:04:58,571 [DEBUG] Data: None
2024-12-14 13:04:58,571 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:04:58,732 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdo31p/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4388
2024-12-14 13:04:58,733 [DEBUG] Response: 200 (4388 bytes) (rst-301:rem-986.0:used-14 ratelimit) at 1734199498.733012
2024-12-14 13:04:58,734 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdlno3/ at 1734199498.734686
2024-12-14 13:04:58,734 [DEBUG] Data: None
2024-12-14 13:04:58,734 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:04:58,897 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdlno3/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3327
2024-12-14 13:04:58,897 [DEBUG] Response: 200 (3327 bytes) (rst-301:rem-985.0:used-15 ratelimit) at 1734199498.897851
2024-12-14 13:04:58,898 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdg5rp/ at 1734199498.898728
2024-12-14 13:04:58,898 [DEBUG] Data: None
2024-12-14 13:04:58,898 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:04:59,037 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdg5rp/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3723
2024-12-14 13:04:59,038 [DEBUG] Response: 200 (3723 bytes) (rst-301:rem-984.0:used-16 ratelimit) at 1734199499.0388951
2024-12-14 13:04:59,041 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdahzr/ at 1734199499.0410051
2024-12-14 13:04:59,041 [DEBUG] Data: None
2024-12-14 13:04:59,041 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:04:59,179 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdahzr/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2520
2024-12-14 13:04:59,179 [DEBUG] Response: 200 (2520 bytes) (rst-300:rem-983.0:used-17 ratelimit) at 1734199499.179374
2024-12-14 13:04:59,179 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hd2nk7/ at 1734199499.1796749
2024-12-14 13:04:59,179 [DEBUG] Data: None
2024-12-14 13:04:59,179 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:04:59,429 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hd2nk7/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7839
2024-12-14 13:04:59,431 [DEBUG] Response: 200 (7839 bytes) (rst-300:rem-982.0:used-18 ratelimit) at 1734199499.431253
2024-12-14 13:04:59,434 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcv8pi/ at 1734199499.4343722
2024-12-14 13:04:59,434 [DEBUG] Data: None
2024-12-14 13:04:59,434 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:04:59,567 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcv8pi/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3049
2024-12-14 13:04:59,568 [DEBUG] Response: 200 (3049 bytes) (rst-300:rem-981.0:used-19 ratelimit) at 1734199499.56832
2024-12-14 13:04:59,569 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hci0sx/ at 1734199499.5694668
2024-12-14 13:04:59,569 [DEBUG] Data: None
2024-12-14 13:04:59,569 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:04:59,757 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hci0sx/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6533
2024-12-14 13:04:59,758 [DEBUG] Response: 200 (6533 bytes) (rst-300:rem-980.0:used-20 ratelimit) at 1734199499.758219
2024-12-14 13:04:59,760 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcfjg8/ at 1734199499.7604952
2024-12-14 13:04:59,760 [DEBUG] Data: None
2024-12-14 13:04:59,760 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:04:59,952 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcfjg8/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4255
2024-12-14 13:04:59,955 [DEBUG] Response: 200 (4255 bytes) (rst-300:rem-979.0:used-21 ratelimit) at 1734199499.955713
2024-12-14 13:04:59,958 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcaa94/ at 1734199499.958026
2024-12-14 13:04:59,958 [DEBUG] Data: None
2024-12-14 13:04:59,958 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:05:00,091 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcaa94/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2770
2024-12-14 13:05:00,092 [DEBUG] Response: 200 (2770 bytes) (rst-299:rem-978.0:used-22 ratelimit) at 1734199500.0921621
2024-12-14 13:05:00,092 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hc7am0/ at 1734199500.092724
2024-12-14 13:05:00,092 [DEBUG] Data: None
2024-12-14 13:05:00,092 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:05:00,320 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hc7am0/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7561
2024-12-14 13:05:00,321 [DEBUG] Response: 200 (7561 bytes) (rst-299:rem-977.0:used-23 ratelimit) at 1734199500.321609
2024-12-14 13:05:00,325 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734199500.325521
2024-12-14 13:05:00,325 [DEBUG] Data: None
2024-12-14 13:05:00,325 [DEBUG] Params: {'after': 't3_1h742r6', 'limit': 200, 'raw_json': 1}
2024-12-14 13:05:00,985 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h742r6&raw_json=1 HTTP/11" 200 48009
2024-12-14 13:05:01,000 [DEBUG] Response: 200 (48009 bytes) (rst-299:rem-976.0:used-24 ratelimit) at 1734199501.0001972
2024-12-14 13:05:01,013 [INFO] Fetched and filtered 10 posts.
2024-12-14 13:05:01,029 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': "\n    You are a helpful assistant. Identify up to 20 good posts.\n\n    Here are the posts:\n    Post ID: 1hdo31p\nTitle: Is email marketing worth the time and money for small e-commerce businesses?\nScore: 5\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI think yes. I plan on working more on this next year and have a decent list to start of people who have signed up to a newsletter.\n\nIt shouldn't be costly at all when you start as free plans are provided with limitations. Once you start seeing results you can then invest money.\n\nIf you're just cold calling you'll land in spam folders and that's pointless. Get people to sign up and verify your domain so you land in their actual inbox!\nYep! I was doing 30%+ of my revenue through email. And it was incremental revenue. \n\nYou dont have to overbake it. \n\n1. Text emails are underrated. \n2. For HTML emails, get a solid template designed up and then its easy to swap in new creative each time. Canva is your friend or get someone on Fiverr to help. \n3. Set up a few smart automationsmight take you an hourand then establish a send cadence; maybe one email a week. Again, this shouldnt take more than 30-60 minutes an email. Time well spent. Provides youve got a database of course. \n4. If your database is tinyunder 50you could even just send the odd email directly to key customers. Hey, John here. Im the owner of XYZ Just wanted to mention\n------\nPost ID: 1hdlno3\nTitle: Dropshipping in 2024: A Comedy Special\nScore: 23\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI dont care if this is written by AI. Its rather funny. Especially Day 30. \nCertainly much better than those posts from people that have zero knowledge about dropshipping and want someone to tell them how to become a millionaire by the end of the week\n------\nPost ID: 1hdg5rp\nTitle: You guys be careful out there\nScore: 9\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nYes 100%, I had one reach out to me. Tried to charge almost double more than Aliexpress...\nYeah even with legitimate agents, the price of shipping and storage is extortionate.\n\nHere's why I still dropship after 4 years and haven't transitioned to agent or 3PL\nhttps://youtu.be/l7uSiQ9sHik?si=aQ9_tytfRXjj7Gzu\n------\nPost ID: 1hdahzr\nTitle: Trending Niches on TikTok Shop US in December\nScore: 7\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n------\nPost ID: 1hd2nk7\nTitle: I have a TikTok shop for sale, what is a fair price to ask for it?\nScore: 11\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nFor dropshipping stores with that short of a history you would realisticly be looking at 500-750$ area.\n\nDropshipping stores in themself do not sell for nearly the same as normal companies that are in multipliers of annual incomes.  \nAnd with both being limited to a platform like that plus such a short history, you are not even guaranteed to get 3x average monthly profit (and you can not expect to get the holiday peak included in that average).\nAvoid putting any money into tictok until after you know if the ban does or doesn't go through next month.\n------\nPost ID: 1hcv8pi\nTitle: Doing Ok I Guess\nScore: 31\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n>(ironic most people seek the opposite).\n\nMost kids/teens walking into it imagining it being easy money seek it, majority that are older do not really seek it.\n\nDoing something like dropshipping fulltime is something that sounds great intil you actualy do it tends to be the experience.  \nYou tend to start missing the coworkers, meetings etc that you used to somewhat hate.\nKeep moving forward, you got this\n------\nPost ID: 1hci0sx\nTitle: How long did it take for you to make the first sale?\nScore: 12\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI know this doesn't answer your question, but I don't think furniture is a good niche for dropshipping, especially for a beginner. Just my 2 cents.\nWhen i initialy started dropshipping half a lifetime ago it was 2-3hours from starting to promote store to first sales, from posting items on listing sites and driving them to the store to purchase.\n\nWhen we launch a store today its also same day from ads.  \nBut with ads is not as much a question if you drive traffic and get sales with a ok store, its how much do you spend per sale.\n------\nPost ID: 1hcfjg8\nTitle: We're a manufacturer from Nepal. I've only recently learned about drop shipping. Is there a specific word for sellers? how do I connect with them?\nScore: 11\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWhat do you manufacture? Cost? Shipping cost and time?\nIm interested in selling for you lets connect @zillymilli instagram\n------\nPost ID: 1hcaa94\nTitle: Dropshipping tips-what to sell in January to make 6fig\nScore: 10\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWinter halt mostly happens in the northern most states, not al around, but the major factor is festive season. Not for all industries like gifting, or clothing, etc. But for manufacturing it becomes a pause.\n------\nPost ID: 1hc7am0\nTitle: Instagram acc 60k\nScore: 21\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI wouldn't rebrand it, as the followers are there for the food. Run with that niche.\nInstead of selling t shirts or gimmicks , you could sell recipes or cooking pdfs :)\n------\n\n\n    Return only a comma-separated list of post IDs without any additional text.\n    "}], 'model': 'gpt-4o-mini', 'max_tokens': 500, 'temperature': 0.7}}
2024-12-14 13:05:01,051 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 13:05:01,052 [DEBUG] connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 13:05:01,138 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10bb527b0>
2024-12-14 13:05:01,138 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x10bb1d010> server_hostname='api.openai.com' timeout=5.0
2024-12-14 13:05:01,177 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10bb591d0>
2024-12-14 13:05:01,178 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-12-14 13:05:01,178 [DEBUG] send_request_headers.complete
2024-12-14 13:05:01,178 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-12-14 13:05:01,178 [DEBUG] send_request_body.complete
2024-12-14 13:05:01,178 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-12-14 13:05:03,743 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 18:05:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-wfobhzlf64ogbzvuffig3c5l'), (b'openai-processing-ms', b'2411'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'197442'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'767ms'), (b'x-request-id', b'req_9d2cd088915d8ed5a248bad183f3a9e0'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=jDEop3hsOMrGkWP5MRKNYCciIfGWwwwbnlxUpSO6UB0-1734199503-1.0.1.1-pWhbMH5IdsFLQ_zZoVvNSzDbzo.7OmPFJpCqHZqhOttY21F7JDH8AjLOsv5yw8mz0MEJO96RwZkm7SiGAlimsQ; path=/; expires=Sat, 14-Dec-24 18:35:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=obaYm.Yqdokpk2WCRmMcEMamCv7I4YqtDCdgmGqUG6k-1734199503758-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f201ea2aa144207-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 13:05:03,744 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-14 13:05:03,744 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-12-14 13:05:03,745 [DEBUG] receive_response_body.complete
2024-12-14 13:05:03,745 [DEBUG] response_closed.started
2024-12-14 13:05:03,745 [DEBUG] response_closed.complete
2024-12-14 13:05:03,745 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sat, 14 Dec 2024 18:05:03 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-wfobhzlf64ogbzvuffig3c5l'), ('openai-processing-ms', '2411'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '197442'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '767ms'), ('x-request-id', 'req_9d2cd088915d8ed5a248bad183f3a9e0'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=jDEop3hsOMrGkWP5MRKNYCciIfGWwwwbnlxUpSO6UB0-1734199503-1.0.1.1-pWhbMH5IdsFLQ_zZoVvNSzDbzo.7OmPFJpCqHZqhOttY21F7JDH8AjLOsv5yw8mz0MEJO96RwZkm7SiGAlimsQ; path=/; expires=Sat, 14-Dec-24 18:35:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=obaYm.Yqdokpk2WCRmMcEMamCv7I4YqtDCdgmGqUG6k-1734199503758-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f201ea2aa144207-EWR'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-12-14 13:05:03,745 [DEBUG] request_id: req_9d2cd088915d8ed5a248bad183f3a9e0
2024-12-14 13:05:03,751 [INFO] GPT-3.5 identified 10 good posts.
2024-12-14 13:05:03,766 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': "\n        Analyze these posts from r/dropship:\n\n        Post ID: 1hdo31p\nTitle: Is email marketing worth the time and money for small e-commerce businesses?\nScore: 5\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI think yes. I plan on working more on this next year and have a decent list to start of people who have signed up to a newsletter.\n\nIt shouldn't be costly at all when you start as free plans are provided with limitations. Once you start seeing results you can then invest money.\n\nIf you're just cold calling you'll land in spam folders and that's pointless. Get people to sign up and verify your domain so you land in their actual inbox!\nYep! I was doing 30%+ of my revenue through email. And it was incremental revenue. \n\nYou dont have to overbake it. \n\n1. Text emails are underrated. \n2. For HTML emails, get a solid template designed up and then its easy to swap in new creative each time. Canva is your friend or get someone on Fiverr to help. \n3. Set up a few smart automationsmight take you an hourand then establish a send cadence; maybe one email a week. Again, this shouldnt take more than 30-60 minutes an email. Time well spent. Provides youve got a database of course. \n4. If your database is tinyunder 50you could even just send the odd email directly to key customers. Hey, John here. Im the owner of XYZ Just wanted to mention\n------\n\n\nPost ID: 1hdlno3\nTitle: Dropshipping in 2024: A Comedy Special\nScore: 23\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI dont care if this is written by AI. Its rather funny. Especially Day 30. \nCertainly much better than those posts from people that have zero knowledge about dropshipping and want someone to tell them how to become a millionaire by the end of the week\n------\n\n\nPost ID: 1hdg5rp\nTitle: You guys be careful out there\nScore: 9\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nYes 100%, I had one reach out to me. Tried to charge almost double more than Aliexpress...\nYeah even with legitimate agents, the price of shipping and storage is extortionate.\n\nHere's why I still dropship after 4 years and haven't transitioned to agent or 3PL\nhttps://youtu.be/l7uSiQ9sHik?si=aQ9_tytfRXjj7Gzu\n------\n\n\nPost ID: 1hdahzr\nTitle: Trending Niches on TikTok Shop US in December\nScore: 7\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n------\n\n\nPost ID: 1hd2nk7\nTitle: I have a TikTok shop for sale, what is a fair price to ask for it?\nScore: 11\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nFor dropshipping stores with that short of a history you would realisticly be looking at 500-750$ area.\n\nDropshipping stores in themself do not sell for nearly the same as normal companies that are in multipliers of annual incomes.  \nAnd with both being limited to a platform like that plus such a short history, you are not even guaranteed to get 3x average monthly profit (and you can not expect to get the holiday peak included in that average).\nAvoid putting any money into tictok until after you know if the ban does or doesn't go through next month.\n------\n\n\nPost ID: 1hcv8pi\nTitle: Doing Ok I Guess\nScore: 31\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n>(ironic most people seek the opposite).\n\nMost kids/teens walking into it imagining it being easy money seek it, majority that are older do not really seek it.\n\nDoing something like dropshipping fulltime is something that sounds great intil you actualy do it tends to be the experience.  \nYou tend to start missing the coworkers, meetings etc that you used to somewhat hate.\nKeep moving forward, you got this\n------\n\n\nPost ID: 1hci0sx\nTitle: How long did it take for you to make the first sale?\nScore: 12\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI know this doesn't answer your question, but I don't think furniture is a good niche for dropshipping, especially for a beginner. Just my 2 cents.\nWhen i initialy started dropshipping half a lifetime ago it was 2-3hours from starting to promote store to first sales, from posting items on listing sites and driving them to the store to purchase.\n\nWhen we launch a store today its also same day from ads.  \nBut with ads is not as much a question if you drive traffic and get sales with a ok store, its how much do you spend per sale.\n------\n\n\nPost ID: 1hcfjg8\nTitle: We're a manufacturer from Nepal. I've only recently learned about drop shipping. Is there a specific word for sellers? how do I connect with them?\nScore: 11\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWhat do you manufacture? Cost? Shipping cost and time?\nIm interested in selling for you lets connect @zillymilli instagram\n------\n\n\nPost ID: 1hcaa94\nTitle: Dropshipping tips-what to sell in January to make 6fig\nScore: 10\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWinter halt mostly happens in the northern most states, not al around, but the major factor is festive season. Not for all industries like gifting, or clothing, etc. But for manufacturing it becomes a pause.\n------\n\n\nPost ID: 1hc7am0\nTitle: Instagram acc 60k\nScore: 21\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI wouldn't rebrand it, as the followers are there for the food. Run with that niche.\nInstead of selling t shirts or gimmicks , you could sell recipes or cooking pdfs :)\n------\n\n\n        Provide insights, trends, or recommendations based on these posts.\n        "}], 'model': 'gpt-4o-mini', 'max_tokens': 3000, 'temperature': 0.7}}
2024-12-14 13:05:03,766 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 13:05:03,767 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-12-14 13:05:03,767 [DEBUG] send_request_headers.complete
2024-12-14 13:05:03,767 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-12-14 13:05:03,767 [DEBUG] send_request_body.complete
2024-12-14 13:05:03,767 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-12-14 13:05:12,520 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 18:05:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-wfobhzlf64ogbzvuffig3c5l'), (b'openai-processing-ms', b'8607'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'194947'), (b'x-ratelimit-reset-requests', b'14.701s'), (b'x-ratelimit-reset-tokens', b'1.515s'), (b'x-request-id', b'req_ddb0ff372352973f81c13db76d2d9339'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f201eb2dea24207-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 13:05:12,520 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-14 13:05:12,521 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-12-14 13:05:12,521 [DEBUG] receive_response_body.complete
2024-12-14 13:05:12,521 [DEBUG] response_closed.started
2024-12-14 13:05:12,521 [DEBUG] response_closed.complete
2024-12-14 13:05:12,521 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sat, 14 Dec 2024 18:05:12 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-wfobhzlf64ogbzvuffig3c5l', 'openai-processing-ms': '8607', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '194947', 'x-ratelimit-reset-requests': '14.701s', 'x-ratelimit-reset-tokens': '1.515s', 'x-request-id': 'req_ddb0ff372352973f81c13db76d2d9339', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f201eb2dea24207-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 13:05:12,521 [DEBUG] request_id: req_ddb0ff372352973f81c13db76d2d9339
2024-12-14 13:05:12,522 [INFO] GPT-4 analysis completed successfully.
2024-12-14 13:27:44,990 [DEBUG] close.started
2024-12-14 13:27:44,990 [DEBUG] close.complete
2024-12-14 13:27:47,012 [ERROR] Fatal error in GUI.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 345, in <module>
    root = create_gui()
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 309, in create_gui
    run_button = ttk.Button(frame, text="Run Analysis", command=run_script_thread)
                                                                ^^^^^^^^^^^^^^^^^
NameError: name 'run_script_thread' is not defined
2024-12-14 13:31:27,335 [ERROR] Error during analysis.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 279, in run_script
    progress_bar['value'] = 0
    ^^^^^^^^^^^^
NameError: name 'progress_bar' is not defined
2024-12-14 13:32:26,679 [ERROR] Fatal error in GUI.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 408, in <module>
    root = create_gui()
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 333, in create_gui
    'progress_bar': progress_bar,
                    ^^^^^^^^^^^^
NameError: name 'progress_bar' is not defined
2024-12-14 13:32:50,465 [ERROR] Fatal error in GUI.
Traceback (most recent call last):
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 411, in <module>
    root = create_gui()
  File "/Users/chrisgaya/openai-python/reddit_crawler.py", line 332, in create_gui
    progress_bar = ttk.Progressbar(frame, orient="horizontal", length=400, mode="determinate")
                                   ^^^^^
UnboundLocalError: cannot access local variable 'frame' where it is not associated with a value
2024-12-14 13:36:14,679 [INFO] Successfully connected to the Reddit API.
2024-12-14 13:36:14,680 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734201374.680131
2024-12-14 13:36:14,680 [DEBUG] Data: None
2024-12-14 13:36:14,680 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-14 13:36:14,682 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-14 13:36:15,187 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 655
2024-12-14 13:36:15,190 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-14 13:36:16,499 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 55702
2024-12-14 13:36:16,560 [DEBUG] Response: 200 (55702 bytes) (rst-224:rem-999.0:used-1 ratelimit) at 1734201376.56053
2024-12-14 13:36:16,572 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdo31p/ at 1734201376.572607
2024-12-14 13:36:16,572 [DEBUG] Data: None
2024-12-14 13:36:16,572 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:36:16,737 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdo31p/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4389
2024-12-14 13:36:16,738 [DEBUG] Response: 200 (4389 bytes) (rst-223:rem-998.0:used-2 ratelimit) at 1734201376.7386189
2024-12-14 13:36:16,739 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdlno3/ at 1734201376.7397811
2024-12-14 13:36:16,739 [DEBUG] Data: None
2024-12-14 13:36:16,739 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:36:16,889 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdlno3/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3325
2024-12-14 13:36:16,890 [DEBUG] Response: 200 (3325 bytes) (rst-223:rem-997.0:used-3 ratelimit) at 1734201376.8909361
2024-12-14 13:36:16,893 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdg5rp/ at 1734201376.893087
2024-12-14 13:36:16,893 [DEBUG] Data: None
2024-12-14 13:36:16,893 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:36:17,071 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdg5rp/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3727
2024-12-14 13:36:17,074 [DEBUG] Response: 200 (3727 bytes) (rst-223:rem-996.0:used-4 ratelimit) at 1734201377.074144
2024-12-14 13:36:17,076 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdahzr/ at 1734201377.076771
2024-12-14 13:36:17,076 [DEBUG] Data: None
2024-12-14 13:36:17,077 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:36:17,209 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdahzr/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2517
2024-12-14 13:36:17,210 [DEBUG] Response: 200 (2517 bytes) (rst-222:rem-995.0:used-5 ratelimit) at 1734201377.210617
2024-12-14 13:36:17,211 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hd2nk7/ at 1734201377.211807
2024-12-14 13:36:17,211 [DEBUG] Data: None
2024-12-14 13:36:17,211 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:36:17,453 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hd2nk7/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7837
2024-12-14 13:36:17,459 [DEBUG] Response: 200 (7837 bytes) (rst-222:rem-994.0:used-6 ratelimit) at 1734201377.4595578
2024-12-14 13:36:17,465 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcv8pi/ at 1734201377.465236
2024-12-14 13:36:17,465 [DEBUG] Data: None
2024-12-14 13:36:17,465 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:36:17,616 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcv8pi/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3047
2024-12-14 13:36:17,617 [DEBUG] Response: 200 (3047 bytes) (rst-222:rem-993.0:used-7 ratelimit) at 1734201377.617345
2024-12-14 13:36:17,618 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hci0sx/ at 1734201377.61839
2024-12-14 13:36:17,618 [DEBUG] Data: None
2024-12-14 13:36:17,618 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:36:17,823 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hci0sx/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6639
2024-12-14 13:36:17,825 [DEBUG] Response: 200 (6639 bytes) (rst-222:rem-992.0:used-8 ratelimit) at 1734201377.825087
2024-12-14 13:36:17,828 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcfjg8/ at 1734201377.828833
2024-12-14 13:36:17,828 [DEBUG] Data: None
2024-12-14 13:36:17,829 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:36:18,037 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcfjg8/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4254
2024-12-14 13:36:18,038 [DEBUG] Response: 200 (4254 bytes) (rst-222:rem-991.0:used-9 ratelimit) at 1734201378.0383658
2024-12-14 13:36:18,041 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcaa94/ at 1734201378.041059
2024-12-14 13:36:18,041 [DEBUG] Data: None
2024-12-14 13:36:18,041 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:36:18,181 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcaa94/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2771
2024-12-14 13:36:18,182 [DEBUG] Response: 200 (2771 bytes) (rst-221:rem-990.0:used-10 ratelimit) at 1734201378.18264
2024-12-14 13:36:18,183 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hc7am0/ at 1734201378.1836522
2024-12-14 13:36:18,183 [DEBUG] Data: None
2024-12-14 13:36:18,183 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 13:36:18,387 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hc7am0/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7563
2024-12-14 13:36:18,389 [DEBUG] Response: 200 (7563 bytes) (rst-221:rem-989.0:used-11 ratelimit) at 1734201378.389122
2024-12-14 13:36:18,393 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734201378.393805
2024-12-14 13:36:18,393 [DEBUG] Data: None
2024-12-14 13:36:18,393 [DEBUG] Params: {'after': 't3_1h742r6', 'limit': 200, 'raw_json': 1}
2024-12-14 13:36:19,191 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h742r6&raw_json=1 HTTP/11" 200 47992
2024-12-14 13:36:19,205 [DEBUG] Response: 200 (47992 bytes) (rst-221:rem-988.0:used-12 ratelimit) at 1734201379.2054021
2024-12-14 13:36:19,216 [INFO] Fetched and filtered 10 posts.
2024-12-14 13:36:19,237 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': "\n    You are a helpful assistant. Identify up to 20 good posts.\n\n    Here are the posts:\n    Post ID: 1hdo31p\nTitle: Is email marketing worth the time and money for small e-commerce businesses?\nScore: 7\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI think yes. I plan on working more on this next year and have a decent list to start of people who have signed up to a newsletter.\n\nIt shouldn't be costly at all when you start as free plans are provided with limitations. Once you start seeing results you can then invest money.\n\nIf you're just cold calling you'll land in spam folders and that's pointless. Get people to sign up and verify your domain so you land in their actual inbox!\nYep! I was doing 30%+ of my revenue through email. And it was incremental revenue. \n\nYou dont have to overbake it. \n\n1. Text emails are underrated. \n2. For HTML emails, get a solid template designed up and then its easy to swap in new creative each time. Canva is your friend or get someone on Fiverr to help. \n3. Set up a few smart automationsmight take you an hourand then establish a send cadence; maybe one email a week. Again, this shouldnt take more than 30-60 minutes an email. Time well spent. Provides youve got a database of course. \n4. If your database is tinyunder 50you could even just send the odd email directly to key customers. Hey, John here. Im the owner of XYZ Just wanted to mention\n------\nPost ID: 1hdlno3\nTitle: Dropshipping in 2024: A Comedy Special\nScore: 25\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI dont care if this is written by AI. Its rather funny. Especially Day 30. \nCertainly much better than those posts from people that have zero knowledge about dropshipping and want someone to tell them how to become a millionaire by the end of the week\n------\nPost ID: 1hdg5rp\nTitle: You guys be careful out there\nScore: 10\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nYes 100%, I had one reach out to me. Tried to charge almost double more than Aliexpress...\nYeah even with legitimate agents, the price of shipping and storage is extortionate.\n\nHere's why I still dropship after 4 years and haven't transitioned to agent or 3PL\nhttps://youtu.be/l7uSiQ9sHik?si=aQ9_tytfRXjj7Gzu\n------\nPost ID: 1hdahzr\nTitle: Trending Niches on TikTok Shop US in December\nScore: 7\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n------\nPost ID: 1hd2nk7\nTitle: I have a TikTok shop for sale, what is a fair price to ask for it?\nScore: 12\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nFor dropshipping stores with that short of a history you would realisticly be looking at 500-750$ area.\n\nDropshipping stores in themself do not sell for nearly the same as normal companies that are in multipliers of annual incomes.  \nAnd with both being limited to a platform like that plus such a short history, you are not even guaranteed to get 3x average monthly profit (and you can not expect to get the holiday peak included in that average).\nAvoid putting any money into tictok until after you know if the ban does or doesn't go through next month.\n------\nPost ID: 1hcv8pi\nTitle: Doing Ok I Guess\nScore: 32\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n>(ironic most people seek the opposite).\n\nMost kids/teens walking into it imagining it being easy money seek it, majority that are older do not really seek it.\n\nDoing something like dropshipping fulltime is something that sounds great intil you actualy do it tends to be the experience.  \nYou tend to start missing the coworkers, meetings etc that you used to somewhat hate.\nKeep moving forward, you got this\n------\nPost ID: 1hci0sx\nTitle: How long did it take for you to make the first sale?\nScore: 12\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI know this doesn't answer your question, but I don't think furniture is a good niche for dropshipping, especially for a beginner. Just my 2 cents.\nWhen i initialy started dropshipping half a lifetime ago it was 2-3hours from starting to promote store to first sales, from posting items on listing sites and driving them to the store to purchase.\n\nWhen we launch a store today its also same day from ads.  \nBut with ads is not as much a question if you drive traffic and get sales with a ok store, its how much do you spend per sale.\n------\nPost ID: 1hcfjg8\nTitle: We're a manufacturer from Nepal. I've only recently learned about drop shipping. Is there a specific word for sellers? how do I connect with them?\nScore: 12\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWhat do you manufacture? Cost? Shipping cost and time?\nIm interested in selling for you lets connect @zillymilli instagram\n------\nPost ID: 1hcaa94\nTitle: Dropshipping tips-what to sell in January to make 6fig\nScore: 11\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWinter halt mostly happens in the northern most states, not al around, but the major factor is festive season. Not for all industries like gifting, or clothing, etc. But for manufacturing it becomes a pause.\n------\nPost ID: 1hc7am0\nTitle: Instagram acc 60k\nScore: 22\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI wouldn't rebrand it, as the followers are there for the food. Run with that niche.\nInstead of selling t shirts or gimmicks , you could sell recipes or cooking pdfs :)\n------\n\n\n    Return only a comma-separated list of post IDs without any additional text.\n    "}], 'model': 'gpt-4o-mini', 'max_tokens': 500, 'temperature': 0.7}}
2024-12-14 13:36:19,256 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 13:36:19,256 [DEBUG] connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 13:36:19,368 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x109fa6510>
2024-12-14 13:36:19,368 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x109f6cf80> server_hostname='api.openai.com' timeout=5.0
2024-12-14 13:36:19,420 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x109e7bc50>
2024-12-14 13:36:19,420 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-12-14 13:36:19,421 [DEBUG] send_request_headers.complete
2024-12-14 13:36:19,421 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-12-14 13:36:19,421 [DEBUG] send_request_body.complete
2024-12-14 13:36:19,421 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-12-14 13:36:20,815 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 18:36:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-wfobhzlf64ogbzvuffig3c5l'), (b'openai-processing-ms', b'1231'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'197442'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'767ms'), (b'x-request-id', b'req_4893cdbcb7cc13320758292e3b3139f9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=gQ9SE6rBRC0UqyIqa9wFQc.W5F1aDSZxurd4fONvkYw-1734201380-1.0.1.1-8sj0D9M2_a4dMUcTOw3DizzqZoeRa5QnjGcjGriZGrheDHCIrUlulv3QMkdrbbiJ1BO1fFU3PFPKl8VB8WCESw; path=/; expires=Sat, 14-Dec-24 19:06:20 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=KqkK1tcsYdrriCr_rBuq24bmiGyBKhwZ5jPeHXDDyZE-1734201380862-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f204c7debaaefa3-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 13:36:20,817 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-14 13:36:20,817 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-12-14 13:36:20,818 [DEBUG] receive_response_body.complete
2024-12-14 13:36:20,818 [DEBUG] response_closed.started
2024-12-14 13:36:20,818 [DEBUG] response_closed.complete
2024-12-14 13:36:20,818 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sat, 14 Dec 2024 18:36:20 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-wfobhzlf64ogbzvuffig3c5l'), ('openai-processing-ms', '1231'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '197442'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '767ms'), ('x-request-id', 'req_4893cdbcb7cc13320758292e3b3139f9'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=gQ9SE6rBRC0UqyIqa9wFQc.W5F1aDSZxurd4fONvkYw-1734201380-1.0.1.1-8sj0D9M2_a4dMUcTOw3DizzqZoeRa5QnjGcjGriZGrheDHCIrUlulv3QMkdrbbiJ1BO1fFU3PFPKl8VB8WCESw; path=/; expires=Sat, 14-Dec-24 19:06:20 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=KqkK1tcsYdrriCr_rBuq24bmiGyBKhwZ5jPeHXDDyZE-1734201380862-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f204c7debaaefa3-EWR'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-12-14 13:36:20,818 [DEBUG] request_id: req_4893cdbcb7cc13320758292e3b3139f9
2024-12-14 13:36:20,823 [INFO] GPT-3.5 identified 9 good posts.
2024-12-14 13:36:20,844 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': "\n        Analyze these posts from r/dropship:\n\n        Post ID: 1hdo31p\nTitle: Is email marketing worth the time and money for small e-commerce businesses?\nScore: 7\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI think yes. I plan on working more on this next year and have a decent list to start of people who have signed up to a newsletter.\n\nIt shouldn't be costly at all when you start as free plans are provided with limitations. Once you start seeing results you can then invest money.\n\nIf you're just cold calling you'll land in spam folders and that's pointless. Get people to sign up and verify your domain so you land in their actual inbox!\nYep! I was doing 30%+ of my revenue through email. And it was incremental revenue. \n\nYou dont have to overbake it. \n\n1. Text emails are underrated. \n2. For HTML emails, get a solid template designed up and then its easy to swap in new creative each time. Canva is your friend or get someone on Fiverr to help. \n3. Set up a few smart automationsmight take you an hourand then establish a send cadence; maybe one email a week. Again, this shouldnt take more than 30-60 minutes an email. Time well spent. Provides youve got a database of course. \n4. If your database is tinyunder 50you could even just send the odd email directly to key customers. Hey, John here. Im the owner of XYZ Just wanted to mention\n------\n\n\nPost ID: 1hdlno3\nTitle: Dropshipping in 2024: A Comedy Special\nScore: 25\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI dont care if this is written by AI. Its rather funny. Especially Day 30. \nCertainly much better than those posts from people that have zero knowledge about dropshipping and want someone to tell them how to become a millionaire by the end of the week\n------\n\n\nPost ID: 1hdg5rp\nTitle: You guys be careful out there\nScore: 10\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nYes 100%, I had one reach out to me. Tried to charge almost double more than Aliexpress...\nYeah even with legitimate agents, the price of shipping and storage is extortionate.\n\nHere's why I still dropship after 4 years and haven't transitioned to agent or 3PL\nhttps://youtu.be/l7uSiQ9sHik?si=aQ9_tytfRXjj7Gzu\n------\n\n\nPost ID: 1hdahzr\nTitle: Trending Niches on TikTok Shop US in December\nScore: 7\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n------\n\n\nPost ID: 1hd2nk7\nTitle: I have a TikTok shop for sale, what is a fair price to ask for it?\nScore: 12\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nFor dropshipping stores with that short of a history you would realisticly be looking at 500-750$ area.\n\nDropshipping stores in themself do not sell for nearly the same as normal companies that are in multipliers of annual incomes.  \nAnd with both being limited to a platform like that plus such a short history, you are not even guaranteed to get 3x average monthly profit (and you can not expect to get the holiday peak included in that average).\nAvoid putting any money into tictok until after you know if the ban does or doesn't go through next month.\n------\n\n\nPost ID: 1hcv8pi\nTitle: Doing Ok I Guess\nScore: 32\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n>(ironic most people seek the opposite).\n\nMost kids/teens walking into it imagining it being easy money seek it, majority that are older do not really seek it.\n\nDoing something like dropshipping fulltime is something that sounds great intil you actualy do it tends to be the experience.  \nYou tend to start missing the coworkers, meetings etc that you used to somewhat hate.\nKeep moving forward, you got this\n------\n\n\nPost ID: 1hcfjg8\nTitle: We're a manufacturer from Nepal. I've only recently learned about drop shipping. Is there a specific word for sellers? how do I connect with them?\nScore: 12\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWhat do you manufacture? Cost? Shipping cost and time?\nIm interested in selling for you lets connect @zillymilli instagram\n------\n\n\nPost ID: 1hcaa94\nTitle: Dropshipping tips-what to sell in January to make 6fig\nScore: 11\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWinter halt mostly happens in the northern most states, not al around, but the major factor is festive season. Not for all industries like gifting, or clothing, etc. But for manufacturing it becomes a pause.\n------\n\n\nPost ID: 1hc7am0\nTitle: Instagram acc 60k\nScore: 22\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI wouldn't rebrand it, as the followers are there for the food. Run with that niche.\nInstead of selling t shirts or gimmicks , you could sell recipes or cooking pdfs :)\n------\n\n\n        Provide insights, trends, or recommendations based on these posts.\n        "}], 'model': 'gpt-4o-mini', 'max_tokens': 3000, 'temperature': 0.7}}
2024-12-14 13:36:20,845 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 13:36:20,845 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-12-14 13:36:20,845 [DEBUG] send_request_headers.complete
2024-12-14 13:36:20,845 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-12-14 13:36:20,846 [DEBUG] send_request_body.complete
2024-12-14 13:36:20,846 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-12-14 13:36:35,650 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 18:36:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-wfobhzlf64ogbzvuffig3c5l'), (b'openai-processing-ms', b'14649'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'195187'), (b'x-ratelimit-reset-requests', b'15.857s'), (b'x-ratelimit-reset-tokens', b'1.443s'), (b'x-request-id', b'req_73235dbfdd2c5c5266bc948e0eb67377'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f204c86ce7eefa3-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 13:36:35,651 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-14 13:36:35,651 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-12-14 13:36:35,651 [DEBUG] receive_response_body.complete
2024-12-14 13:36:35,651 [DEBUG] response_closed.started
2024-12-14 13:36:35,651 [DEBUG] response_closed.complete
2024-12-14 13:36:35,651 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sat, 14 Dec 2024 18:36:35 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-wfobhzlf64ogbzvuffig3c5l', 'openai-processing-ms': '14649', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '195187', 'x-ratelimit-reset-requests': '15.857s', 'x-ratelimit-reset-tokens': '1.443s', 'x-request-id': 'req_73235dbfdd2c5c5266bc948e0eb67377', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f204c86ce7eefa3-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 13:36:35,652 [DEBUG] request_id: req_73235dbfdd2c5c5266bc948e0eb67377
2024-12-14 13:36:35,652 [INFO] GPT-4 analysis completed successfully.
2024-12-14 15:22:27,823 [DEBUG] Starting new HTTPS connection (1): pypi.org:443
2024-12-14 15:22:27,994 [DEBUG] https://pypi.org:443 "GET /pypi/praw/json HTTP/11" 200 36290
2024-12-14 15:22:28,040 [INFO] Successfully connected to the Reddit API.
2024-12-14 15:22:28,041 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734207748.041434
2024-12-14 15:22:28,041 [DEBUG] Data: None
2024-12-14 15:22:28,041 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-14 15:22:28,043 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-14 15:22:28,477 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 653
2024-12-14 15:22:28,479 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-14 15:22:29,644 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 55436
2024-12-14 15:22:29,705 [DEBUG] Response: 200 (55436 bytes) (rst-451:rem-999.0:used-1 ratelimit) at 1734207749.705963
2024-12-14 15:22:29,725 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdo31p/ at 1734207749.725301
2024-12-14 15:22:29,725 [DEBUG] Data: None
2024-12-14 15:22:29,725 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:22:29,956 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdo31p/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4588
2024-12-14 15:22:29,961 [DEBUG] Response: 200 (4588 bytes) (rst-450:rem-998.0:used-2 ratelimit) at 1734207749.961866
2024-12-14 15:22:29,964 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdlno3/ at 1734207749.964871
2024-12-14 15:22:29,965 [DEBUG] Data: None
2024-12-14 15:22:29,965 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:22:30,159 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdlno3/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3320
2024-12-14 15:22:30,160 [DEBUG] Response: 200 (3320 bytes) (rst-449:rem-997.0:used-3 ratelimit) at 1734207750.160713
2024-12-14 15:22:30,162 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdg5rp/ at 1734207750.162466
2024-12-14 15:22:30,162 [DEBUG] Data: None
2024-12-14 15:22:30,162 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:22:30,354 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdg5rp/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3824
2024-12-14 15:22:30,355 [DEBUG] Response: 200 (3824 bytes) (rst-449:rem-996.0:used-4 ratelimit) at 1734207750.355826
2024-12-14 15:22:30,357 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdahzr/ at 1734207750.357478
2024-12-14 15:22:30,357 [DEBUG] Data: None
2024-12-14 15:22:30,357 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:22:30,540 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdahzr/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2518
2024-12-14 15:22:30,541 [DEBUG] Response: 200 (2518 bytes) (rst-449:rem-995.0:used-5 ratelimit) at 1734207750.541513
2024-12-14 15:22:30,542 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hd2nk7/ at 1734207750.5428019
2024-12-14 15:22:30,542 [DEBUG] Data: None
2024-12-14 15:22:30,543 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:22:30,798 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hd2nk7/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7842
2024-12-14 15:22:30,800 [DEBUG] Response: 200 (7842 bytes) (rst-449:rem-994.0:used-6 ratelimit) at 1734207750.800012
2024-12-14 15:22:30,804 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcv8pi/ at 1734207750.804266
2024-12-14 15:22:30,804 [DEBUG] Data: None
2024-12-14 15:22:30,804 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:22:30,980 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcv8pi/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3046
2024-12-14 15:22:30,982 [DEBUG] Response: 200 (3046 bytes) (rst-449:rem-993.0:used-7 ratelimit) at 1734207750.982425
2024-12-14 15:22:30,984 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hci0sx/ at 1734207750.984239
2024-12-14 15:22:30,984 [DEBUG] Data: None
2024-12-14 15:22:30,984 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:22:31,248 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hci0sx/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6639
2024-12-14 15:22:31,249 [DEBUG] Response: 200 (6639 bytes) (rst-448:rem-992.0:used-8 ratelimit) at 1734207751.2499661
2024-12-14 15:22:31,253 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcfjg8/ at 1734207751.2531168
2024-12-14 15:22:31,253 [DEBUG] Data: None
2024-12-14 15:22:31,253 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:22:31,434 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcfjg8/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4253
2024-12-14 15:22:31,435 [DEBUG] Response: 200 (4253 bytes) (rst-448:rem-991.0:used-9 ratelimit) at 1734207751.4354382
2024-12-14 15:22:31,437 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcaa94/ at 1734207751.4371111
2024-12-14 15:22:31,437 [DEBUG] Data: None
2024-12-14 15:22:31,437 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:22:31,604 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcaa94/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2769
2024-12-14 15:22:31,604 [DEBUG] Response: 200 (2769 bytes) (rst-448:rem-990.0:used-10 ratelimit) at 1734207751.604876
2024-12-14 15:22:31,606 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hc7am0/ at 1734207751.6065018
2024-12-14 15:22:31,606 [DEBUG] Data: None
2024-12-14 15:22:31,606 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:22:31,880 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hc7am0/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7554
2024-12-14 15:22:31,882 [DEBUG] Response: 200 (7554 bytes) (rst-448:rem-989.0:used-11 ratelimit) at 1734207751.882505
2024-12-14 15:22:31,886 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734207751.8869061
2024-12-14 15:22:31,887 [DEBUG] Data: None
2024-12-14 15:22:31,887 [DEBUG] Params: {'after': 't3_1h7a71l', 'limit': 200, 'raw_json': 1}
2024-12-14 15:22:32,740 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h7a71l&raw_json=1 HTTP/11" 200 48330
2024-12-14 15:22:32,768 [DEBUG] Response: 200 (48330 bytes) (rst-448:rem-988.0:used-12 ratelimit) at 1734207752.768048
2024-12-14 15:22:32,778 [INFO] Fetched and filtered 10 posts.
2024-12-14 15:22:32,798 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': "\n    You are a helpful assistant. Identify up to 20 good posts.\n\n    Here are the posts:\n    Post ID: 1hdo31p\nTitle: Is email marketing worth the time and money for small e-commerce businesses?\nScore: 8\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI think yes. I plan on working more on this next year and have a decent list to start of people who have signed up to a newsletter.\n\nIt shouldn't be costly at all when you start as free plans are provided with limitations. Once you start seeing results you can then invest money.\n\nIf you're just cold calling you'll land in spam folders and that's pointless. Get people to sign up and verify your domain so you land in their actual inbox!\nYep! I was doing 30%+ of my revenue through email. And it was incremental revenue. \n\nYou dont have to overbake it. \n\n1. Text emails are underrated. \n2. For HTML emails, get a solid template designed up and then its easy to swap in new creative each time. Canva is your friend or get someone on Fiverr to help. \n3. Set up a few smart automationsmight take you an hourand then establish a send cadence; maybe one email a week. Again, this shouldnt take more than 30-60 minutes an email. Time well spent. Provides youve got a database of course. \n4. If your database is tinyunder 50you could even just send the odd email directly to key customers. Hey, John here. Im the owner of XYZ Just wanted to mention\n------\nPost ID: 1hdlno3\nTitle: Dropshipping in 2024: A Comedy Special\nScore: 26\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI dont care if this is written by AI. Its rather funny. Especially Day 30. \nCertainly much better than those posts from people that have zero knowledge about dropshipping and want someone to tell them how to become a millionaire by the end of the week\n------\nPost ID: 1hdg5rp\nTitle: You guys be careful out there\nScore: 9\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nYes 100%, I had one reach out to me. Tried to charge almost double more than Aliexpress...\nYeah even with legitimate agents, the price of shipping and storage is extortionate.\n\nHere's why I still dropship after 4 years and haven't transitioned to agent or 3PL\nhttps://youtu.be/l7uSiQ9sHik?si=aQ9_tytfRXjj7Gzu\n------\nPost ID: 1hdahzr\nTitle: Trending Niches on TikTok Shop US in December\nScore: 6\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n------\nPost ID: 1hd2nk7\nTitle: I have a TikTok shop for sale, what is a fair price to ask for it?\nScore: 12\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nFor dropshipping stores with that short of a history you would realisticly be looking at 500-750$ area.\n\nDropshipping stores in themself do not sell for nearly the same as normal companies that are in multipliers of annual incomes.  \nAnd with both being limited to a platform like that plus such a short history, you are not even guaranteed to get 3x average monthly profit (and you can not expect to get the holiday peak included in that average).\nAvoid putting any money into tictok until after you know if the ban does or doesn't go through next month.\n------\nPost ID: 1hcv8pi\nTitle: Doing Ok I Guess\nScore: 30\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n>(ironic most people seek the opposite).\n\nMost kids/teens walking into it imagining it being easy money seek it, majority that are older do not really seek it.\n\nDoing something like dropshipping fulltime is something that sounds great intil you actualy do it tends to be the experience.  \nYou tend to start missing the coworkers, meetings etc that you used to somewhat hate.\nKeep moving forward, you got this\n------\nPost ID: 1hci0sx\nTitle: How long did it take for you to make the first sale?\nScore: 13\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI know this doesn't answer your question, but I don't think furniture is a good niche for dropshipping, especially for a beginner. Just my 2 cents.\nWhen i initialy started dropshipping half a lifetime ago it was 2-3hours from starting to promote store to first sales, from posting items on listing sites and driving them to the store to purchase.\n\nWhen we launch a store today its also same day from ads.  \nBut with ads is not as much a question if you drive traffic and get sales with a ok store, its how much do you spend per sale.\n------\nPost ID: 1hcfjg8\nTitle: We're a manufacturer from Nepal. I've only recently learned about drop shipping. Is there a specific word for sellers? how do I connect with them?\nScore: 12\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWhat do you manufacture? Cost? Shipping cost and time?\nIm interested in selling for you lets connect @zillymilli instagram\n------\nPost ID: 1hcaa94\nTitle: Dropshipping tips-what to sell in January to make 6fig\nScore: 12\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWinter halt mostly happens in the northern most states, not al around, but the major factor is festive season. Not for all industries like gifting, or clothing, etc. But for manufacturing it becomes a pause.\n------\nPost ID: 1hc7am0\nTitle: Instagram acc 60k\nScore: 22\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI wouldn't rebrand it, as the followers are there for the food. Run with that niche.\nInstead of selling t shirts or gimmicks , you could sell recipes or cooking pdfs :)\n------\n\n\n    Return only a comma-separated list of post IDs without any additional text.\n    "}], 'model': 'gpt-4o-mini', 'max_tokens': 500, 'temperature': 0.7}}
2024-12-14 15:22:32,824 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 15:22:32,824 [DEBUG] connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 15:22:32,883 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10dca9a90>
2024-12-14 15:22:32,883 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x10dc68f80> server_hostname='api.openai.com' timeout=5.0
2024-12-14 15:22:32,921 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11ecdfb10>
2024-12-14 15:22:32,922 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-12-14 15:22:32,922 [DEBUG] send_request_headers.complete
2024-12-14 15:22:32,922 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-12-14 15:22:32,922 [DEBUG] send_request_body.complete
2024-12-14 15:22:32,922 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-12-14 15:22:34,068 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 20:22:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-wfobhzlf64ogbzvuffig3c5l'), (b'openai-processing-ms', b'922'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'197442'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'767ms'), (b'x-request-id', b'req_a7fcbb8ea4aec46b1df412825a1f8d79'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=pmqlKnAA5LMRsvu0RAVsOTDpKNSwyM.NB64Fjww_oI0-1734207754-1.0.1.1-7P9aR5QGYD1BFQXbb7RgMSsSuDwbqU2pYH29YxIjaTN7xKMAz9QAnJLb1mb4wIYHBNXh8NegmNO2P4a.7Y1xSw; path=/; expires=Sat, 14-Dec-24 20:52:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=pUn5t7vvy0Aci8hRSIizMmfyZPVbu6Tyk8qSZTPPhWw-1734207754080-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f20e8181c917295-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 15:22:34,069 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-14 15:22:34,069 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-12-14 15:22:34,069 [DEBUG] receive_response_body.complete
2024-12-14 15:22:34,069 [DEBUG] response_closed.started
2024-12-14 15:22:34,069 [DEBUG] response_closed.complete
2024-12-14 15:22:34,070 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sat, 14 Dec 2024 20:22:34 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-wfobhzlf64ogbzvuffig3c5l'), ('openai-processing-ms', '922'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '197442'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '767ms'), ('x-request-id', 'req_a7fcbb8ea4aec46b1df412825a1f8d79'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=pmqlKnAA5LMRsvu0RAVsOTDpKNSwyM.NB64Fjww_oI0-1734207754-1.0.1.1-7P9aR5QGYD1BFQXbb7RgMSsSuDwbqU2pYH29YxIjaTN7xKMAz9QAnJLb1mb4wIYHBNXh8NegmNO2P4a.7Y1xSw; path=/; expires=Sat, 14-Dec-24 20:52:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=pUn5t7vvy0Aci8hRSIizMmfyZPVbu6Tyk8qSZTPPhWw-1734207754080-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f20e8181c917295-EWR'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-12-14 15:22:34,070 [DEBUG] request_id: req_a7fcbb8ea4aec46b1df412825a1f8d79
2024-12-14 15:22:34,074 [INFO] GPT-3.5 identified 9 good posts.
2024-12-14 15:22:34,087 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': "\n        Analyze these posts from r/dropship:\n\n        Post ID: 1hdo31p\nTitle: Is email marketing worth the time and money for small e-commerce businesses?\nScore: 8\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI think yes. I plan on working more on this next year and have a decent list to start of people who have signed up to a newsletter.\n\nIt shouldn't be costly at all when you start as free plans are provided with limitations. Once you start seeing results you can then invest money.\n\nIf you're just cold calling you'll land in spam folders and that's pointless. Get people to sign up and verify your domain so you land in their actual inbox!\nYep! I was doing 30%+ of my revenue through email. And it was incremental revenue. \n\nYou dont have to overbake it. \n\n1. Text emails are underrated. \n2. For HTML emails, get a solid template designed up and then its easy to swap in new creative each time. Canva is your friend or get someone on Fiverr to help. \n3. Set up a few smart automationsmight take you an hourand then establish a send cadence; maybe one email a week. Again, this shouldnt take more than 30-60 minutes an email. Time well spent. Provides youve got a database of course. \n4. If your database is tinyunder 50you could even just send the odd email directly to key customers. Hey, John here. Im the owner of XYZ Just wanted to mention\n------\n\n\nPost ID: 1hdlno3\nTitle: Dropshipping in 2024: A Comedy Special\nScore: 26\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI dont care if this is written by AI. Its rather funny. Especially Day 30. \nCertainly much better than those posts from people that have zero knowledge about dropshipping and want someone to tell them how to become a millionaire by the end of the week\n------\n\n\nPost ID: 1hdg5rp\nTitle: You guys be careful out there\nScore: 9\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nYes 100%, I had one reach out to me. Tried to charge almost double more than Aliexpress...\nYeah even with legitimate agents, the price of shipping and storage is extortionate.\n\nHere's why I still dropship after 4 years and haven't transitioned to agent or 3PL\nhttps://youtu.be/l7uSiQ9sHik?si=aQ9_tytfRXjj7Gzu\n------\n\n\nPost ID: 1hdahzr\nTitle: Trending Niches on TikTok Shop US in December\nScore: 6\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n------\n\n\nPost ID: 1hd2nk7\nTitle: I have a TikTok shop for sale, what is a fair price to ask for it?\nScore: 12\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nFor dropshipping stores with that short of a history you would realisticly be looking at 500-750$ area.\n\nDropshipping stores in themself do not sell for nearly the same as normal companies that are in multipliers of annual incomes.  \nAnd with both being limited to a platform like that plus such a short history, you are not even guaranteed to get 3x average monthly profit (and you can not expect to get the holiday peak included in that average).\nAvoid putting any money into tictok until after you know if the ban does or doesn't go through next month.\n------\n\n\nPost ID: 1hcv8pi\nTitle: Doing Ok I Guess\nScore: 30\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n>(ironic most people seek the opposite).\n\nMost kids/teens walking into it imagining it being easy money seek it, majority that are older do not really seek it.\n\nDoing something like dropshipping fulltime is something that sounds great intil you actualy do it tends to be the experience.  \nYou tend to start missing the coworkers, meetings etc that you used to somewhat hate.\nKeep moving forward, you got this\n------\n\n\nPost ID: 1hci0sx\nTitle: How long did it take for you to make the first sale?\nScore: 13\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI know this doesn't answer your question, but I don't think furniture is a good niche for dropshipping, especially for a beginner. Just my 2 cents.\nWhen i initialy started dropshipping half a lifetime ago it was 2-3hours from starting to promote store to first sales, from posting items on listing sites and driving them to the store to purchase.\n\nWhen we launch a store today its also same day from ads.  \nBut with ads is not as much a question if you drive traffic and get sales with a ok store, its how much do you spend per sale.\n------\n\n\nPost ID: 1hcaa94\nTitle: Dropshipping tips-what to sell in January to make 6fig\nScore: 12\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWinter halt mostly happens in the northern most states, not al around, but the major factor is festive season. Not for all industries like gifting, or clothing, etc. But for manufacturing it becomes a pause.\n------\n\n\nPost ID: 1hc7am0\nTitle: Instagram acc 60k\nScore: 22\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI wouldn't rebrand it, as the followers are there for the food. Run with that niche.\nInstead of selling t shirts or gimmicks , you could sell recipes or cooking pdfs :)\n------\n\n\n        Provide insights, trends, or recommendations based on these posts.\n        "}], 'model': 'gpt-4o-mini', 'max_tokens': 3000, 'temperature': 0.7}}
2024-12-14 15:22:34,088 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 15:22:34,089 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-12-14 15:22:34,089 [DEBUG] send_request_headers.complete
2024-12-14 15:22:34,089 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-12-14 15:22:34,089 [DEBUG] send_request_body.complete
2024-12-14 15:22:34,089 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-12-14 15:22:43,088 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 20:22:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-wfobhzlf64ogbzvuffig3c5l'), (b'openai-processing-ms', b'8830'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'195110'), (b'x-ratelimit-reset-requests', b'16.168s'), (b'x-ratelimit-reset-tokens', b'1.467s'), (b'x-request-id', b'req_8370c85a2dcd5320d218b555989c287f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f20e81f5e0a7295-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 15:22:43,089 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-14 15:22:43,090 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-12-14 15:22:43,090 [DEBUG] receive_response_body.complete
2024-12-14 15:22:43,090 [DEBUG] response_closed.started
2024-12-14 15:22:43,090 [DEBUG] response_closed.complete
2024-12-14 15:22:43,091 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sat, 14 Dec 2024 20:22:43 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-wfobhzlf64ogbzvuffig3c5l', 'openai-processing-ms': '8830', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '195110', 'x-ratelimit-reset-requests': '16.168s', 'x-ratelimit-reset-tokens': '1.467s', 'x-request-id': 'req_8370c85a2dcd5320d218b555989c287f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f20e81f5e0a7295-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 15:22:43,091 [DEBUG] request_id: req_8370c85a2dcd5320d218b555989c287f
2024-12-14 15:22:43,091 [INFO] GPT-4 analysis completed successfully.
2024-12-14 15:25:00,383 [INFO] Successfully connected to the Reddit API.
2024-12-14 15:25:00,385 [DEBUG] Fetching: GET https://oauth.reddit.com/r/stocks/new at 1734207900.3852422
2024-12-14 15:25:00,385 [DEBUG] Data: None
2024-12-14 15:25:00,385 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-14 15:25:00,388 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-14 15:25:00,871 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 651
2024-12-14 15:25:00,872 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-14 15:25:02,131 [DEBUG] https://oauth.reddit.com:443 "GET /r/stocks/new?limit=200&raw_json=1 HTTP/11" 200 98327
2024-12-14 15:25:02,215 [DEBUG] Response: 200 (98327 bytes) (rst-298:rem-987.0:used-13 ratelimit) at 1734207902.215543
2024-12-14 15:25:02,228 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1heb1aj/ at 1734207902.228501
2024-12-14 15:25:02,228 [DEBUG] Data: None
2024-12-14 15:25:02,228 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:02,427 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1heb1aj/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4362
2024-12-14 15:25:02,428 [DEBUG] Response: 200 (4362 bytes) (rst-297:rem-986.0:used-14 ratelimit) at 1734207902.4286458
2024-12-14 15:25:02,430 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1he8nxm/ at 1734207902.430627
2024-12-14 15:25:02,430 [DEBUG] Data: None
2024-12-14 15:25:02,430 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:02,618 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1he8nxm/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3458
2024-12-14 15:25:02,621 [DEBUG] Response: 200 (3458 bytes) (rst-297:rem-985.0:used-15 ratelimit) at 1734207902.6210618
2024-12-14 15:25:02,622 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1he8c0q/ at 1734207902.6221492
2024-12-14 15:25:02,622 [DEBUG] Data: None
2024-12-14 15:25:02,622 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:03,043 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1he8c0q/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 13198
2024-12-14 15:25:03,045 [DEBUG] Response: 200 (13198 bytes) (rst-297:rem-984.0:used-16 ratelimit) at 1734207903.045471
2024-12-14 15:25:03,051 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1he43hc/ at 1734207903.051622
2024-12-14 15:25:03,051 [DEBUG] Data: None
2024-12-14 15:25:03,052 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:03,247 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1he43hc/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3473
2024-12-14 15:25:03,248 [DEBUG] Response: 200 (3473 bytes) (rst-296:rem-983.0:used-17 ratelimit) at 1734207903.248897
2024-12-14 15:25:03,250 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdxxw6/ at 1734207903.250711
2024-12-14 15:25:03,250 [DEBUG] Data: None
2024-12-14 15:25:03,250 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:03,690 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdxxw6/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 21026
2024-12-14 15:25:03,713 [DEBUG] Response: 200 (21026 bytes) (rst-296:rem-982.0:used-18 ratelimit) at 1734207903.713571
2024-12-14 15:25:03,722 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdvkcy/ at 1734207903.72248
2024-12-14 15:25:03,722 [DEBUG] Data: None
2024-12-14 15:25:03,722 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:03,883 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdvkcy/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2019
2024-12-14 15:25:03,883 [DEBUG] Response: 200 (2019 bytes) (rst-296:rem-981.0:used-19 ratelimit) at 1734207903.8839738
2024-12-14 15:25:03,885 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdrfe6/ at 1734207903.885215
2024-12-14 15:25:03,885 [DEBUG] Data: None
2024-12-14 15:25:03,885 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:04,580 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdrfe6/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 22066
2024-12-14 15:25:04,583 [DEBUG] Response: 200 (22066 bytes) (rst-296:rem-980.0:used-20 ratelimit) at 1734207904.583271
2024-12-14 15:25:04,592 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdmaj3/ at 1734207904.5924962
2024-12-14 15:25:04,592 [DEBUG] Data: None
2024-12-14 15:25:04,592 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:04,981 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdmaj3/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 15089
2024-12-14 15:25:04,983 [DEBUG] Response: 200 (15089 bytes) (rst-295:rem-979.0:used-21 ratelimit) at 1734207904.983971
2024-12-14 15:25:04,989 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdlc3o/ at 1734207904.989144
2024-12-14 15:25:04,989 [DEBUG] Data: None
2024-12-14 15:25:04,989 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:05,337 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdlc3o/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 11541
2024-12-14 15:25:05,341 [DEBUG] Response: 200 (11541 bytes) (rst-294:rem-978.0:used-22 ratelimit) at 1734207905.341075
2024-12-14 15:25:05,347 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdkaq6/ at 1734207905.3478599
2024-12-14 15:25:05,347 [DEBUG] Data: None
2024-12-14 15:25:05,348 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:07,053 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdkaq6/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 71851
2024-12-14 15:25:07,089 [DEBUG] Response: 200 (71851 bytes) (rst-294:rem-977.0:used-23 ratelimit) at 1734207907.089131
2024-12-14 15:25:07,115 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdgzh6/ at 1734207907.1155689
2024-12-14 15:25:07,115 [DEBUG] Data: None
2024-12-14 15:25:07,115 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:07,477 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdgzh6/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 15715
2024-12-14 15:25:07,481 [DEBUG] Response: 200 (15715 bytes) (rst-292:rem-976.0:used-24 ratelimit) at 1734207907.481667
2024-12-14 15:25:07,488 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdgkeo/ at 1734207907.488566
2024-12-14 15:25:07,488 [DEBUG] Data: None
2024-12-14 15:25:07,488 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:08,455 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdgkeo/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 18771
2024-12-14 15:25:08,458 [DEBUG] Response: 200 (18771 bytes) (rst-292:rem-975.0:used-25 ratelimit) at 1734207908.458974
2024-12-14 15:25:08,466 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdgkeo/_/m1xfwa1 at 1734207908.4667342
2024-12-14 15:25:08,466 [DEBUG] Data: None
2024-12-14 15:25:08,466 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:08,653 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdgkeo/_/m1xfwa1?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2790
2024-12-14 15:25:08,654 [DEBUG] Response: 200 (2790 bytes) (rst-291:rem-974.0:used-26 ratelimit) at 1734207908.654917
2024-12-14 15:25:08,656 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdcpo2/ at 1734207908.656173
2024-12-14 15:25:08,656 [DEBUG] Data: None
2024-12-14 15:25:08,656 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:08,947 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdcpo2/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7758
2024-12-14 15:25:08,948 [DEBUG] Response: 200 (7758 bytes) (rst-291:rem-973.0:used-27 ratelimit) at 1734207908.948242
2024-12-14 15:25:08,949 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hd9ewq/ at 1734207908.9491572
2024-12-14 15:25:08,949 [DEBUG] Data: None
2024-12-14 15:25:08,949 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:10,153 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hd9ewq/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 52521
2024-12-14 15:25:10,180 [DEBUG] Response: 200 (52521 bytes) (rst-290:rem-972.0:used-28 ratelimit) at 1734207910.180379
2024-12-14 15:25:10,198 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hd6j6q/ at 1734207910.1988769
2024-12-14 15:25:10,199 [DEBUG] Data: None
2024-12-14 15:25:10,199 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:11,326 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hd6j6q/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 38813
2024-12-14 15:25:11,336 [DEBUG] Response: 200 (38813 bytes) (rst-289:rem-971.0:used-29 ratelimit) at 1734207911.336376
2024-12-14 15:25:11,354 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hd3xw8/ at 1734207911.35495
2024-12-14 15:25:11,355 [DEBUG] Data: None
2024-12-14 15:25:11,355 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:11,747 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hd3xw8/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 13734
2024-12-14 15:25:11,749 [DEBUG] Response: 200 (13734 bytes) (rst-288:rem-970.0:used-30 ratelimit) at 1734207911.749633
2024-12-14 15:25:11,755 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hd3e7z/ at 1734207911.755172
2024-12-14 15:25:11,755 [DEBUG] Data: None
2024-12-14 15:25:11,755 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:12,081 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hd3e7z/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 11644
2024-12-14 15:25:12,083 [DEBUG] Response: 200 (11644 bytes) (rst-288:rem-969.0:used-31 ratelimit) at 1734207912.0837429
2024-12-14 15:25:12,098 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hd019p/ at 1734207912.098036
2024-12-14 15:25:12,098 [DEBUG] Data: None
2024-12-14 15:25:12,098 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:12,307 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hd019p/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4389
2024-12-14 15:25:12,309 [DEBUG] Response: 200 (4389 bytes) (rst-287:rem-968.0:used-32 ratelimit) at 1734207912.3093529
2024-12-14 15:25:12,312 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hczb56/ at 1734207912.3122911
2024-12-14 15:25:12,312 [DEBUG] Data: None
2024-12-14 15:25:12,312 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:12,568 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hczb56/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7184
2024-12-14 15:25:12,569 [DEBUG] Response: 200 (7184 bytes) (rst-287:rem-967.0:used-33 ratelimit) at 1734207912.5698612
2024-12-14 15:25:12,572 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcxg6d/ at 1734207912.5727959
2024-12-14 15:25:12,572 [DEBUG] Data: None
2024-12-14 15:25:12,573 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:12,747 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcxg6d/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4207
2024-12-14 15:25:12,748 [DEBUG] Response: 200 (4207 bytes) (rst-287:rem-966.0:used-34 ratelimit) at 1734207912.748207
2024-12-14 15:25:12,749 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcxeea/ at 1734207912.749145
2024-12-14 15:25:12,749 [DEBUG] Data: None
2024-12-14 15:25:12,749 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:13,387 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcxeea/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 21044
2024-12-14 15:25:13,392 [DEBUG] Response: 200 (21044 bytes) (rst-287:rem-965.0:used-35 ratelimit) at 1734207913.3922849
2024-12-14 15:25:13,403 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcvv08/ at 1734207913.403177
2024-12-14 15:25:13,403 [DEBUG] Data: None
2024-12-14 15:25:13,403 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:14,297 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcvv08/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 30581
2024-12-14 15:25:14,306 [DEBUG] Response: 200 (30581 bytes) (rst-286:rem-964.0:used-36 ratelimit) at 1734207914.306286
2024-12-14 15:25:14,319 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcvrbe/ at 1734207914.319762
2024-12-14 15:25:14,319 [DEBUG] Data: None
2024-12-14 15:25:14,320 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:14,806 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcvrbe/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 19078
2024-12-14 15:25:14,810 [DEBUG] Response: 200 (19078 bytes) (rst-285:rem-963.0:used-37 ratelimit) at 1734207914.810144
2024-12-14 15:25:14,818 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hctfm3/ at 1734207914.818131
2024-12-14 15:25:14,818 [DEBUG] Data: None
2024-12-14 15:25:14,818 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:15,031 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hctfm3/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 5976
2024-12-14 15:25:15,032 [DEBUG] Response: 200 (5976 bytes) (rst-285:rem-962.0:used-38 ratelimit) at 1734207915.032541
2024-12-14 15:25:15,035 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcs5au/ at 1734207915.03585
2024-12-14 15:25:15,036 [DEBUG] Data: None
2024-12-14 15:25:15,036 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:15,253 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcs5au/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 5957
2024-12-14 15:25:15,255 [DEBUG] Response: 200 (5957 bytes) (rst-284:rem-961.0:used-39 ratelimit) at 1734207915.255336
2024-12-14 15:25:15,257 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcnngo/ at 1734207915.257928
2024-12-14 15:25:15,258 [DEBUG] Data: None
2024-12-14 15:25:15,258 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:15,478 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcnngo/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 5120
2024-12-14 15:25:15,479 [DEBUG] Response: 200 (5120 bytes) (rst-284:rem-960.0:used-40 ratelimit) at 1734207915.4795468
2024-12-14 15:25:15,481 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcms3b/ at 1734207915.481787
2024-12-14 15:25:15,481 [DEBUG] Data: None
2024-12-14 15:25:15,481 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:16,563 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcms3b/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 32879
2024-12-14 15:25:16,572 [DEBUG] Response: 200 (32879 bytes) (rst-284:rem-959.0:used-41 ratelimit) at 1734207916.5728939
2024-12-14 15:25:16,587 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcms3b/_/m1to08s at 1734207916.587156
2024-12-14 15:25:16,587 [DEBUG] Data: None
2024-12-14 15:25:16,587 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:16,774 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcms3b/_/m1to08s?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 5914
2024-12-14 15:25:16,775 [DEBUG] Response: 200 (5914 bytes) (rst-283:rem-958.0:used-42 ratelimit) at 1734207916.7753642
2024-12-14 15:25:16,777 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcms3b/_/m1tqmui at 1734207916.777538
2024-12-14 15:25:16,777 [DEBUG] Data: None
2024-12-14 15:25:16,777 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:16,957 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcms3b/_/m1tqmui?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3462
2024-12-14 15:25:16,959 [DEBUG] Response: 200 (3462 bytes) (rst-283:rem-957.0:used-43 ratelimit) at 1734207916.95899
2024-12-14 15:25:16,960 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcms3b/_/m1tueac at 1734207916.9604402
2024-12-14 15:25:16,960 [DEBUG] Data: None
2024-12-14 15:25:16,960 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:17,133 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcms3b/_/m1tueac?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3628
2024-12-14 15:25:17,135 [DEBUG] Response: 200 (3628 bytes) (rst-282:rem-956.0:used-44 ratelimit) at 1734207917.135052
2024-12-14 15:25:17,136 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcm0te/ at 1734207917.1367
2024-12-14 15:25:17,136 [DEBUG] Data: None
2024-12-14 15:25:17,136 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:17,437 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcm0te/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 11613
2024-12-14 15:25:17,439 [DEBUG] Response: 200 (11613 bytes) (rst-282:rem-955.0:used-45 ratelimit) at 1734207917.4395578
2024-12-14 15:25:17,444 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hclzhd/ at 1734207917.4442828
2024-12-14 15:25:17,444 [DEBUG] Data: None
2024-12-14 15:25:17,444 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:17,635 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hclzhd/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3456
2024-12-14 15:25:17,637 [DEBUG] Response: 200 (3456 bytes) (rst-282:rem-954.0:used-46 ratelimit) at 1734207917.637223
2024-12-14 15:25:17,639 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hci8e1/ at 1734207917.639564
2024-12-14 15:25:17,639 [DEBUG] Data: None
2024-12-14 15:25:17,639 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:18,348 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hci8e1/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 34381
2024-12-14 15:25:18,356 [DEBUG] Response: 200 (34381 bytes) (rst-282:rem-953.0:used-47 ratelimit) at 1734207918.35659
2024-12-14 15:25:18,372 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hchkfs/ at 1734207918.372294
2024-12-14 15:25:18,372 [DEBUG] Data: None
2024-12-14 15:25:18,372 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:19,069 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hchkfs/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 14524
2024-12-14 15:25:19,071 [DEBUG] Response: 200 (14524 bytes) (rst-281:rem-952.0:used-48 ratelimit) at 1734207919.071873
2024-12-14 15:25:19,078 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcgxsj/ at 1734207919.078919
2024-12-14 15:25:19,079 [DEBUG] Data: None
2024-12-14 15:25:19,079 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:19,298 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcgxsj/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3920
2024-12-14 15:25:19,299 [DEBUG] Response: 200 (3920 bytes) (rst-280:rem-951.0:used-49 ratelimit) at 1734207919.2992482
2024-12-14 15:25:19,301 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcfjvy/ at 1734207919.301116
2024-12-14 15:25:19,301 [DEBUG] Data: None
2024-12-14 15:25:19,301 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:19,449 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcfjvy/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 1529
2024-12-14 15:25:19,450 [DEBUG] Response: 200 (1529 bytes) (rst-280:rem-950.0:used-50 ratelimit) at 1734207919.45018
2024-12-14 15:25:19,450 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hca86o/ at 1734207919.450876
2024-12-14 15:25:19,451 [DEBUG] Data: None
2024-12-14 15:25:19,451 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:20,693 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hca86o/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 42831
2024-12-14 15:25:20,719 [DEBUG] Response: 200 (42831 bytes) (rst-280:rem-949.0:used-51 ratelimit) at 1734207920.719148
2024-12-14 15:25:20,739 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hc8a47/ at 1734207920.739543
2024-12-14 15:25:20,739 [DEBUG] Data: None
2024-12-14 15:25:20,739 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:20,923 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hc8a47/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2733
2024-12-14 15:25:20,924 [DEBUG] Response: 200 (2733 bytes) (rst-279:rem-948.0:used-52 ratelimit) at 1734207920.924132
2024-12-14 15:25:20,925 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hc80ac/ at 1734207920.925629
2024-12-14 15:25:20,925 [DEBUG] Data: None
2024-12-14 15:25:20,925 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:22,202 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hc80ac/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 57362
2024-12-14 15:25:22,229 [DEBUG] Response: 200 (57362 bytes) (rst-278:rem-947.0:used-53 ratelimit) at 1734207922.2297962
2024-12-14 15:25:22,250 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hc4glu/ at 1734207922.250087
2024-12-14 15:25:22,250 [DEBUG] Data: None
2024-12-14 15:25:22,250 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:25:22,593 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hc4glu/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 10202
2024-12-14 15:25:22,595 [DEBUG] Response: 200 (10202 bytes) (rst-277:rem-946.0:used-54 ratelimit) at 1734207922.5954702
2024-12-14 15:25:22,599 [DEBUG] Fetching: GET https://oauth.reddit.com/r/stocks/new at 1734207922.599042
2024-12-14 15:25:22,599 [DEBUG] Data: None
2024-12-14 15:25:22,599 [DEBUG] Params: {'after': 't3_1h90jzg', 'limit': 200, 'raw_json': 1}
2024-12-14 15:25:23,795 [DEBUG] https://oauth.reddit.com:443 "GET /r/stocks/new?limit=200&after=t3_1h90jzg&raw_json=1 HTTP/11" 200 107458
2024-12-14 15:25:23,847 [DEBUG] Response: 200 (107458 bytes) (rst-277:rem-945.0:used-55 ratelimit) at 1734207923.847498
2024-12-14 15:25:23,859 [INFO] Fetched and filtered 37 posts.
2024-12-14 15:25:23,875 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\n    You are a helpful assistant. Identify up to 20 good posts.\n\n    Here are the posts:\n    Post ID: 1heb1aj\nTitle: Microsoft looks like a solid bet for long-term investors \nScore: 7\nFirst 3 Comments:\nAll of the Mag 7 are solid bets, that\'s why they\'re the Mag 7.\nWhats your position and entry?\nQuite the hot take\n------\nPost ID: 1he8nxm\nTitle: Buy or Not? Is Evolution AB a Good Bet Right Now? \nScore: 15\nFirst 3 Comments:\nI dont get why this stock is so cheap. Growing with 50% profit margins and strong market position. \n\nI think people are just short it because theyre short anything European\nChris Mayer owns them. He is the author of 100 Baggers. You can Google his portfolio\nIts a ridiculously cheap growth stock growing at mid double digits.\n\nI think it will be an easy 3 bagger over the next 3-4 years. Im DCAing in\n------\nPost ID: 1he8c0q\nTitle: Declining birth rates and future of stock market..\nScore: 30\nFirst 3 Comments:\nIt\'s true the birth rate is declining and more in some parts of the world, however, the global population is still projected to reach 10.3 billion by 2080\nNot gonna happen till the day i die so \nTrue but also you need to take into consideration immigration and that productivity is going up (at least in the US)\n------\nPost ID: 1he43hc\nTitle: Thoughts on LNTH?\nScore: 5\nFirst 3 Comments:\nWelcome to r/stocks!\n\nFor beginner advice, brokerage info, book recommendations, even advanced topics and more, please read our [Wiki here.](https://www.reddit.com/r/stocks/wiki/index)\n\nIf you\'re wondering **why a stock moved** a certain way, check out [Finviz](https://finviz.com/quote.ashx?t=spy) which aggregates the most news for almost every stock, but also see [Reuters](https://www.reuters.com/), and even [Yahoo Finance](https://finance.yahoo.com/).\n\nPlease direct all simple questions towards the stickied Daily Discussion and Quarterly Rate My Portfolio threads (sort by Hot, they\'re at the top).\n\nAlso include *some* [due diligence](https://www.investopedia.com/terms/d/duediligence.asp) to this post or it may be removed if it\'s low effort.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/stocks) if you have any questions or concerns.*\nIm seeing a much different price. Is there a typo?\nAre you possibly getting the price/book ratio confused with the price? Its current price is $93.02\n------\nPost ID: 1hdxxw6\nTitle: Broadcom (AVGO) broke the $1T barrier - here\'s how it compares to the Mag 7\nScore: 212\nFirst 3 Comments:\nThanks for stacking up all Mag 7 like this. Really useful for my rebalancing move next year.\nI dont have any input other than these numbers show how ridiculous TSLA is. Completely decoupled from reality. \n\nPE that is literally 4x all the others despite having the least operating income and the smallest margins. It wont be today, and it wont be tomorrow, but it will crash eventually.\nGOOGL seems cheap\n------\nPost ID: 1hdvkcy\nTitle: Looking for feedback on RBBN\nScore: 4\nFirst 3 Comments:\nWhat is Ribbons level of involvement with quantum computing? More specifically, do they have any partnerships in that realm? Kind of a wacko question but QC seems to be the way we are heading and with a comm tech company likely having future needs there.\n------\nPost ID: 1hdrfe6\nTitle: Annual changes to the nasdaq 100 announced\nScore: 293\nFirst 3 Comments:\nIndex ETF buyers funding Bitcoin now.\nLooking forward to SMCI removal from S&P 500 soon.\noh man the crrypto boys gonna be annoying\n------\nPost ID: 1hdmaj3\nTitle: AI Leading the Way: Palantir\'s Rise and Investment Potential\nScore: 19\nFirst 3 Comments:\nThe stock is overvalued even if you use something crazy like 2030 forward PE ratio\nI\'m also optimistic about PLTR.\n\nFunny thing is, I\'ve seen a lot of people ragging on it\nReddit is always interesting. When I bought in at 8 dollars per share in mid 2023 no one was talking about Palantir despite the AI hype already being in full swing. Somehow the bullish posts and analysis always seem to pop up after a stock has 10 X\'d.\n\nPersonally I hate making the decision between great company and extreme overvaluation hoping one side outweighs the other.\n------\nPost ID: 1hdlc3o\nTitle: Which founders do you invest in?\nScore: 57\nFirst 3 Comments:\nPart of the reason why I invested in CPRT was because the then co-ceo (founders son in law) took $1 salary and opted for stock instead. He is worth billions now and i like to think our objectives are aligned.\n\nOther companies in my portfolio which the founders are still active:\n\nMeta.  \nCoupang.  \nBerkshire Hathaway.  \nSanrio 8136 (grandson running Hello Kitty).   \nMedpace.\nFollowing. This is a school of thought I have given lots of thought to. I was pretty early in investing in Elon Musk with Tesla and Jack Dorsey with SQ. Peter Beck with Rocket Lab comes to mind, he seems very driven, passionate, somewhat of a visionary in his respective space.\nSPB\n------\nPost ID: 1hdkaq6\nTitle: When should you take profits? \nScore: 152\nFirst 3 Comments:\nWhen you go to a forum to ask "when should you take profits?"\nWould you buy it now? \n\nReframe the question to get the answer\nYes.\n------\nPost ID: 1hdgzh6\nTitle: Continued investment in AVGO\nScore: 93\nFirst 3 Comments:\nVery nice worth investing in, btw I read the article you posted in WSB about AVGO about a month ago and you accomplished your target price\nI think people overreacted with the VMWare masking AVGO growth rate I think it was a good acquisition that did what it was supposed to, under this new administration I think AVGO will be back in a few years acquiring another company and implementing it into its business, is that really such a bad thing? Yes they can improve their growth rate individually but if they can successfully acquire and implement acquisitions then why not. AVGO $300 is my price target.\nAs long as Nancy Pelosi stays in this trade, it\'s good\n------\nPost ID: 1hdgkeo\nTitle: 10 Yr/3 M Spread Has Un-inverted \nScore: 121\nFirst 3 Comments:\nI\'m not saying there won\'t be/can\'t be a recession, but I have seen the goalpost moved about this yield curve inversion so many times we\'re now playing in different stadiums\nCan someone explain what this means\nSo like what do the YouTuber bears talk about now? \n\n\nNot saying that the inversion curve holds no water, rather to be full on bear really hurt those who were 100% cash this year.\n------\nPost ID: 1hdcpo2\nTitle: Semiconductor Stocks Exposed To China With Tariffs Incoming\nScore: 82\nFirst 3 Comments:\nHi, you\'re on r/Stocks, please make sure your post is related to stocks or the stockmarket or it will most likely get removed as being off-topic/political; feel free to edit it now and be more specific.\n\n**To everyone commenting:**  Please focus on how this affects the stock market or specific stocks or it will be removed as being off-topic/political.\n\nIf you\'re interested in just politics, see our wiki on ["relevant subreddits"](https://www.reddit.com/r/stocks/wiki/index) and post to those Reddit communities instead without linking back here, thanks!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/stocks) if you have any questions or concerns.*\nSmartest thing Avgo ever did was become a us headquartered company\nBeth Kindig is one of the best semi analysts in the business. She knows the space inside out\n------\nPost ID: 1hd9ewq\nTitle: r/Stocks Daily Discussion & Fundamentals Friday Dec 13, 2024\nScore: 7\nFirst 3 Comments:\nAvgo up 200b market cap is pretty crazy\nWhat an odd day. Nasdaq green but META down 2%, NVDA down 2.5%, Amazon down around 1%.\nGLD has pulled back to the 15-day. If it drops below it (245.76), it will lose support and the seasonal thesis should be invalidated.\n------\nPost ID: 1hd6j6q\nTitle: Good Time To Buy Into Markets?\nScore: 133\nFirst 3 Comments:\nThe best time was yesterday, you missed it. \n\nYou wanna miss it some more?\nI thought the market was overvalued a year or even two years ago. The market can keep going like this for the 5 years,  at some point it will be a bear market, but you would have missed on a 50% gain. I would just focus on time in the market and not timing the market.\nPeople will say no because were at all time high but indexes are at all time high half the time in a bull market. A recession and slowdown in markets are sure to kick in but who knows if next year, in 2,3 years and how much growth will happen till then.\n\nThat being said, I would not lump sum all available cash right now. \n------\nPost ID: 1hd3xw8\nTitle: AAPL The Buyback machine\nScore: 87\nFirst 3 Comments:\nBeen holding apple since 08. I might skim some profit here and there but I don\'t over analyze companies like Apple. They are a company that makes its investors money over and over and over.\xa0\nAPPL is a "stay rich" equity, the shares won\'t tank over long period. \n\nThis company can acquire innovation by buying the companies off. So doesn\'t matter if said company is stagnant, it has enough war chest to last a long long time (long means next 40 years or thereabouts).\nI\'ve held APPL since 2006.  Buy and never sell, honestly.\n------\nPost ID: 1hd3e7z\nTitle: Hedging the SP500 with a put?\nScore: 14\nFirst 3 Comments:\nId personally rather hold cash and be ready to DCA in on dips. 5% with SGOV aint bad\nThe issue with ours is you need to be right about the direction AND time or else it expires worthless\nI\'ve been buying some puts exp 12/27\n\nIn case the market doesn\'t like the message the fed has. Since the market has been on a big run up, feels like they will be quite sensitive to any news.\n------\nPost ID: 1hd019p\nTitle: Market cap vs GDP weight, mother of all bubbles?\nScore: 2\nFirst 3 Comments:\nWhile I believe valuations look frothy, I dont think this pie chart comparison is a good one.\n\nThe big listed companies in the US are mostly multinationals and contribute heavily to GDP worldwide.\nGDP weight does not make any sense.\nUS corporate margins are almost twice as the rest of the world as well as a lot of companies from other countries being counted in the US market cap. That being said the US is trading high but not as high as it seems.\n------\nPost ID: 1hczb56\nTitle: Best way to sell large volume orders \nScore: 7\nFirst 3 Comments:\nIts called a trailing stop loss. You can set up all your trades with one automatically.\n\nThat said, never get too greedy and feel bad about taking profits. Overstaying and fear of missing out (FOMO) will cause you great losses.\nJust sell when you think its time\n\nYou can try to get fancy but the price might tank and you will be stuck with selling at a lower price\nTrailing stoploss wouldve made u sell tsla at 380 or something. Its not good for crazy stock which move up n down so much. Just take the profit n be happy about it\n------\nPost ID: 1hcxg6d\nTitle: 2025 Strategy - critique invited\nScore: 15\nFirst 3 Comments:\nBut if you cash out 90% of your port into the money market... don\'t you hafta consider the taxes owed?\nWhat money market fund are you using? Why did you choose MM vs t-bills or a t-bill etf?\nFor a second I thought this was wsb and was about to liquidate everything and put them into SPY\n------\nPost ID: 1hcxeea\nTitle: Broadcom beats on profit, says AI revenue more than tripled this year\nScore: 198\nFirst 3 Comments:\nIve said throughout the year the big 3 chip winners of the AI boom are Nvidia, Broadcom, and TSMC. Everything else is noise.\nLoaded up on Tuesdays  dip. Yea the pe is high but the companys actually growing unlike that car manufacturer\nI sold recently, you\'re welcome. \n------\nPost ID: 1hcvv08\nTitle: Costco beats on earnings as membership fee hike boosts revenue\nScore: 441\nFirst 3 Comments:\nEvery year I wish I got into this stock , and keep waiting for a good pull back but it always looks overvalued and keeps climbing\nIve owed Costco for a number of years and have always been worried about it being over priced.  Heres what keeps me in the stock:  there are only 600 stores in the US and 100 in Canada.  There is still ample room for expansion in North America let alone the rest of the world.\nGlizzy and a drink are still $1.50.\n------\nPost ID: 1hcvrbe\nTitle: Adobe shares suffer steepest drop in over two years on disappointing revenue guidance\nScore: 339\nFirst 3 Comments:\nI had made puts yesterday on a paper trading account thinking that ai was gonna kill adobe over time. Just had puts at 537 though didnt predict such a steep decline. Is this where I start trading options with real money and end up losing everything?\nI really don\'t get what people were expecting Adobe to start selling/doing to justify the $699/share price a few years ago.  \n\nAlso this article sucks, it twice mentions lowered 2025 guidance but never mentions the old or new figures.\nI bought today around $470 \n\n23 FWD PE with 50% margins is too tasty. \n\nBut I also bought at $470 earlier this year \n------\nPost ID: 1hctfm3\nTitle: Why I\'m bullish on MELI\nScore: 32\nFirst 3 Comments:\nTheir earnings came out a month ago\nShhh don\'t tell anyone about meli\nBut here\'s the kicker\n------\nPost ID: 1hcs5au\nTitle: Massive opportunity? \nScore: 11\nFirst 3 Comments:\nWhat makes them underpriced? Do you have any financial reasons\nHmm.   \nDecent numbers.    Low volume.  Decent profitability.   \n\nIt\'s not a quick score by any means as it\'s been bouncing between $10 and $12,   with occasional periods higher and lower, but generally flat-ish around $10-12. \n\nBut if all holds true, it could be a solid gaining stock in a long-term hold situation,  providing they don\'t have any adverse news.  \n\nhttps://www.google.com/finance/quote/HOEGF:OTCMKTS?sa=X&ved=2ahUKEwjjh56fgqOKAxV6L9AFHUuTLzsQ3ecFegQIIBAe&window=6M. \n\n\nMy thought:   They\'re better than speculative grade stocks but are still largely unknown on the world stage.   \n\n Regionally,  they may be making some progress, but in the big picture they\'re breaking into territory held by larger shipping companies, and the growth of such a sector is limited by a saturated industry with the underlying customer/user base in a slowdown.   (Auto.industry). \n\nConclusion: It may be nearing a good entry point to buy into it if it continues to drop.  But-- it will be a slow investment in one\'s portfolio. \n\nIt\'s a 5-year minimum buy and hold stock. \nVolume may make it a bit tough to move if something panics stock-holders.   You may not be able to get out as quickly as you\'d like.  \n\nBut then again, I\'m a truck driver, not a stock analyst.\nYou have to be able to buy them since they\'re not on the US market unless your brokerage has access. It looks interesting though.\n------\nPost ID: 1hcnngo\nTitle: Warner Bros. Discovery shares surge after company announces linear, streaming restructuring\nScore: 45\nFirst 3 Comments:\nso close to being able to get rid of this bag lol\n"Suing bondholders please queue..."\nGreat news for WBD stock. Assumedly most of the $40billion in debt is going with the linear tv Spinco. Whats left will be the studio and Max with 120million users and virtually no debt. About half the subscribers of Netflix but 1/15th the market cap.\xa0\n------\nPost ID: 1hcms3b\nTitle: Who is the best investment opportunity in AI, NVDA or PLTR?\nScore: 108\nFirst 3 Comments:\nHonestly, the big tech companies are the way to go. MSFT, GOOG, META, AMZN.\nGoogle\nPalantir if you bought more than a year ago, lol\n\nActual AI investments: MSFT, AMZN, GOOG. TSMC or NVDA if you don\'t think they\'re overvalued.\n------\nPost ID: 1hcm0te\nTitle: These are the stocks on my watchlist (12/12)\nScore: 91\nFirst 3 Comments:\nCurious about TTAN. Do you know if there is something particularly unique about their software solution that might be a competitive moat of some sort?\n\nIt kinda feels like another BL or similar - good stuff but a small addressable market, almost niche?\nQualcomm at PE 17 and fwd PE 12.\n\n\nWill markets suddenly wake up one day and realize this, like it happened with Google?\n\n\nIt got a new CTO now, who\'s the Guru behind 5G and 6G technology.\nI appreciate your daily posts. Just wanted to let you know\n------\nPost ID: 1hclzhd\nTitle: Canadian National railway\nScore: 6\nFirst 3 Comments:\nAs a cn employee it is SLOW. way to many people, not enough traffic. If it wasn\'t a duopoly it would be bankrupt\nI was looking at rails earlier today, but leaning CP and UNP over CNI.\nI prefer CPKC\n------\nPost ID: 1hci8e1\nTitle: r/Stocks Daily Discussion & Options Trading Thursday - Dec 12, 2024\nScore: 11\nFirst 3 Comments:\nPlease award me a medal for the most stupid person on this sub. Wanted Broadcom, placed order for Qualcomm !!! Thought it tanked 20% when I saw $160 price tag.\nI\'ve thinking we could have a weekly open/offtopic thread. I just like hanging around here reading news and random stuff, even tho I\'m only invested in ETFs. With 8.2M members there should be enough to build a small comunity. Thoughts?\nDecided to finally capitulate on CLFD for a 36% loss, as I figure might as well offset my taxable gains I\'ve been taking. Had a 27 shares left over. Now up to $18K in dry powder roughly (that figure was $0 dry powder January 2023, $13K January 2024).\n\nWhat went wrong with CLFD?\n\n- Fed rate hikes + general slowdown in 2022 caused all the big telecom companies to pullback on fiber capex\n- There was a major amount of over-ordering in 2021\n- Federal government has been a disgrace when it comes to disbursing federal funds. After 3 years, with $42B in BEADs funding authorized, not one home has been connected via this program. Just gotta slog through letter of intent, 5 year action plan, initial proposal, back and forth challenge process with local stakeholders, final proposal, ... Goes on and on. Now you have Trump + Elon (Starlink competing with fiber). Tariffs will hurt their operations in Mexico + Finland as well as supply chains. New administration will fight the rollout of BEADS most likely as a colossal waste of money (they\'re mostly right).\n- You see the same thing with the federal EV chargers. 7 charging stations connected with $5B authorized in 2021... To be clear it\'s not that the money is being thrown into a fire pit, it\'s being frozen for years on someone\'s balance sheet waiting for bureacrats at all levels of government needing to sign off. (Then it gets thrown into the pit)\n- Company has no (trustworthy) visibility into near term demand\n------\nPost ID: 1hchkfs\nTitle: How come AAPL isnt affected by the rise of the AI market?\nScore: 53\nFirst 3 Comments:\nIts the same reason BMW doesnt own an oil refinery\nI think AAPL has decoupled itself from the AI game. And it could be a smart move. AI in these relatively early stages is still an expensive game. AAPL seems content to focus on the consumer product/software aspects of their business which are cash cows, and they can monetise AI in the future by integrating other developers\' apps onto their platform anyway.\nApple is up 30% this year by the way\n------\nPost ID: 1hcgxsj\nTitle: Nvidia, Rigetti, Quantum Machines Deliver AI-Powered Quantum Computing \nScore: 40\nFirst 3 Comments:\nUmm great post -- need to string together a few more buzzwords, qubits, automata, spin torque, 4th dimension, dual big bang ... probably make it more appealing. Just saying.\nRgti is great choice\nForgot hyperscaler and green dildos\n------\nPost ID: 1hcfjvy\nTitle: Alaska Air stock soars to 52-week high of $63.95\nScore: 18\nFirst 3 Comments:\n\n------\nPost ID: 1hca86o\nTitle: Elon Musk becomes the first person to reach a net worth of $400 billion\nScore: 6088\nFirst 3 Comments:\nWhew, I was a bit worried he was having trouble putting food on the table\nHes increased his net worth since the election more than the annual GDP of most countries.\nI wonder how long his friendship with Trump will last.\n------\nPost ID: 1hc8a47\nTitle: $BITI Question \nScore: 6\nFirst 3 Comments:\nYou\'re both kind of wrong.\n\nIf Bitcoin goes up 100% in one single day, that ETF is gone. -100%. If Bitcoin goes up 50% on day 1 and 33% on day 2 (=100% total), the ETF will have lost only 66% of its value.\n\nEdit: Fixed the math, I hope.\nI\'ve never been a bitcoin believer, but Trump has talked about buying bitcoin with taxpayer money to create a national bitcoin reserve. All the crypto bros who supported him are looking for their payback. I wouldn\'t bet against it at this point.\nI see cause the daily rebalancing. I actually think understand it more now. Thank you.\n------\nPost ID: 1hc80ac\nTitle: Too late to buy RDDT? \nScore: 195\nFirst 3 Comments:\nYeah markets are closed, try tomorrow\nJust posting to make you feel betterI had the chance to buy IPO sharesand I didnt\nIf I can suggest: \n\nTake the amount you had originally allocated to buy RDDT and divide by 3. Take that 1/3 and buy RDDT.\n\nThis serves the following:\n\n- it takes the edge off FOMO\n\n(you buy more, if it drops 15% or more from your initial price. the last 1/3 you keep for later)\n\n- in the meantime, while 2/3 of your capital is waiting to be deployed, take the time and do some serious homework.\n\n-\n\nBy homework,\n\n- go and compare RDDT with its peers, go and find out on average as a group how are they being measured by multiples (multiples = p/e, p/s etc)\n\n- apply that group multiple on RDDT to see if RDDT  above or under valued\n\n- try and project some growth on RDDT into the future and work back wards to the present to see if the share price appreciation is worth it. \n\n- I did something like this before I bought RDDT, you can use this and update it to see if my assumptions were too conservative (which they are): \n\nhttps://www.reddit.com/u/raytoei/s/A2saaWOf76\n\n- dont worry too much if your numbers are way off, you can adjust them as you do more digging and read up on rddt earnings call etc. But you would have done more DD than the majority of people out there looking to buy RDDT.\n------\nPost ID: 1hc4glu\nTitle: 6 years investing but there are still open questions\nScore: 32\nFirst 3 Comments:\nTech has run for a long time at unprecedented levels, be wary of over leveraging in case of a humbling correction.\n\nPersonally thinking a safety net hedge may be the shout.\ndepends. most stocks fade away into bankrupt obscurity. but catch a star on the ground floor and yes the fortunes are born.\nI think you\'re speaking about generational wealth. If you can hold it that long and grow it and your kids can hold it and grow it, etc that is how it works.\n------\n\n\n    Return only a comma-separated list of post IDs without any additional text.\n    '}], 'model': 'gpt-4o-mini', 'max_tokens': 500, 'temperature': 0.7}}
2024-12-14 15:25:23,877 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 15:25:23,877 [DEBUG] close.started
2024-12-14 15:25:23,878 [DEBUG] close.complete
2024-12-14 15:25:23,878 [DEBUG] connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 15:25:23,974 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11e516fd0>
2024-12-14 15:25:23,974 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x10dc68f80> server_hostname='api.openai.com' timeout=5.0
2024-12-14 15:25:24,009 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11e4909d0>
2024-12-14 15:25:24,009 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-12-14 15:25:24,010 [DEBUG] send_request_headers.complete
2024-12-14 15:25:24,010 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-12-14 15:25:24,010 [DEBUG] send_request_body.complete
2024-12-14 15:25:24,010 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-12-14 15:25:26,129 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 20:25:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-wfobhzlf64ogbzvuffig3c5l'), (b'openai-processing-ms', b'1931'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'193852'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'1.844s'), (b'x-request-id', b'req_aba46b7a02241a27b8f506609840956a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f20ec455e53de92-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 15:25:26,130 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-14 15:25:26,130 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-12-14 15:25:26,139 [DEBUG] receive_response_body.complete
2024-12-14 15:25:26,139 [DEBUG] response_closed.started
2024-12-14 15:25:26,139 [DEBUG] response_closed.complete
2024-12-14 15:25:26,139 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sat, 14 Dec 2024 20:25:26 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-wfobhzlf64ogbzvuffig3c5l', 'openai-processing-ms': '1931', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '193852', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '1.844s', 'x-request-id': 'req_aba46b7a02241a27b8f506609840956a', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f20ec455e53de92-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 15:25:26,140 [DEBUG] request_id: req_aba46b7a02241a27b8f506609840956a
2024-12-14 15:25:26,140 [INFO] GPT-3.5 identified 20 good posts.
2024-12-14 15:25:26,160 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\n        Analyze these posts from r/stocks:\n\n        Post ID: 1he8nxm\nTitle: Buy or Not? Is Evolution AB a Good Bet Right Now? \nScore: 15\nFirst 3 Comments:\nI dont get why this stock is so cheap. Growing with 50% profit margins and strong market position. \n\nI think people are just short it because theyre short anything European\nChris Mayer owns them. He is the author of 100 Baggers. You can Google his portfolio\nIts a ridiculously cheap growth stock growing at mid double digits.\n\nI think it will be an easy 3 bagger over the next 3-4 years. Im DCAing in\n------\n\n\nPost ID: 1he8c0q\nTitle: Declining birth rates and future of stock market..\nScore: 30\nFirst 3 Comments:\nIt\'s true the birth rate is declining and more in some parts of the world, however, the global population is still projected to reach 10.3 billion by 2080\nNot gonna happen till the day i die so \nTrue but also you need to take into consideration immigration and that productivity is going up (at least in the US)\n------\n\n\nPost ID: 1he43hc\nTitle: Thoughts on LNTH?\nScore: 5\nFirst 3 Comments:\nWelcome to r/stocks!\n\nFor beginner advice, brokerage info, book recommendations, even advanced topics and more, please read our [Wiki here.](https://www.reddit.com/r/stocks/wiki/index)\n\nIf you\'re wondering **why a stock moved** a certain way, check out [Finviz](https://finviz.com/quote.ashx?t=spy) which aggregates the most news for almost every stock, but also see [Reuters](https://www.reuters.com/), and even [Yahoo Finance](https://finance.yahoo.com/).\n\nPlease direct all simple questions towards the stickied Daily Discussion and Quarterly Rate My Portfolio threads (sort by Hot, they\'re at the top).\n\nAlso include *some* [due diligence](https://www.investopedia.com/terms/d/duediligence.asp) to this post or it may be removed if it\'s low effort.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/stocks) if you have any questions or concerns.*\nIm seeing a much different price. Is there a typo?\nAre you possibly getting the price/book ratio confused with the price? Its current price is $93.02\n------\n\n\nPost ID: 1hdxxw6\nTitle: Broadcom (AVGO) broke the $1T barrier - here\'s how it compares to the Mag 7\nScore: 212\nFirst 3 Comments:\nThanks for stacking up all Mag 7 like this. Really useful for my rebalancing move next year.\nI dont have any input other than these numbers show how ridiculous TSLA is. Completely decoupled from reality. \n\nPE that is literally 4x all the others despite having the least operating income and the smallest margins. It wont be today, and it wont be tomorrow, but it will crash eventually.\nGOOGL seems cheap\n------\n\n\nPost ID: 1hdrfe6\nTitle: Annual changes to the nasdaq 100 announced\nScore: 293\nFirst 3 Comments:\nIndex ETF buyers funding Bitcoin now.\nLooking forward to SMCI removal from S&P 500 soon.\noh man the crrypto boys gonna be annoying\n------\n\n\nPost ID: 1hdkaq6\nTitle: When should you take profits? \nScore: 152\nFirst 3 Comments:\nWhen you go to a forum to ask "when should you take profits?"\nWould you buy it now? \n\nReframe the question to get the answer\nYes.\n------\n\n\nPost ID: 1hdgzh6\nTitle: Continued investment in AVGO\nScore: 93\nFirst 3 Comments:\nVery nice worth investing in, btw I read the article you posted in WSB about AVGO about a month ago and you accomplished your target price\nI think people overreacted with the VMWare masking AVGO growth rate I think it was a good acquisition that did what it was supposed to, under this new administration I think AVGO will be back in a few years acquiring another company and implementing it into its business, is that really such a bad thing? Yes they can improve their growth rate individually but if they can successfully acquire and implement acquisitions then why not. AVGO $300 is my price target.\nAs long as Nancy Pelosi stays in this trade, it\'s good\n------\n\n\nPost ID: 1hdgkeo\nTitle: 10 Yr/3 M Spread Has Un-inverted \nScore: 121\nFirst 3 Comments:\nI\'m not saying there won\'t be/can\'t be a recession, but I have seen the goalpost moved about this yield curve inversion so many times we\'re now playing in different stadiums\nCan someone explain what this means\nSo like what do the YouTuber bears talk about now? \n\n\nNot saying that the inversion curve holds no water, rather to be full on bear really hurt those who were 100% cash this year.\n------\n\n\nPost ID: 1hdcpo2\nTitle: Semiconductor Stocks Exposed To China With Tariffs Incoming\nScore: 82\nFirst 3 Comments:\nHi, you\'re on r/Stocks, please make sure your post is related to stocks or the stockmarket or it will most likely get removed as being off-topic/political; feel free to edit it now and be more specific.\n\n**To everyone commenting:**  Please focus on how this affects the stock market or specific stocks or it will be removed as being off-topic/political.\n\nIf you\'re interested in just politics, see our wiki on ["relevant subreddits"](https://www.reddit.com/r/stocks/wiki/index) and post to those Reddit communities instead without linking back here, thanks!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/stocks) if you have any questions or concerns.*\nSmartest thing Avgo ever did was become a us headquartered company\nBeth Kindig is one of the best semi analysts in the business. She knows the space inside out\n------\n\n\nPost ID: 1hcxg6d\nTitle: 2025 Strategy - critique invited\nScore: 15\nFirst 3 Comments:\nBut if you cash out 90% of your port into the money market... don\'t you hafta consider the taxes owed?\nWhat money market fund are you using? Why did you choose MM vs t-bills or a t-bill etf?\nFor a second I thought this was wsb and was about to liquidate everything and put them into SPY\n------\n\n\n        Provide insights, trends, or recommendations based on these posts.\n        '}], 'model': 'gpt-4o-mini', 'max_tokens': 3000, 'temperature': 0.7}}
2024-12-14 15:25:26,161 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 15:25:26,161 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-12-14 15:25:26,161 [DEBUG] send_request_headers.complete
2024-12-14 15:25:26,161 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-12-14 15:25:26,161 [DEBUG] send_request_body.complete
2024-12-14 15:25:26,161 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-12-14 15:25:35,479 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 20:25:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-wfobhzlf64ogbzvuffig3c5l'), (b'openai-processing-ms', b'9181'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'195512'), (b'x-ratelimit-reset-requests', b'15.17s'), (b'x-ratelimit-reset-tokens', b'1.346s'), (b'x-request-id', b'req_3a8b23db3e6612d92eef9be009727a7b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f20ec52cd00de92-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 15:25:35,480 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-14 15:25:35,480 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-12-14 15:25:35,481 [DEBUG] receive_response_body.complete
2024-12-14 15:25:35,482 [DEBUG] response_closed.started
2024-12-14 15:25:35,482 [DEBUG] response_closed.complete
2024-12-14 15:25:35,482 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sat, 14 Dec 2024 20:25:35 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-wfobhzlf64ogbzvuffig3c5l', 'openai-processing-ms': '9181', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '195512', 'x-ratelimit-reset-requests': '15.17s', 'x-ratelimit-reset-tokens': '1.346s', 'x-request-id': 'req_3a8b23db3e6612d92eef9be009727a7b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f20ec52cd00de92-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 15:25:35,482 [DEBUG] request_id: req_3a8b23db3e6612d92eef9be009727a7b
2024-12-14 15:25:35,483 [INFO] GPT-4 analysis completed successfully.
2024-12-14 15:32:48,744 [INFO] Successfully connected to the Reddit API.
2024-12-14 15:32:48,745 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734208368.745515
2024-12-14 15:32:48,745 [DEBUG] Data: None
2024-12-14 15:32:48,745 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-14 15:32:48,748 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-14 15:32:49,230 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 652
2024-12-14 15:32:49,234 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-14 15:32:50,026 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 55405
2024-12-14 15:32:50,090 [DEBUG] Response: 200 (55405 bytes) (rst-430:rem-999.0:used-1 ratelimit) at 1734208370.090963
2024-12-14 15:32:50,108 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdo31p/ at 1734208370.108242
2024-12-14 15:32:50,108 [DEBUG] Data: None
2024-12-14 15:32:50,108 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:32:50,386 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdo31p/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4588
2024-12-14 15:32:50,388 [DEBUG] Response: 200 (4588 bytes) (rst-429:rem-998.0:used-2 ratelimit) at 1734208370.388096
2024-12-14 15:32:50,389 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdlno3/ at 1734208370.389931
2024-12-14 15:32:50,390 [DEBUG] Data: None
2024-12-14 15:32:50,390 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:32:50,562 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdlno3/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3314
2024-12-14 15:32:50,563 [DEBUG] Response: 200 (3314 bytes) (rst-429:rem-997.0:used-3 ratelimit) at 1734208370.5630772
2024-12-14 15:32:50,564 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdg5rp/ at 1734208370.5640619
2024-12-14 15:32:50,564 [DEBUG] Data: None
2024-12-14 15:32:50,564 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:32:50,753 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdg5rp/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3827
2024-12-14 15:32:50,754 [DEBUG] Response: 200 (3827 bytes) (rst-429:rem-996.0:used-4 ratelimit) at 1734208370.754721
2024-12-14 15:32:50,756 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdahzr/ at 1734208370.7567239
2024-12-14 15:32:50,756 [DEBUG] Data: None
2024-12-14 15:32:50,756 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:32:50,880 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdahzr/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2517
2024-12-14 15:32:50,881 [DEBUG] Response: 200 (2517 bytes) (rst-429:rem-995.0:used-5 ratelimit) at 1734208370.8813398
2024-12-14 15:32:50,882 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hd2nk7/ at 1734208370.882229
2024-12-14 15:32:50,882 [DEBUG] Data: None
2024-12-14 15:32:50,882 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:32:51,147 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hd2nk7/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7839
2024-12-14 15:32:51,149 [DEBUG] Response: 200 (7839 bytes) (rst-429:rem-994.0:used-6 ratelimit) at 1734208371.149123
2024-12-14 15:32:51,153 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcv8pi/ at 1734208371.153269
2024-12-14 15:32:51,153 [DEBUG] Data: None
2024-12-14 15:32:51,153 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:32:51,301 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcv8pi/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3047
2024-12-14 15:32:51,301 [DEBUG] Response: 200 (3047 bytes) (rst-428:rem-993.0:used-7 ratelimit) at 1734208371.301931
2024-12-14 15:32:51,303 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hci0sx/ at 1734208371.303263
2024-12-14 15:32:51,303 [DEBUG] Data: None
2024-12-14 15:32:51,303 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:32:51,515 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hci0sx/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6639
2024-12-14 15:32:51,517 [DEBUG] Response: 200 (6639 bytes) (rst-428:rem-992.0:used-8 ratelimit) at 1734208371.5170538
2024-12-14 15:32:51,519 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcfjg8/ at 1734208371.519218
2024-12-14 15:32:51,519 [DEBUG] Data: None
2024-12-14 15:32:51,519 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:32:51,707 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcfjg8/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4255
2024-12-14 15:32:51,708 [DEBUG] Response: 200 (4255 bytes) (rst-428:rem-991.0:used-9 ratelimit) at 1734208371.7085912
2024-12-14 15:32:51,710 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcaa94/ at 1734208371.7106528
2024-12-14 15:32:51,710 [DEBUG] Data: None
2024-12-14 15:32:51,710 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:32:51,842 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcaa94/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2770
2024-12-14 15:32:51,843 [DEBUG] Response: 200 (2770 bytes) (rst-428:rem-990.0:used-10 ratelimit) at 1734208371.8439481
2024-12-14 15:32:51,845 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hc7am0/ at 1734208371.8453739
2024-12-14 15:32:51,845 [DEBUG] Data: None
2024-12-14 15:32:51,845 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:32:52,226 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hc7am0/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7554
2024-12-14 15:32:52,228 [DEBUG] Response: 200 (7554 bytes) (rst-428:rem-989.0:used-11 ratelimit) at 1734208372.228605
2024-12-14 15:32:52,233 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734208372.233535
2024-12-14 15:32:52,233 [DEBUG] Data: None
2024-12-14 15:32:52,233 [DEBUG] Params: {'after': 't3_1h7a71l', 'limit': 200, 'raw_json': 1}
2024-12-14 15:32:53,078 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h7a71l&raw_json=1 HTTP/11" 200 48341
2024-12-14 15:32:53,094 [DEBUG] Response: 200 (48341 bytes) (rst-427:rem-988.0:used-12 ratelimit) at 1734208373.0945642
2024-12-14 15:32:53,106 [INFO] Fetched and filtered 10 posts.
2024-12-14 15:32:53,126 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': "\n    You are a helpful assistant. Identify up to 20 good posts.\n\n    Here are the posts:\n    Post ID: 1hdo31p\nTitle: Is email marketing worth the time and money for small e-commerce businesses?\nScore: 7\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI think yes. I plan on working more on this next year and have a decent list to start of people who have signed up to a newsletter.\n\nIt shouldn't be costly at all when you start as free plans are provided with limitations. Once you start seeing results you can then invest money.\n\nIf you're just cold calling you'll land in spam folders and that's pointless. Get people to sign up and verify your domain so you land in their actual inbox!\nYep! I was doing 30%+ of my revenue through email. And it was incremental revenue. \n\nYou dont have to overbake it. \n\n1. Text emails are underrated. \n2. For HTML emails, get a solid template designed up and then its easy to swap in new creative each time. Canva is your friend or get someone on Fiverr to help. \n3. Set up a few smart automationsmight take you an hourand then establish a send cadence; maybe one email a week. Again, this shouldnt take more than 30-60 minutes an email. Time well spent. Provides youve got a database of course. \n4. If your database is tinyunder 50you could even just send the odd email directly to key customers. Hey, John here. Im the owner of XYZ Just wanted to mention\n------\nPost ID: 1hdlno3\nTitle: Dropshipping in 2024: A Comedy Special\nScore: 25\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI dont care if this is written by AI. Its rather funny. Especially Day 30. \nCertainly much better than those posts from people that have zero knowledge about dropshipping and want someone to tell them how to become a millionaire by the end of the week\n------\nPost ID: 1hdg5rp\nTitle: You guys be careful out there\nScore: 9\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nYes 100%, I had one reach out to me. Tried to charge almost double more than Aliexpress...\nYeah even with legitimate agents, the price of shipping and storage is extortionate.\n\nHere's why I still dropship after 4 years and haven't transitioned to agent or 3PL\nhttps://youtu.be/l7uSiQ9sHik?si=aQ9_tytfRXjj7Gzu\n------\nPost ID: 1hdahzr\nTitle: Trending Niches on TikTok Shop US in December\nScore: 7\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n------\nPost ID: 1hd2nk7\nTitle: I have a TikTok shop for sale, what is a fair price to ask for it?\nScore: 11\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nFor dropshipping stores with that short of a history you would realisticly be looking at 500-750$ area.\n\nDropshipping stores in themself do not sell for nearly the same as normal companies that are in multipliers of annual incomes.  \nAnd with both being limited to a platform like that plus such a short history, you are not even guaranteed to get 3x average monthly profit (and you can not expect to get the holiday peak included in that average).\nAvoid putting any money into tictok until after you know if the ban does or doesn't go through next month.\n------\nPost ID: 1hcv8pi\nTitle: Doing Ok I Guess\nScore: 33\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n>(ironic most people seek the opposite).\n\nMost kids/teens walking into it imagining it being easy money seek it, majority that are older do not really seek it.\n\nDoing something like dropshipping fulltime is something that sounds great intil you actualy do it tends to be the experience.  \nYou tend to start missing the coworkers, meetings etc that you used to somewhat hate.\nKeep moving forward, you got this\n------\nPost ID: 1hci0sx\nTitle: How long did it take for you to make the first sale?\nScore: 13\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI know this doesn't answer your question, but I don't think furniture is a good niche for dropshipping, especially for a beginner. Just my 2 cents.\nWhen i initialy started dropshipping half a lifetime ago it was 2-3hours from starting to promote store to first sales, from posting items on listing sites and driving them to the store to purchase.\n\nWhen we launch a store today its also same day from ads.  \nBut with ads is not as much a question if you drive traffic and get sales with a ok store, its how much do you spend per sale.\n------\nPost ID: 1hcfjg8\nTitle: We're a manufacturer from Nepal. I've only recently learned about drop shipping. Is there a specific word for sellers? how do I connect with them?\nScore: 11\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWhat do you manufacture? Cost? Shipping cost and time?\nIm interested in selling for you lets connect @zillymilli instagram\n------\nPost ID: 1hcaa94\nTitle: Dropshipping tips-what to sell in January to make 6fig\nScore: 11\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWinter halt mostly happens in the northern most states, not al around, but the major factor is festive season. Not for all industries like gifting, or clothing, etc. But for manufacturing it becomes a pause.\n------\nPost ID: 1hc7am0\nTitle: Instagram acc 60k\nScore: 22\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI wouldn't rebrand it, as the followers are there for the food. Run with that niche.\nInstead of selling t shirts or gimmicks , you could sell recipes or cooking pdfs :)\n------\n\n\n    Return only a comma-separated list of post IDs without any additional text.\n    "}], 'model': 'gpt-4o-mini', 'max_tokens': 500, 'temperature': 0.7}}
2024-12-14 15:32:53,147 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 15:32:53,148 [DEBUG] connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 15:32:53,223 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10b7fa510>
2024-12-14 15:32:53,224 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x10b7c4ef0> server_hostname='api.openai.com' timeout=5.0
2024-12-14 15:32:53,259 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10b808910>
2024-12-14 15:32:53,260 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-12-14 15:32:53,260 [DEBUG] send_request_headers.complete
2024-12-14 15:32:53,260 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-12-14 15:32:53,260 [DEBUG] send_request_body.complete
2024-12-14 15:32:53,260 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-12-14 15:32:54,160 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 20:32:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-wfobhzlf64ogbzvuffig3c5l'), (b'openai-processing-ms', b'725'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'197442'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'767ms'), (b'x-request-id', b'req_16c374c840b74b29fde2a8d530d8637a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=nxmF4Bu3zvn6q32XXT72QoqymM2neJ50MgIXoDzO6RE-1734208374-1.0.1.1-j.Oos.GQ_BDcBR5FzvsEDYlbWaYz8hOFZUJyNi3R7CaXWh9e9Wj8gl1CmsA53eBj8iMb3Lxi3y.WriURjEzRtw; path=/; expires=Sat, 14-Dec-24 21:02:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=xNoAKi.ggR.fahW1onQ9CGnTacWsfJ2WP_nJfkuNClU-1734208374172-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f20f73d2e338c3f-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 15:32:54,161 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-14 15:32:54,161 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-12-14 15:32:54,161 [DEBUG] receive_response_body.complete
2024-12-14 15:32:54,162 [DEBUG] response_closed.started
2024-12-14 15:32:54,162 [DEBUG] response_closed.complete
2024-12-14 15:32:54,162 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sat, 14 Dec 2024 20:32:54 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-wfobhzlf64ogbzvuffig3c5l'), ('openai-processing-ms', '725'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '197442'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '767ms'), ('x-request-id', 'req_16c374c840b74b29fde2a8d530d8637a'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=nxmF4Bu3zvn6q32XXT72QoqymM2neJ50MgIXoDzO6RE-1734208374-1.0.1.1-j.Oos.GQ_BDcBR5FzvsEDYlbWaYz8hOFZUJyNi3R7CaXWh9e9Wj8gl1CmsA53eBj8iMb3Lxi3y.WriURjEzRtw; path=/; expires=Sat, 14-Dec-24 21:02:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=xNoAKi.ggR.fahW1onQ9CGnTacWsfJ2WP_nJfkuNClU-1734208374172-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f20f73d2e338c3f-EWR'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-12-14 15:32:54,162 [DEBUG] request_id: req_16c374c840b74b29fde2a8d530d8637a
2024-12-14 15:32:54,165 [INFO] GPT-3.5 identified 6 good posts.
2024-12-14 15:32:54,184 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': "\n        Analyze these posts from r/dropship:\n\n        Post ID: 1hdlno3\nTitle: Dropshipping in 2024: A Comedy Special\nScore: 25\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI dont care if this is written by AI. Its rather funny. Especially Day 30. \nCertainly much better than those posts from people that have zero knowledge about dropshipping and want someone to tell them how to become a millionaire by the end of the week\n------\n\n\nPost ID: 1hcv8pi\nTitle: Doing Ok I Guess\nScore: 33\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n>(ironic most people seek the opposite).\n\nMost kids/teens walking into it imagining it being easy money seek it, majority that are older do not really seek it.\n\nDoing something like dropshipping fulltime is something that sounds great intil you actualy do it tends to be the experience.  \nYou tend to start missing the coworkers, meetings etc that you used to somewhat hate.\nKeep moving forward, you got this\n------\n\n\nPost ID: 1hci0sx\nTitle: How long did it take for you to make the first sale?\nScore: 13\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI know this doesn't answer your question, but I don't think furniture is a good niche for dropshipping, especially for a beginner. Just my 2 cents.\nWhen i initialy started dropshipping half a lifetime ago it was 2-3hours from starting to promote store to first sales, from posting items on listing sites and driving them to the store to purchase.\n\nWhen we launch a store today its also same day from ads.  \nBut with ads is not as much a question if you drive traffic and get sales with a ok store, its how much do you spend per sale.\n------\n\n\nPost ID: 1hcfjg8\nTitle: We're a manufacturer from Nepal. I've only recently learned about drop shipping. Is there a specific word for sellers? how do I connect with them?\nScore: 11\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWhat do you manufacture? Cost? Shipping cost and time?\nIm interested in selling for you lets connect @zillymilli instagram\n------\n\n\nPost ID: 1hcaa94\nTitle: Dropshipping tips-what to sell in January to make 6fig\nScore: 11\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWinter halt mostly happens in the northern most states, not al around, but the major factor is festive season. Not for all industries like gifting, or clothing, etc. But for manufacturing it becomes a pause.\n------\n\n\nPost ID: 1hc7am0\nTitle: Instagram acc 60k\nScore: 22\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI wouldn't rebrand it, as the followers are there for the food. Run with that niche.\nInstead of selling t shirts or gimmicks , you could sell recipes or cooking pdfs :)\n------\n\n\n        Provide insights, trends, or recommendations based on these posts.\n        "}], 'model': 'gpt-4o-mini', 'max_tokens': 3000, 'temperature': 0.7}}
2024-12-14 15:32:54,184 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 15:32:54,185 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-12-14 15:32:54,185 [DEBUG] send_request_headers.complete
2024-12-14 15:32:54,185 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-12-14 15:32:54,185 [DEBUG] send_request_body.complete
2024-12-14 15:32:54,185 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-12-14 15:33:04,970 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 20:33:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-wfobhzlf64ogbzvuffig3c5l'), (b'openai-processing-ms', b'10616'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'195886'), (b'x-ratelimit-reset-requests', b'16.364s'), (b'x-ratelimit-reset-tokens', b'1.234s'), (b'x-request-id', b'req_dd69cca7d4e8a478870931a19ebf6804'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f20f742fcb48c3f-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 15:33:04,971 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-14 15:33:04,971 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-12-14 15:33:04,972 [DEBUG] receive_response_body.complete
2024-12-14 15:33:04,972 [DEBUG] response_closed.started
2024-12-14 15:33:04,972 [DEBUG] response_closed.complete
2024-12-14 15:33:04,972 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sat, 14 Dec 2024 20:33:04 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-wfobhzlf64ogbzvuffig3c5l', 'openai-processing-ms': '10616', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '195886', 'x-ratelimit-reset-requests': '16.364s', 'x-ratelimit-reset-tokens': '1.234s', 'x-request-id': 'req_dd69cca7d4e8a478870931a19ebf6804', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f20f742fcb48c3f-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 15:33:04,972 [DEBUG] request_id: req_dd69cca7d4e8a478870931a19ebf6804
2024-12-14 15:33:04,974 [INFO] GPT-4 analysis completed successfully.
2024-12-14 15:38:12,655 [DEBUG] close.started
2024-12-14 15:38:12,656 [DEBUG] close.complete
2024-12-14 15:39:07,144 [INFO] Successfully connected to the Reddit API.
2024-12-14 15:39:07,145 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734208747.145026
2024-12-14 15:39:07,145 [DEBUG] Data: None
2024-12-14 15:39:07,145 [DEBUG] Params: {'limit': 200, 'raw_json': 1}
2024-12-14 15:39:07,147 [DEBUG] Starting new HTTPS connection (1): www.reddit.com:443
2024-12-14 15:39:07,624 [DEBUG] https://www.reddit.com:443 "POST /api/v1/access_token HTTP/11" 200 655
2024-12-14 15:39:07,628 [DEBUG] Starting new HTTPS connection (1): oauth.reddit.com:443
2024-12-14 15:39:09,069 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&raw_json=1 HTTP/11" 200 55404
2024-12-14 15:39:09,130 [DEBUG] Response: 200 (55404 bytes) (rst-52:rem-987.0:used-13 ratelimit) at 1734208749.130114
2024-12-14 15:39:09,143 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdo31p/ at 1734208749.1433222
2024-12-14 15:39:09,143 [DEBUG] Data: None
2024-12-14 15:39:09,143 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:39:09,327 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdo31p/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4588
2024-12-14 15:39:09,329 [DEBUG] Response: 200 (4588 bytes) (rst-50:rem-986.0:used-14 ratelimit) at 1734208749.329275
2024-12-14 15:39:09,330 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdlno3/ at 1734208749.3306491
2024-12-14 15:39:09,330 [DEBUG] Data: None
2024-12-14 15:39:09,330 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:39:09,497 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdlno3/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3324
2024-12-14 15:39:09,498 [DEBUG] Response: 200 (3324 bytes) (rst-50:rem-985.0:used-15 ratelimit) at 1734208749.498335
2024-12-14 15:39:09,499 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdg5rp/ at 1734208749.499091
2024-12-14 15:39:09,499 [DEBUG] Data: None
2024-12-14 15:39:09,499 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:39:09,665 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdg5rp/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3823
2024-12-14 15:39:09,668 [DEBUG] Response: 200 (3823 bytes) (rst-50:rem-984.0:used-16 ratelimit) at 1734208749.668897
2024-12-14 15:39:09,670 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hdahzr/ at 1734208749.670423
2024-12-14 15:39:09,670 [DEBUG] Data: None
2024-12-14 15:39:09,670 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:39:09,825 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hdahzr/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2520
2024-12-14 15:39:09,826 [DEBUG] Response: 200 (2520 bytes) (rst-50:rem-983.0:used-17 ratelimit) at 1734208749.826486
2024-12-14 15:39:09,827 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hd2nk7/ at 1734208749.827178
2024-12-14 15:39:09,827 [DEBUG] Data: None
2024-12-14 15:39:09,827 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:39:10,071 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hd2nk7/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7840
2024-12-14 15:39:10,073 [DEBUG] Response: 200 (7840 bytes) (rst-50:rem-982.0:used-18 ratelimit) at 1734208750.073898
2024-12-14 15:39:10,078 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcv8pi/ at 1734208750.078836
2024-12-14 15:39:10,078 [DEBUG] Data: None
2024-12-14 15:39:10,079 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:39:10,240 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcv8pi/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 3046
2024-12-14 15:39:10,241 [DEBUG] Response: 200 (3046 bytes) (rst-49:rem-981.0:used-19 ratelimit) at 1734208750.241225
2024-12-14 15:39:10,242 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hci0sx/ at 1734208750.242794
2024-12-14 15:39:10,242 [DEBUG] Data: None
2024-12-14 15:39:10,243 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:39:10,437 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hci0sx/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 6639
2024-12-14 15:39:10,439 [DEBUG] Response: 200 (6639 bytes) (rst-49:rem-980.0:used-20 ratelimit) at 1734208750.439615
2024-12-14 15:39:10,442 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcfjg8/ at 1734208750.4422169
2024-12-14 15:39:10,442 [DEBUG] Data: None
2024-12-14 15:39:10,442 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:39:10,619 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcfjg8/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 4255
2024-12-14 15:39:10,620 [DEBUG] Response: 200 (4255 bytes) (rst-49:rem-979.0:used-21 ratelimit) at 1734208750.620565
2024-12-14 15:39:10,622 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hcaa94/ at 1734208750.622339
2024-12-14 15:39:10,622 [DEBUG] Data: None
2024-12-14 15:39:10,622 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:39:10,754 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hcaa94/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 2769
2024-12-14 15:39:10,755 [DEBUG] Response: 200 (2769 bytes) (rst-49:rem-978.0:used-22 ratelimit) at 1734208750.7552562
2024-12-14 15:39:10,756 [DEBUG] Fetching: GET https://oauth.reddit.com/comments/1hc7am0/ at 1734208750.756144
2024-12-14 15:39:10,756 [DEBUG] Data: None
2024-12-14 15:39:10,756 [DEBUG] Params: {'limit': 2048, 'raw_json': 1, 'sort': 'confidence'}
2024-12-14 15:39:11,014 [DEBUG] https://oauth.reddit.com:443 "GET /comments/1hc7am0/?limit=2048&sort=confidence&raw_json=1 HTTP/11" 200 7563
2024-12-14 15:39:11,015 [DEBUG] Response: 200 (7563 bytes) (rst-49:rem-977.0:used-23 ratelimit) at 1734208751.0157251
2024-12-14 15:39:11,020 [DEBUG] Fetching: GET https://oauth.reddit.com/r/dropship/new at 1734208751.020556
2024-12-14 15:39:11,020 [DEBUG] Data: None
2024-12-14 15:39:11,020 [DEBUG] Params: {'after': 't3_1h7a71l', 'limit': 200, 'raw_json': 1}
2024-12-14 15:39:11,891 [DEBUG] https://oauth.reddit.com:443 "GET /r/dropship/new?limit=200&after=t3_1h7a71l&raw_json=1 HTTP/11" 200 48324
2024-12-14 15:39:11,906 [DEBUG] Response: 200 (48324 bytes) (rst-48:rem-976.0:used-24 ratelimit) at 1734208751.906254
2024-12-14 15:39:11,918 [INFO] Fetched and filtered 10 posts.
2024-12-14 15:39:11,937 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': "\n    You are a helpful assistant. Identify up to 20 good posts.\n\n    Here are the posts:\n    Post ID: 1hdo31p\nTitle: Is email marketing worth the time and money for small e-commerce businesses?\nScore: 7\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI think yes. I plan on working more on this next year and have a decent list to start of people who have signed up to a newsletter.\n\nIt shouldn't be costly at all when you start as free plans are provided with limitations. Once you start seeing results you can then invest money.\n\nIf you're just cold calling you'll land in spam folders and that's pointless. Get people to sign up and verify your domain so you land in their actual inbox!\nYep! I was doing 30%+ of my revenue through email. And it was incremental revenue. \n\nYou dont have to overbake it. \n\n1. Text emails are underrated. \n2. For HTML emails, get a solid template designed up and then its easy to swap in new creative each time. Canva is your friend or get someone on Fiverr to help. \n3. Set up a few smart automationsmight take you an hourand then establish a send cadence; maybe one email a week. Again, this shouldnt take more than 30-60 minutes an email. Time well spent. Provides youve got a database of course. \n4. If your database is tinyunder 50you could even just send the odd email directly to key customers. Hey, John here. Im the owner of XYZ Just wanted to mention\n------\nPost ID: 1hdlno3\nTitle: Dropshipping in 2024: A Comedy Special\nScore: 26\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI dont care if this is written by AI. Its rather funny. Especially Day 30. \nCertainly much better than those posts from people that have zero knowledge about dropshipping and want someone to tell them how to become a millionaire by the end of the week\n------\nPost ID: 1hdg5rp\nTitle: You guys be careful out there\nScore: 8\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nYes 100%, I had one reach out to me. Tried to charge almost double more than Aliexpress...\nYeah even with legitimate agents, the price of shipping and storage is extortionate.\n\nHere's why I still dropship after 4 years and haven't transitioned to agent or 3PL\nhttps://youtu.be/l7uSiQ9sHik?si=aQ9_tytfRXjj7Gzu\n------\nPost ID: 1hdahzr\nTitle: Trending Niches on TikTok Shop US in December\nScore: 7\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n------\nPost ID: 1hd2nk7\nTitle: I have a TikTok shop for sale, what is a fair price to ask for it?\nScore: 11\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nFor dropshipping stores with that short of a history you would realisticly be looking at 500-750$ area.\n\nDropshipping stores in themself do not sell for nearly the same as normal companies that are in multipliers of annual incomes.  \nAnd with both being limited to a platform like that plus such a short history, you are not even guaranteed to get 3x average monthly profit (and you can not expect to get the holiday peak included in that average).\nAvoid putting any money into tictok until after you know if the ban does or doesn't go through next month.\n------\nPost ID: 1hcv8pi\nTitle: Doing Ok I Guess\nScore: 32\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n>(ironic most people seek the opposite).\n\nMost kids/teens walking into it imagining it being easy money seek it, majority that are older do not really seek it.\n\nDoing something like dropshipping fulltime is something that sounds great intil you actualy do it tends to be the experience.  \nYou tend to start missing the coworkers, meetings etc that you used to somewhat hate.\nKeep moving forward, you got this\n------\nPost ID: 1hci0sx\nTitle: How long did it take for you to make the first sale?\nScore: 13\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI know this doesn't answer your question, but I don't think furniture is a good niche for dropshipping, especially for a beginner. Just my 2 cents.\nWhen i initialy started dropshipping half a lifetime ago it was 2-3hours from starting to promote store to first sales, from posting items on listing sites and driving them to the store to purchase.\n\nWhen we launch a store today its also same day from ads.  \nBut with ads is not as much a question if you drive traffic and get sales with a ok store, its how much do you spend per sale.\n------\nPost ID: 1hcfjg8\nTitle: We're a manufacturer from Nepal. I've only recently learned about drop shipping. Is there a specific word for sellers? how do I connect with them?\nScore: 12\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWhat do you manufacture? Cost? Shipping cost and time?\nIm interested in selling for you lets connect @zillymilli instagram\n------\nPost ID: 1hcaa94\nTitle: Dropshipping tips-what to sell in January to make 6fig\nScore: 10\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWinter halt mostly happens in the northern most states, not al around, but the major factor is festive season. Not for all industries like gifting, or clothing, etc. But for manufacturing it becomes a pause.\n------\nPost ID: 1hc7am0\nTitle: Instagram acc 60k\nScore: 22\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI wouldn't rebrand it, as the followers are there for the food. Run with that niche.\nInstead of selling t shirts or gimmicks , you could sell recipes or cooking pdfs :)\n------\n\n\n    Return only a comma-separated list of post IDs without any additional text.\n    "}], 'model': 'gpt-4o-mini', 'max_tokens': 500, 'temperature': 0.7}}
2024-12-14 15:39:11,966 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 15:39:11,966 [DEBUG] connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 15:39:12,055 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10c256510>
2024-12-14 15:39:12,055 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x10c224ef0> server_hostname='api.openai.com' timeout=5.0
2024-12-14 15:39:12,091 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10c264910>
2024-12-14 15:39:12,092 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-12-14 15:39:12,092 [DEBUG] send_request_headers.complete
2024-12-14 15:39:12,092 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-12-14 15:39:12,092 [DEBUG] send_request_body.complete
2024-12-14 15:39:12,092 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-12-14 15:39:13,324 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 20:39:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-wfobhzlf64ogbzvuffig3c5l'), (b'openai-processing-ms', b'1072'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'197442'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'767ms'), (b'x-request-id', b'req_4430948bbd6e7ff862913fea675f542a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=w1UxFqx8pxjGEHW7QMhLklG6z2jaNNEj92VOnFXLiGQ-1734208753-1.0.1.1-MAmk65iJbdISIxmGNU3p.rNpwDJ5iK5Rl0mCsh_JhpkUVvTxBIyNfi_1.XeuknZwspDJ8MsJNSWAij.TlM_rrQ; path=/; expires=Sat, 14-Dec-24 21:09:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=_HHMq51D4TFsp8ygfwSiFlSRFsCSBeOOarvc083UA.k-1734208753346-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21007ce8891902-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 15:39:13,326 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-14 15:39:13,327 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-12-14 15:39:13,327 [DEBUG] receive_response_body.complete
2024-12-14 15:39:13,327 [DEBUG] response_closed.started
2024-12-14 15:39:13,328 [DEBUG] response_closed.complete
2024-12-14 15:39:13,328 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sat, 14 Dec 2024 20:39:13 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-wfobhzlf64ogbzvuffig3c5l'), ('openai-processing-ms', '1072'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '197442'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '767ms'), ('x-request-id', 'req_4430948bbd6e7ff862913fea675f542a'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=w1UxFqx8pxjGEHW7QMhLklG6z2jaNNEj92VOnFXLiGQ-1734208753-1.0.1.1-MAmk65iJbdISIxmGNU3p.rNpwDJ5iK5Rl0mCsh_JhpkUVvTxBIyNfi_1.XeuknZwspDJ8MsJNSWAij.TlM_rrQ; path=/; expires=Sat, 14-Dec-24 21:09:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=_HHMq51D4TFsp8ygfwSiFlSRFsCSBeOOarvc083UA.k-1734208753346-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f21007ce8891902-EWR'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-12-14 15:39:13,328 [DEBUG] request_id: req_4430948bbd6e7ff862913fea675f542a
2024-12-14 15:39:13,332 [INFO] GPT-3.5 identified 11 good posts.
2024-12-14 15:39:13,347 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': "\n        Analyze these posts from r/dropship:\n\n        Post ID: 1hdo31p\nTitle: Is email marketing worth the time and money for small e-commerce businesses?\nScore: 7\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI think yes. I plan on working more on this next year and have a decent list to start of people who have signed up to a newsletter.\n\nIt shouldn't be costly at all when you start as free plans are provided with limitations. Once you start seeing results you can then invest money.\n\nIf you're just cold calling you'll land in spam folders and that's pointless. Get people to sign up and verify your domain so you land in their actual inbox!\nYep! I was doing 30%+ of my revenue through email. And it was incremental revenue. \n\nYou dont have to overbake it. \n\n1. Text emails are underrated. \n2. For HTML emails, get a solid template designed up and then its easy to swap in new creative each time. Canva is your friend or get someone on Fiverr to help. \n3. Set up a few smart automationsmight take you an hourand then establish a send cadence; maybe one email a week. Again, this shouldnt take more than 30-60 minutes an email. Time well spent. Provides youve got a database of course. \n4. If your database is tinyunder 50you could even just send the odd email directly to key customers. Hey, John here. Im the owner of XYZ Just wanted to mention\n------\n\n\nPost ID: 1hdlno3\nTitle: Dropshipping in 2024: A Comedy Special\nScore: 26\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI dont care if this is written by AI. Its rather funny. Especially Day 30. \nCertainly much better than those posts from people that have zero knowledge about dropshipping and want someone to tell them how to become a millionaire by the end of the week\n------\n\n\nPost ID: 1hdg5rp\nTitle: You guys be careful out there\nScore: 8\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nYes 100%, I had one reach out to me. Tried to charge almost double more than Aliexpress...\nYeah even with legitimate agents, the price of shipping and storage is extortionate.\n\nHere's why I still dropship after 4 years and haven't transitioned to agent or 3PL\nhttps://youtu.be/l7uSiQ9sHik?si=aQ9_tytfRXjj7Gzu\n------\n\n\nPost ID: 1hdahzr\nTitle: Trending Niches on TikTok Shop US in December\nScore: 7\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n------\n\n\nPost ID: 1hd2nk7\nTitle: I have a TikTok shop for sale, what is a fair price to ask for it?\nScore: 11\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nFor dropshipping stores with that short of a history you would realisticly be looking at 500-750$ area.\n\nDropshipping stores in themself do not sell for nearly the same as normal companies that are in multipliers of annual incomes.  \nAnd with both being limited to a platform like that plus such a short history, you are not even guaranteed to get 3x average monthly profit (and you can not expect to get the holiday peak included in that average).\nAvoid putting any money into tictok until after you know if the ban does or doesn't go through next month.\n------\n\n\nPost ID: 1hcv8pi\nTitle: Doing Ok I Guess\nScore: 32\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\n>(ironic most people seek the opposite).\n\nMost kids/teens walking into it imagining it being easy money seek it, majority that are older do not really seek it.\n\nDoing something like dropshipping fulltime is something that sounds great intil you actualy do it tends to be the experience.  \nYou tend to start missing the coworkers, meetings etc that you used to somewhat hate.\nKeep moving forward, you got this\n------\n\n\nPost ID: 1hci0sx\nTitle: How long did it take for you to make the first sale?\nScore: 13\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI know this doesn't answer your question, but I don't think furniture is a good niche for dropshipping, especially for a beginner. Just my 2 cents.\nWhen i initialy started dropshipping half a lifetime ago it was 2-3hours from starting to promote store to first sales, from posting items on listing sites and driving them to the store to purchase.\n\nWhen we launch a store today its also same day from ads.  \nBut with ads is not as much a question if you drive traffic and get sales with a ok store, its how much do you spend per sale.\n------\n\n\nPost ID: 1hcaa94\nTitle: Dropshipping tips-what to sell in January to make 6fig\nScore: 10\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nWinter halt mostly happens in the northern most states, not al around, but the major factor is festive season. Not for all industries like gifting, or clothing, etc. But for manufacturing it becomes a pause.\n------\n\n\nPost ID: 1hc7am0\nTitle: Instagram acc 60k\nScore: 22\nFirst 3 Comments:\n**REPORT posts/comments if they are SPAM, self-promotion, or a store review/critique**  \n    + help keep r/dropship SPAM free \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dropship) if you have any questions or concerns.*\nI wouldn't rebrand it, as the followers are there for the food. Run with that niche.\nInstead of selling t shirts or gimmicks , you could sell recipes or cooking pdfs :)\n------\n\n\n        Provide insights, trends, or recommendations based on these posts.\n        "}], 'model': 'gpt-4o-mini', 'max_tokens': 3000, 'temperature': 0.7}}
2024-12-14 15:39:13,348 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 15:39:13,348 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-12-14 15:39:13,348 [DEBUG] send_request_headers.complete
2024-12-14 15:39:13,348 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-12-14 15:39:13,348 [DEBUG] send_request_body.complete
2024-12-14 15:39:13,348 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-12-14 15:39:24,036 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 20:39:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-wfobhzlf64ogbzvuffig3c5l'), (b'openai-processing-ms', b'10527'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'195110'), (b'x-ratelimit-reset-requests', b'16.029s'), (b'x-ratelimit-reset-tokens', b'1.467s'), (b'x-request-id', b'req_bc70543c67feeb12ebc0b8e29b733b8a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f210084c8bc1902-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 15:39:24,038 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-14 15:39:24,038 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-12-14 15:39:24,039 [DEBUG] receive_response_body.complete
2024-12-14 15:39:24,039 [DEBUG] response_closed.started
2024-12-14 15:39:24,039 [DEBUG] response_closed.complete
2024-12-14 15:39:24,039 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sat, 14 Dec 2024 20:39:24 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-wfobhzlf64ogbzvuffig3c5l', 'openai-processing-ms': '10527', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '195110', 'x-ratelimit-reset-requests': '16.029s', 'x-ratelimit-reset-tokens': '1.467s', 'x-request-id': 'req_bc70543c67feeb12ebc0b8e29b733b8a', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f210084c8bc1902-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 15:39:24,039 [DEBUG] request_id: req_bc70543c67feeb12ebc0b8e29b733b8a
2024-12-14 15:39:24,040 [INFO] GPT-4 analysis completed successfully.
